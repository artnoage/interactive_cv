# Large deviations for configurations generated by Gibbs distributions with energy functionals consisting of singular interaction and weakly confining potentials

Paul Dupuis<sup>∗</sup> , Vaios Laschos† , and Kavita Ramanan‡

> Division of Applied Mathematics Brown University Providence, RI

> > January 7, 2020

#### Abstract

We establish large deviation principles (LDPs) for empirical measures associated with a sequence of Gibbs distributions on n-particle configurations, each of which is defined in terms of an inverse temperature β<sup>n</sup> and an energy functional consisting of a (possibly singular) interaction potential and a (possibly weakly) confining potential. Under fairly general assumptions on the potentials, we use a common framework to establish LDPs both with speeds βn/n → ∞, in which case the rate function is expressed in terms of a functional involving the potentials, and with speed β<sup>n</sup> = n, when the rate function contains an additional entropic term. Such LDPs are motivated by questions arising in random matrix theory, sampling, simulated annealing and asymptotic convex geometry. Our approach, which uses the weak convergence method developed by Dupuis and Ellis, establishes LDPs with respect to stronger Wasserstein-type topologies. Our results address several interesting examples not covered by previous works, including the case of a weakly confining potential, which allows for rate functions with minimizers that do not have compact support, thus resolving several open questions raised in a work of Chafa¨ı et al.

2010 Mathematics Subject Classification. Primary: 60F10, 60K35; Secondary: 60B20 Key Words and Phrases. Large deviations principle, empirical measures, Gibbs distributions, interacting

particle systems, singular interaction potential, weakly confining potential, rate function, weak topology, Wasserstein topology, relative entropy, Coulomb gases, random matrices, asymptotic thin shell condition.

<sup>∗</sup>Research supported in part by AFOSR FA9550-12-1-0399

<sup>†</sup>Research supported in part by AFOSR FA9550-12-1-0399

<sup>‡</sup>Research supported in part by AFOSR FA9550-12-1-0399 and NSF DMS-1407504

# Contents

| 1 | Introduction                                                 | 3  |
|---|--------------------------------------------------------------|----|
|   | 1.1<br>Description of problem and contributions<br>.<br>.    | 3  |
|   | 1.2<br>Discussion of related recent results<br>.<br>.        | 5  |
| 2 | Assumptions and main results                                 | 5  |
|   | 2.1<br>Notation and definitions<br>.<br>.                    | 6  |
|   | 2.2<br>Results in the case<br>βn<br>=<br>n<br>.              | 7  |
|   | 2.3<br>Results in the case<br>βn/n<br>→ ∞                    | 9  |
|   | 2.4<br>Corollaries of the main results<br>.                  | 10 |
|   | 2.4.1<br>Known examples covered by our assumptions<br>.<br>. | 10 |
|   | 2.4.2<br>Non-diverging, weakly confining potentials<br>.     | 11 |
|   | 2.4.3<br>Discontinuous interaction potentials<br>.<br>.      | 14 |
|   | 2.5<br>Outline of the paper<br>.<br>.                        | 15 |
| 3 | Rate Function Property                                       | 15 |
|   | 3.1<br>Basic definitions<br>.<br>.                           | 16 |
|   | 3.2<br>Verification of the rate function property<br>.       | 16 |
| 4 | Proof of Theorem 2.7                                         | 18 |
|   | 4.1<br>Representation formula<br>.<br>.                      | 19 |
|   | 4.2<br>Properties of the controls<br>.<br>.                  | 20 |
|   | 4.3<br>Proof of the lower bound<br>.                         | 23 |
|   | 4.4<br>Proof of the upper bound<br>.<br>.                    | 24 |
| 5 | Proof of Theorem 2.9                                         | 25 |
|   | 5.1<br>Representation formula<br>.<br>.                      | 25 |
|   | 5.2<br>Tightness of controls<br>.<br>.                       | 26 |
|   | 5.3<br>Proof of the lower bound<br>.                         | 28 |
|   | 5.4<br>Proof of the upper bound<br>.<br>.                    | 29 |
| A | The Weak Convergence Approach to Large Deviations            | 30 |
| B | Proof of Lemma 2.6                                           | 31 |
| C | Proof of Lemma 3.5                                           | 33 |
| D | Tightness Results                                            | 36 |
| E | Auxiliary Lemmas                                             | 36 |
|   |                                                              |    |
| F | Proof of Lemma 5.3                                           | 37 |

### <span id="page-2-1"></span><span id="page-2-0"></span>1 Introduction

#### 1.1 Description of problem and contributions

We consider configurations of a finite number of R d -valued particles that are subject to an external force consisting of a confining potential V : R <sup>d</sup> <sup>→</sup> (−∞, <sup>+</sup>∞] that acts on each particle and a pairwise interaction potential W : R <sup>d</sup> <sup>×</sup> <sup>R</sup> <sup>d</sup> <sup>→</sup> (−∞, <sup>+</sup>∞]. For every <sup>n</sup> <sup>∈</sup> <sup>N</sup>, we define a Hamiltonian or energy functional H<sup>n</sup> : R dn <sup>→</sup> (−∞, <sup>+</sup>∞] that assigns to every <sup>R</sup> dn-valued configuration x <sup>n</sup> = (x1, x2, . . . , xn) of n particles, the energy

<span id="page-2-7"></span>
$$
H_n(\mathbf{x}^n) = H_n(\mathbf{x}_1, ..., \mathbf{x}_n) := \frac{1}{n} \sum_{i=1}^n V(\mathbf{x}_i) + \frac{1}{2n^2} \sum_{i,j=1, i \neq j}^n W(\mathbf{x}_i, \mathbf{x}_j).
$$
(1.1)

Also, for any n-particle configuration x <sup>n</sup> = (x1, x2, . . . , xn), let Ln(x n , ·) be the associated empirical measure:

<span id="page-2-3"></span>
$$
L_n(\mathbf{x}^n; \cdot) := \frac{1}{n} \sum_{i=1}^n \delta_{\mathbf{x}_i}(\cdot),
$$
\n(1.2)

where δ<sup>y</sup> represents the Dirac delta mass at y ∈ R d . Given a separable metric space S, let B(S) denote the collection of Borel subsets of S, and let P(S) denote the space of probability measures on (S,B(S)). Note that for every x <sup>n</sup> <sup>∈</sup> <sup>R</sup> d , Ln(x n ; ·) lies in P(R d ), where R d is equipped with the usual Euclidean metric. If x n is random and each component of x <sup>n</sup> has a density that is absolutely continuous with respect to a measure with no atoms (which will be true in this article), H<sup>n</sup> can be rewritten in terms of L<sup>n</sup> as follows:

<span id="page-2-5"></span>
$$
H_n(\mathbf{x}^n) = \int_{\mathbb{R}^d} V(\mathbf{x}) L_n(\mathbf{x}^n; d\mathbf{x}) + \frac{1}{2} \int_{(\mathbb{R}^d \times \mathbb{R}^d)_{\neq}} W(\mathbf{x}, \mathbf{y}) L_n(\mathbf{x}^n; d\mathbf{x}) L_n(\mathbf{x}^n; d\mathbf{y})
$$
  
= 
$$
\frac{1}{n} \int_{\mathbb{R}^d} V(\mathbf{x}) L_n(\mathbf{x}^n; d\mathbf{x}) + \frac{1}{2} \int_{(\mathbb{R}^d \times \mathbb{R}^d)_{\neq}} (W(\mathbf{x}, \mathbf{y}) + V(\mathbf{x}) + V(\mathbf{y})) L_n(\mathbf{x}^n; d\mathbf{x}) L_n(\mathbf{x}^n; d\mathbf{y}),
$$
(1.3)

where for k ∈ N and a set A ⊂ R kd , the symbol A6<sup>=</sup> denotes the set of points in A whose d-dimensional components are all distinct:

<span id="page-2-4"></span>
$$
A_{\neq} := A \setminus \left\{ (\mathbf{x}_1, \dots, \mathbf{x}_k) \in \mathbb{R}^{kd} : \mathbf{x}_i = \mathbf{x}_j \text{ for some } 1 \le i \le j \le k \right\}.
$$
 (1.4)

Let {βn} be a sequence of positive numbers diverging to infinity, which can be interpreted as a sequence of inverse temperatures, and for each n ∈ N, let P<sup>n</sup> ∈ P(R dn) be the probability measure given by

<span id="page-2-2"></span>
$$
P_n\left(d\mathbf{x}_1,\ldots,d\mathbf{x}_n\right) := \frac{\exp\left(-\beta_n H_n\left(\mathbf{x}_1,\ldots,\mathbf{x}_n\right)\right)}{Z_n}\ell(d\mathbf{x}_1)\cdots\ell(d\mathbf{x}_n),\tag{1.5}
$$

where ℓ is a σ-finite measure on R d that has no atoms and acts as a reference measure, and Z<sup>n</sup> is the normalization constant (which is also referred to as the partition function) given by

<span id="page-2-6"></span>
$$
Z_n := \int_{\mathbb{R}^d} \cdots \int_{\mathbb{R}^d} \exp(-\beta_n H_n(\mathbf{x}_1, ..., \mathbf{x}_n)) \ell(d\mathbf{x}_1) \cdots \ell(d\mathbf{x}_n).
$$
 (1.6)

Measures of the form [\(1.5\)](#page-2-2) arise in a variety of contexts. For the case when ℓ is Lebesgue measure on R d , it is well known that if W and V are sufficiently smooth, then P<sup>n</sup> is the invariant distribution of a reversible Markov diffusion on R dn (with identity diffusion matrix and drift proportional to <sup>∇</sup>Hn), which can be viewed as describing the dynamics of n interacting Brownian particles in R d [\[17,](#page-38-0) Chapter 5]. On the other hand, for particular choices of d, V and W, P<sup>n</sup> arises as the law of the spectrum of various random matrix ensembles, including the so-called β-ensemble as well as certain random normal matrices (see Section 1.5.7 of [\[9\]](#page-37-0) for details).

Given P<sup>n</sup> ∈ P(R d ) as in [\(1.5\)](#page-2-2), let Q<sup>n</sup> = (Ln)#P<sup>n</sup> be the measure induced on P R d by pushing P<sup>n</sup> forward under the mapping L<sup>n</sup> : R dn → P(<sup>R</sup> d ) defined in [\(1.2\)](#page-2-3) (see Definition [2.2](#page-5-1) for the definition of (Ln)#). The aim of this paper is to establish large deviation principles (LDPs) for sequences {Qn} under general conditions on V and W that allow V and W to be not only unbounded, but also highly irregular. We apply the weak convergence methods developed in [\[13\]](#page-37-1) to provide results for both cases where β<sup>n</sup> = n (see Theorem [2.7\)](#page-7-0), and limn→∞ βn/n = ∞ (see Theorem [2.9\)](#page-9-2). For the reader unfamiliar with the weak convergence approach to large deviations, we provide a brief outline in Appendix [A.](#page-29-0)

To the best of our knowledge, the most general result in the direction of Theorem [2.9](#page-9-2) is [\[9,](#page-37-0) Theorem 1.1]. The latter seems to be the first paper to present a general approach to proving LDPs for empirical measures generated by Gibbs distributions, when the inverse temperatures β<sup>n</sup> diverge faster than n, the number of particles (the particular case of β<sup>n</sup> = n <sup>2</sup> was considered earlier in [\[4\]](#page-37-2)). Our theorems recover existing results (see Example [2.11\)](#page-9-3) and also extend prior results in the following multiple directions, in particular resolving several open questions raised in [\[9\]](#page-37-0):

- 1. First, whereas the result in [\[9,](#page-37-0) Theorem 1.1] considers only speeds {βn} that satisfy limn→∞ βn/nlog n = ∞, we allow for any speed diverging faster than n, including the speed n 2 considered in [\[4\]](#page-37-2), thus showing that the growth rate condition of [\[9\]](#page-37-0) is a technical one related to the combinatorial approach used in the proofs therein.
- 2. Second, we consider more general confining potentials V . In particular, the assumptions imposed in [\[9\]](#page-37-0) only allow for large deviation rate functions whose minimizers have compact support. The minimizer of the rate function in the LDP (when unique) identifies the limiting equilibrium measure of the particles. On the other hand, LDPs with rate functions that have minimizers that are not compactly supported arise in the context of simulated annealing algorithms that are designed to sample from the minimizer of the rate function (in which case the sequence {βn} is referred to as a cooling schedule); see, e.g., [\[9,](#page-37-0) Section 1.5.8]. In this article, we impose weaker assumptions that, unlike in [\[9\]](#page-37-0), allow for confining potentials V that can be weak (that is, with the limit of the corresponding sequence of empirical measures being non-compactly supported), discontinuous (see Examples [2.12](#page-10-1) and [2.17\)](#page-13-1), unbounded, and possibly not even locally integrable. In particular, the potential V is allowed to even be zero in a non-trivial unbounded domain, provided that the volume of the domain outside a ball of radius R around the origin decreases "sufficiently fast" as R goes to infinity. This allows us to consider cases where the particles are not confined in a bounded set, and in particular leads to examples with minimizers that do not have compact support (see Example [2.12\)](#page-10-1), thus addressing the open question raised in [\[9,](#page-37-0) Section 1.5.1]. It appears that this has only been previously studied in the case of R <sup>2</sup> with the logarithmic Coulomb interaction potential (see Remark [2.16\)](#page-13-2).
- 3. Third, the freedom of choice for the reference measure ℓ allows the study of Gibbs distributions defined on sets that have zero d-dimensional Lebesgue measure such as, for example, a non-smooth surface on R <sup>3</sup> or a fractal set like the Cantor dust in R 2 . A more specific example that often appears in complex potential theory is the case where W is the Coulomb potential, and ℓ is Lebesgue measure on some 1-dimensional subset of the complex plane C such as the unit circle.
- 4. Furthermore, we establish these LDPs not only with respect to the weak topology, but also with respect to a family of stronger topologies that include the p-Wasserstein topologies for p ≥ 1, thus resolving another open question raised in [\[9,](#page-37-0) Section 1.5.6]. The LDPs with respect to stronger topologies are used in Lemma 3.4 of [\[22\]](#page-38-1) (see also [\[21\]](#page-38-2)) to show that, for a large class of Hamiltonians, the sequence {x <sup>n</sup>}n∈<sup>N</sup> of Gibbs configurations satisfies the so-called "asymptotic thin-shell condition", which is of relevance in asymptotic geometric analysis and high-dimensional probability. Specifically, this condition stipulates that the sequence of scaled Euclidean norms of the random vectors satisfies an LDP, and was shown in [\[22\]](#page-38-1) (see Theorems 2.4, 2.6 and 2.8 therein) to imply that then the corresponding sequences of multi-dimensional random projections

of the random vectors also satisfy an LDP. This can be viewed as a non-universal large deviation counterpart of the universality result of [\[2\]](#page-37-3) that random projections of a high-dimensional measure whose Euclidean norms satisfy a certain concentration property called the "thin shell condition" have Gaussian fluctuations. As first observed in [\[16,](#page-38-3) [15\]](#page-37-4), LDPs are useful for describing non-universal features lower-dimensional projections that encode information about the original high-dimensional measures, which is of relevance in numerous applications. Since the mapping that takes a vector to its Euclidean norm is continuous in the Wasserstein-2 topology, the fact that {x <sup>n</sup>}n∈<sup>N</sup> satisfies the asymptotic thin shell condition can be deduced from the contraction principle and the LDPs (with respect to the 2-Wasserstein topology) for {x <sup>n</sup>}n∈<sup>N</sup> established in this article.

It is also worthwhile to mention that, in contrast to prior works, in this work the LDPs for all speeds and topologies are established using a common methodology.

#### <span id="page-4-0"></span>1.2 Discussion of related recent results

This article is a substantial generalization of the first version of this article [\[14\]](#page-37-5) and also resolves a minor technical issue therein. It contains significant extensions, the most important of which is to allow weakly confining potentials V . In the case limn→∞ βn/n = ∞ we show that although the entropic term disappears in the limit, its appearance in the pre-limit can guarantee the validity of the LDP in some cases when V does not satisfy limkxk→∞ V (x) = ∞ (see Section [5.4\)](#page-25-1). This result also highlights the intuitive nature of weak convergence methods, and more specifically the use of representations that are connected to the method, like the one in [\(5.4\)](#page-25-1). In addition, compared to the original version [\[14\]](#page-37-5), in the present article the illustrative examples have been significantly extended (see Section [2.4\)](#page-9-0), to include cases where V and W are not continuous, and heuristic arguments in [\[14\]](#page-37-5) related to the examples have been replaced here with rigorous proofs. Finally, some open problems have also been added, which can generate new directions for research.

Since the first version [\[14\]](#page-37-5) appeared, several authors have extended our work or used some of the arguments. In [\[18\]](#page-38-4) an LDP for a sequence of point processes defined by Gibbs measures on a compact orientable two-dimensional Riemannian manifold is studied. In [\[5,](#page-37-6) [19\]](#page-38-5), the connection between LDPs and Γ-convergence that was first highlighted in [\[23\]](#page-38-6) and subsequently implicitly exploited in our work, was furthered explored. We believe that this is a very natural connection and hypothesize that it can also lead to some new insights in the case where Assumption [C2](#page-8-1) is not satisfied. More recent work that appeared after the present version of this article was posted includes [\[10\]](#page-37-7), where the particular case of the Coulomb potential in dimension d = 2 is studied.

### <span id="page-4-1"></span>2 Assumptions and main results

This section is devoted to stating and discussion our main assumptions and results. Section [2.1](#page-5-0) introduced basic definitions and notation used throughout the article, and Sections [2.2](#page-6-0) and [2.3,](#page-8-0) present the main results for the case β<sup>n</sup> = n and β<sup>n</sup> → ∞, respectively. Corollaries of the main results and illustrative examples are presented in Section [2.4,](#page-9-0) and an outline of the rest of the article is given in Section [2.5.](#page-14-0)

First, we start by stating the assumptions on the potentials V and W that will hold throughout.

<span id="page-4-2"></span>Assumption A. The functions W : R <sup>d</sup> <sup>×</sup> <sup>R</sup> <sup>d</sup> <sup>→</sup> (−∞,∞] and <sup>V</sup> : <sup>R</sup> <sup>d</sup> <sup>→</sup> (−∞, <sup>+</sup>∞] are lsc on their respective domains. There exist 1 > a ≥ 0 and c ∈ R such that

<span id="page-4-3"></span>
$$
\int_{\mathbb{R}^d} \exp\left(- (1 - a)V\left(\mathbf{x}\right)\right) \ell(d\mathbf{x}) < \infty, \quad \inf_{\mathbf{x} \in \mathbb{R}^d} V\left(\mathbf{x}\right), \inf_{(\mathbf{x}, \mathbf{y}) \in \mathbb{R}^d \times \mathbb{R}^d} \left[W\left(\mathbf{x}, \mathbf{y}\right) + a\left(V\left(\mathbf{x}\right) + V\left(\mathbf{y}\right)\right)\right] > c. \tag{2.1}
$$

In addition, there exists a set A ∈ B(R d ) with ℓ(A) > 0 such that

<span id="page-4-4"></span>
$$
\int_{A\times A} (V(\mathbf{x}) + V(\mathbf{y}) + W(\mathbf{x}, \mathbf{y})) \ell(d\mathbf{x}) \ell(d\mathbf{y}) < \infty.
$$
\n(2.2)

Assumption [A](#page-4-2) guarantees that the Gibbs distribution given in [\(1.5\)](#page-2-2) is well defined. More precisely, [\(2.1\)](#page-4-3) guarantees that the measure is well defined and finite, and [\(2.2\)](#page-4-4) guarantees that the measure is not trivial.

<span id="page-5-3"></span>Remark 2.1. Under Assumption [A,](#page-4-2) without loss of generality, we can assume that

$$
\int_{\mathbb{R}^d} \exp(-(1-a)V(\mathbf{x})) \,\ell(d\mathbf{x}) = 1,
$$

because any constant added to V can be absorbed into Zn; see [\(1.5\)](#page-2-2). With some abuse of notation, we use e −(1−a)V ℓ to denote the probability measure e −(1−a)V (x) ℓ(dx).

#### <span id="page-5-0"></span>2.1 Notation and definitions

In this section, we provide some necessary definitions. Although some of the definitions will be given in their more general form, we would like to clarify that for our results, the underlying space S would be a separable metric space without any assumptions about its completeness. We recall the standard definition of the push forward operator #.

<span id="page-5-1"></span>Definition 2.2. Given measurable spaces (S, <sup>F</sup>) and (S, ˜ <sup>F</sup>˜), a measurable mapping <sup>f</sup> : <sup>S</sup> <sup>→</sup> <sup>S</sup>˜ and a measure <sup>µ</sup> : F → [0,∞], the pushforward of <sup>µ</sup> is the measure induced on (S, ˜ <sup>F</sup>˜) by <sup>µ</sup> under <sup>f</sup>, that is, the measure <sup>f</sup>#<sup>µ</sup> : F →˜ [0,∞] is given by

$$
(f_{\#}\mu)(B) = \mu\left(f^{-1}(B)\right) \text{ for } B \in \tilde{\mathcal{F}}.
$$

In other words, f#µ is the image measure of µ under f.

We next recall the definition of a rate function on a separable metric space S.

<span id="page-5-2"></span>Definition 2.3. Given a topological space S, a function H : S → [0,∞] is said to be a rate function if each level set {x : H(x) ≤ M}, M ∈ [0,∞), is compact.

Note that a function that satisfies the properties in Definition [2.3](#page-5-2) is sometimes referred to as a good rate function in the literature, as a way to highlight the compactness of the level sets and to distinguish it from lower semi-continuous functions that can be defined by the property of having closed level sets, but which can in some cases provide large deviation rates of decay. When not in the context of LDPs, a function that has the properties stated in Definition [2.3](#page-5-2) is also called a tightness function; a term that will be used extensively in the sequel. In contrast to much of the previous application of weak convergence methods in large deviations, here we do not assume S is complete. This will be convenient when dealing with topologies other than the weak topology.

We now recall the definition of an LDP for a sequence of probability measures on (S,B(S)).

Definition 2.4. Let {Rn} ⊂ P(S), let {αn} be a sequence of positive real numbers such that limn→∞ α<sup>n</sup> = ∞, and let H : S → [0,∞] be a rate function. The sequence {Rn} is said to satisfy a large deviation principle with speed {αn} and rate function H if for each E ∈ B(S),

$$
-\inf_{x\in E^{\circ}}\mathcal{H}(x) \leq \liminf_{n\to\infty} \alpha_n^{-1}\log(R_n(E)) \leq \limsup_{n\to\infty} \alpha_n^{-1}\log(R_n(E)) \leq -\inf_{x\in \overline{E}}\mathcal{H}(x),
$$

where E◦ and E¯ denote the interior and closure of E, respectively.

Let C(R d ) be the space of continuous functions on R d , and let Cb(R d ) denote the subspace of bounded functions in C(R d ). We endow P(R d ) with the topology of weak convergence and use <sup>w</sup>−→ to denote convergence with respect to this topology; recall that µ<sup>n</sup> <sup>w</sup>−→ <sup>µ</sup> if and only if for all <sup>f</sup> <sup>∈</sup> <sup>C</sup>b(<sup>R</sup> d ), R <sup>R</sup><sup>d</sup> f(x)µn(dx) → R <sup>R</sup><sup>d</sup> f(x)µ(dx). The L´evy-Prohorov metric d<sup>w</sup> metrizes the weak topology on P(R d ), and the space (P(R d ), dw) is Polish (see, e.g., Theorem 5 of Appendix III of [\[6\]](#page-37-8)). We also consider stronger topologies, parameterized by functions belonging to the following set:

<span id="page-6-1"></span>
$$
\Psi := \{ \psi \in C(\mathbb{R}^d) ; \psi \ge 0, \lim_{c \to \infty} \inf_{\mathbf{x}: \|\mathbf{x}\| = c} \psi(\mathbf{x}) = \infty \}.
$$
\n(2.3)

Given ψ ∈ Ψ, let

$$
\mathcal{P}_{\psi}(\mathbb{R}^d) := \left\{ \mu \in \mathcal{P}(\mathbb{R}^d) : \int_{\mathbb{R}^d} \psi(\mathbf{x}) \mu(d\mathbf{x}) < +\infty \right\}.
$$
 (2.4)

We endow P<sup>ψ</sup> R d with the metric

<span id="page-6-6"></span>
$$
d_{\psi}(\mu, \nu) := d_{\psi}(\mu, \nu) + \left| \int_{\mathbb{R}^d} \psi(\mathbf{x}) \mu(d\mathbf{x}) - \int_{\mathbb{R}^d} \psi(\mathbf{x}) \nu(d\mathbf{x}) \right|.
$$
 (2.5)

The space (Pψ(R d ), dψ) is a separable metric space (see Lemma [C.1](#page-32-1) for a proof).

Remark 2.5. (Alternative metrizations of the Wasserstein topology) When ψ(x) = kxk p for p ∈ [1,∞), with x ∈ R d , and k · k denoting the Euclidean norm, d<sup>ψ</sup> induces the p-Wasserstein topology (see [\[1,](#page-37-9) Remark 7.1.11]). Another metric that is commonly used to induce the p-Wasserstein topology on P(R d ) is dp(µ, ν) := infζ∈Π(µ,ν) R <sup>R</sup>d×R<sup>d</sup> ||x−y||<sup>p</sup> ζ(dx, dy), where Π(µ, ν) is the set of all measures in R <sup>2</sup><sup>d</sup> with first marginal µ and second marginal ν. Although Pψ(R d ) endowed with d<sup>p</sup> is complete and separable, we use the somewhat simpler metric d<sup>ψ</sup> defined for any ψ satisfying [\(2.3\)](#page-6-1), under which Pψ(R d ) is only separable, and not complete. For more information on the Wasserstein distance and its topological properties, the reader is referred to [\[28\]](#page-38-7); specifically, see Theorem 6.8 therein.

### <span id="page-6-0"></span>2.2 Results in the case β<sup>n</sup> = n

Our first result concerns the LDP for {Qn} with speed α<sup>n</sup> = β<sup>n</sup> = n. The rate function is expressed in terms of the following functionals. Given a ∈ [0, 1], for ζ ∈ P(R <sup>d</sup> <sup>×</sup> <sup>R</sup> d ), let

<span id="page-6-4"></span>
$$
\mathfrak{J}_a(\zeta) := \frac{1}{2} \int_{\mathbb{R}^d \times \mathbb{R}^d} \left( W(\mathbf{x}, \mathbf{y}) + aV(\mathbf{x}) + aV(\mathbf{y}) \right) \zeta(d\mathbf{x} d\mathbf{y}).\tag{2.6}
$$

Also, for a measure ν ∈ P(R d ), as usual we define the relative entropy functional by

$$
\mathcal{R}(\mu|\nu) := \begin{cases} \int_{\mathbb{R}^d} \frac{d\mu}{d\nu}(\mathbf{x}) \log \left(\frac{d\mu}{d\nu}(\mathbf{x})\right) \nu(d\mathbf{x}) & \text{if } \mu \ll \nu, \\ \infty & \text{otherwise,} \end{cases}
$$

where µ ≪ ν denotes that µ is absolutely continuous with respect to ν. Then, for µ ∈ P(R d ) let

<span id="page-6-3"></span>
$$
\mathcal{J}_a(\mu) := \mathfrak{J}_a(\mu \otimes \mu) = \frac{1}{2} \int_{\mathbb{R}^d \times \mathbb{R}^d} \left( W(\mathbf{x}, \mathbf{y}) + aV(\mathbf{x}) + aV(\mathbf{y}) \right) \mu \left( d\mathbf{x} \right) \mu \left( d\mathbf{y} \right), \tag{2.7}
$$

and

<span id="page-6-2"></span>
$$
\mathcal{I}(\mu) := \mathcal{R}\left(\mu|e^{-(1-a)V}\ell\right) + \mathcal{J}_a(\mu),\tag{2.8}
$$

Note that the lack of subscript on I in [\(2.8\)](#page-6-2) is justified because, as the following easily verifiable relation shows, I does not depend on the constant a:

$$
\mathcal{I}(\mu) = \mathcal{S}(\mu) + \mathcal{V}(\mu) + \mathcal{W}(\mu),
$$

where V, S,W : P(R d ) → (−∞,∞], are given by

<span id="page-6-5"></span>
$$
\mathcal{V}(\mu) := \int_{\mathbb{R}^d} V(\mathbf{x}) \, \mu(d\mathbf{x}), \quad \mathcal{S}(\mu) := \int_{\mathbb{R}^d} \frac{d\mu}{d\ell}(\mathbf{x}) \log \left(\frac{d\mu}{d\ell}(\mathbf{x})\right) \ell(d\mathbf{x}), \tag{2.9}
$$

and

$$
\mathcal{W}(\mu) := \frac{1}{2} \int_{\mathbb{R}^d \times \mathbb{R}^d} W(\mathbf{x}, \mathbf{y}) \mu(d\mathbf{x}) \mu(d\mathbf{y}). \tag{2.10}
$$

To establish the LDP with respect to stronger topologies dψ, ψ ∈ Ψ, we will need an additional condition, which we now state. Let Φ be the class of functions defined by

<span id="page-7-5"></span>
$$
\Phi := \left\{ \phi : \mathbb{R}_+ \mapsto \mathbb{R}; \phi \text{ is lsc and } \lim_{s \to \infty} \frac{\phi(s)}{s} = \infty \right\}.
$$
\n(2.11)

<span id="page-7-2"></span>Assumption B. There exists a lsc function γ : R <sup>d</sup> <sup>→</sup> <sup>R</sup>, of the form <sup>γ</sup>(x) = <sup>φ</sup> (<sup>ψ</sup> (x)), for some <sup>φ</sup> <sup>∈</sup> <sup>Φ</sup>, such that for the constant a in Assumption [A,](#page-4-2) and every µ ∈ P(R d ), we have

<span id="page-7-8"></span>
$$
\int_{\mathbb{R}^d} \gamma(\mathbf{x}) \,\mu\left(d\mathbf{x}\right) \le \inf_{\zeta \in \Pi(\mu,\mu)} \left\{ \mathfrak{J}_a\left(\zeta\right) + \mathcal{R}\left(\zeta \middle| e^{-(1-a)V} \ell \otimes e^{-(1-a)V} \ell\right) \right\}.
$$
\n(2.12)

The following lemma provides a more easily verifiable sufficient condition under which Assumption [B](#page-7-2) holds; its proof is deferred to Appendix [B.](#page-30-0) Recall the set Ψ defined in [\(2.3\)](#page-6-1).

<span id="page-7-1"></span>Lemma 2.6. Let V and W satisfy Assumptions [A,](#page-4-2) and let ψ ∈ Ψ satisfy

<span id="page-7-3"></span>
$$
\int_{\mathbb{R}^d \times \mathbb{R}^d} e^{\lambda(\psi(\mathbf{x}) + \psi(\mathbf{y}))} e^{-(V(\mathbf{x}) + V(\mathbf{y}) + W(\mathbf{x}, \mathbf{y}))} d\mathbf{x} d\mathbf{y} < \infty \tag{2.13}
$$

for all λ ∈ R. Then Assumption [B](#page-7-2) is satisfied for that ψ and some φ ∈ Φ.

We now state our first main result, whose proof is given in Section [4.](#page-17-0)

<span id="page-7-0"></span>Theorem 2.7. Let V and W satisfy Assumption [A,](#page-4-2) and for n ∈ N, let β<sup>n</sup> = n, let P<sup>n</sup> be defined as in [\(1.5\)](#page-2-2) and let Q<sup>n</sup> = (Ln)#Pn. Then {Qn} satisfies an LDP on (P R d , dw) with speed α<sup>n</sup> = β<sup>n</sup> = n and rate function

<span id="page-7-6"></span>
$$
\mathcal{I}_{\star}(\mu) := \mathcal{I}(\mu) - \inf_{\mu \in \mathcal{P}(\mathbb{R}^d)} \{ \mathcal{I}(\mu) \},\tag{2.14}
$$

where I is defined by [\(2.8\)](#page-6-2). Furthermore, if there exists ψ ∈ Ψ for which Assumption [B](#page-7-2) holds, then {Qn} satisfies an LDP on (Pψ(R d ), dψ) with rate function

<span id="page-7-7"></span>
$$
\mathcal{I}_{\star}^{\psi}(\mu) := \mathcal{I}(\mu) - \inf_{\mu \in \mathcal{P}_{\psi}(\mathbb{R}^d)} \{ \mathcal{I}(\mu) \}. \tag{2.15}
$$

In the case when W ≡ 0, Theorem [2.7](#page-7-0) recovers the well known Sanov's Theorem (see [\[11,](#page-37-10) Theorem 6.2.10] or [\[13,](#page-37-1) Theorem 2.2.1] for the LDP with respect to the weak topology and [\[27,](#page-38-8) Theorem 1.1] for the LDP with respect to the p-Wasserstein topology). In [\[27,](#page-38-8) Theorem 1.1] the authors prove that for any <sup>p</sup> <sup>∈</sup> [1,∞) and <sup>ψ</sup>(x) = ||x||<sup>p</sup> , if the following condition holds:

<span id="page-7-4"></span>
$$
\int_{\mathbb{R}^d \times \mathbb{R}^d} e^{\lambda \psi(\mathbf{x}) - V(\mathbf{x})} \ell(d\mathbf{x}) < +\infty \quad \forall \lambda > 0,
$$
\n(2.16)

then {Qn} satisfies an LDP in Pψ(R d ) with rate function R(µ|e −V ℓ), which corresponds to the case a = 0 in our setting. The bound [\(2.13\)](#page-7-3) implies Assumption [B,](#page-7-2) and can be viewed as a generalization of condition (1.3) of [\[27\]](#page-38-8) (which was shown in [\[27\]](#page-38-8) to be equivalent to [\(2.16\)](#page-7-4)) to the case when W 6= 0.

Next, if W is continuous and satisfies certain growth conditions on R <sup>d</sup> <sup>×</sup> <sup>R</sup> d , then the result can be obtained from the W = 0 (or Sanov's theorem) case by a simple application of Varadhan's lemma (see [\[11,](#page-37-10) Theorem 4.3.1] or [\[13,](#page-37-1) Theorem 1.2.1]). To the best of our knowledge, there are no general results in the literature that cover the case when W is both unbounded and discontinuous, and therefore Theorem [2.7](#page-7-0) is the first in that direction. Furthermore, Assumption [B](#page-7-2) provides a sufficient condition for the LDP to hold with respect to a rather large class of stronger topologies, which was useful for the verification of the asymptotic thin shell condition in [\[21,](#page-38-2) [22\]](#page-38-1).

## <span id="page-8-0"></span>2.3 Results in the case βn/n → ∞

Motivated by questions arising in random matrix theory, sampling and simulated annealing, several authors [\[3,](#page-37-11) [4,](#page-37-2) [9,](#page-37-0) [20,](#page-38-9) [24,](#page-38-10) [25\]](#page-38-11) have considered LDPs for {Qn} at specific speeds that are faster than n, such as βn/n log n → ∞ and β<sup>n</sup> = n 2 . Our second theorem presents a general result for speeds faster than n, that is, when βn/n → ∞, under Assumption [A](#page-4-2) and certain modified assumptions on V and W stated in Assumption C below. In what follows, we use J to denote the functional J<sup>1</sup> : P(R d ) → (−∞,∞] defined in [\(2.7\)](#page-6-3), with a = 1. Recall the set Φ defined in [\(2.11\)](#page-7-5), for a set A ⊂ R d , A6<sup>=</sup> is defined in [\(1.4\)](#page-2-4), and as usual let I<sup>A</sup> denote the indicator function, which assigns 1 to points in A and 0 otherwise.

<span id="page-8-2"></span>Assumption C. 1. There exist a lsc function γ : R <sup>d</sup> <sup>→</sup> <sup>R</sup> of the form <sup>γ</sup>(x) = <sup>φ</sup>(kxk) for some φ : R<sup>+</sup> 7→ R with lims→∞ φ(s) = ∞, a set A ∈ B(R d ), a sequence {rn} ⊂ (0,∞) with r<sup>n</sup> → ∞ and a constant C ∈ R, such that

<span id="page-8-5"></span>
$$
\gamma(\mathbf{x})I_{A^c}(\mathbf{x}) + \gamma(\mathbf{y})I_{A^c}(\mathbf{y}) \le V(\mathbf{x}) + V(\mathbf{y}) + W(\mathbf{x}, \mathbf{y}) + C,\tag{2.17}
$$

for every n ∈ N and x <sup>n</sup> <sup>∈</sup> (<sup>R</sup> nd)6<sup>=</sup>

<span id="page-8-7"></span>
$$
\int_{A_n^1} \gamma(\mathbf{x}) L_n(\mathbf{x}^n; d\mathbf{x}) \le \int_{(A_n^1 \times A_n^1)_{\neq}} \left( V(\mathbf{x}) + V(\mathbf{y}) + W(\mathbf{x}, \mathbf{y}) \right) L_n(\mathbf{x}^n; d\mathbf{x}) L_n(\mathbf{x}^n; d\mathbf{y}) + C, \quad (2.18)
$$

and

<span id="page-8-6"></span>
$$
\sup_{n \in \mathbb{N}} \frac{n}{\beta_n} \log \left( \int_{A_n^2} e^{\frac{\beta_n}{n} \gamma(\mathbf{x}) - (1-a)V(\mathbf{x})} \ell(d\mathbf{x}) \right) < C,\tag{2.19}
$$

where A<sup>1</sup> n := <sup>A</sup> <sup>∩</sup> <sup>B</sup> (0, rn) and <sup>A</sup><sup>2</sup> n := A \ B (0, rn).

- <span id="page-8-1"></span>2. For each <sup>µ</sup> ∈ P R d such that J (µ) < +∞, there is a sequence {µn} ⊂ P(R d ), with each µ<sup>n</sup> ≪ ℓ such that µ<sup>n</sup> <sup>w</sup><sup>→</sup> <sup>µ</sup>, and <sup>J</sup> (µn) → J (µ) as <sup>n</sup> → ∞.
- <span id="page-8-4"></span>3. The function γ in part 1. above is of the form γ(x) = φ(ψ(x)), for some φ ∈ Φ.

When A = ∅, then Assumption [C1](#page-8-2) collapses to the following more easily verifiable condition:

<span id="page-8-3"></span>Assumption C'1. There exists a lsc function γ : R <sup>d</sup> <sup>→</sup> <sup>R</sup> of the form <sup>γ</sup>(x) = <sup>φ</sup>(kxk), where <sup>φ</sup> : <sup>R</sup><sup>+</sup> <sup>→</sup> <sup>R</sup> satisfies lims→+<sup>∞</sup> φ (s) = +∞, such that

$$
V(\mathbf{x}) + V(\mathbf{y}) + W(\mathbf{x}, \mathbf{y}) \ge \gamma(\mathbf{x}) + \gamma(\mathbf{y}).
$$
\n(2.20)

Assumption [C'1](#page-8-3) covers all of the well known examples in the literature and the majority of generalizations that we provide in this paper. The main reason we introduce the more complicated Assumption [C1,](#page-8-2) is that we want to include cases involving higher dimensional spaces (d ≥ 3), where the confining potential V does not necessarily satisfy limn→∞ V (xn) = ∞ when kxnk → ∞, an assumption that is used in both [\[9\]](#page-37-0) and [\[25\]](#page-38-11), which cover cases where the rate function has minimizers with compact support. For special cases in two dimensions where minimizers do not have compact support, see [\[20\]](#page-38-9) and Remark [2.16.](#page-13-2)

Assumption [C2](#page-8-1) is used in Section [5.4](#page-28-0) to establish the Laplace principle upper bound. For examples of pairs (V, W) that satisfy Assumption [C2,](#page-8-1) the reader is directed to [\[9,](#page-37-0) Proposition 2.8]. Finally, Assumption [C3](#page-8-4) is used to obtain the result for the stronger topologies.

Remark 2.8. (On the entropic term in the case βn/n → ∞. ) It is worthwhile to emphasize that, in the case where βn/n → ∞, although the entropic term disappears from the rate function and is ignored in almost all other proofs we found in the literature, in our proof approach (see in particular, Lemma [5.2\)](#page-26-0) the relative entropy functional still plays an important role in the intermediate steps. In particular, it helps us establish tightness and prove the LDP under weaker conditions on V than those assumed in the literature.

We now state our second main result, whose proof is deferred to Section [5.](#page-24-0)

<span id="page-9-2"></span>Theorem 2.9. Consider a sequence {βn} such that limn→∞ βn/n = ∞, and let V and W satisfy Assumptions [A,](#page-4-2) [C1](#page-8-2) and [C2.](#page-8-1) For n ∈ N, let P<sup>n</sup> be as in [\(1.5\)](#page-2-2) and Q<sup>n</sup> = (Ln)#Pn. Then {Qn} satisfies an LDP on P(R d ) with speed α<sup>n</sup> = β<sup>n</sup> and rate function

<span id="page-9-4"></span>
$$
\mathcal{J}_{\star}(\mu) = \mathcal{J}(\mu) - \inf_{\mu \in \mathcal{P}(\mathbb{R}^d)} \{ \mathcal{J}(\mu) \},\tag{2.21}
$$

where J is the functional J<sup>1</sup> given in [\(2.7\)](#page-6-3). Furthermore, if there exists ψ ∈ Ψ for which Assumption C[3](#page-8-4) holds, then {Qn} satisfies an LDP on (Pψ(R d ), dψ) with the rate function

<span id="page-9-5"></span>
$$
\mathcal{J}_{\star}^{\psi}(\mu) := \mathcal{J}(\mu) - \inf_{\mu \in \mathcal{P}_{\psi}(\mathbb{R}^d)} \{ \mathcal{J}(\mu) \}. \tag{2.22}
$$

A direct consequence of Theorems [2.7](#page-7-0) and [2.9](#page-9-2) is the following.

Remark 2.10. ( LDPs for empirical moments) Suppose V and W satisfy Assumption [A,](#page-4-2) and Assumption [B](#page-7-2) holds with <sup>ψ</sup>(x) := ||x||<sup>p</sup> for some <sup>p</sup> <sup>≥</sup> 1. Let (X<sup>n</sup> 1 , . . . , X<sup>n</sup> n ) be distributed according to P <sup>n</sup> and for any q ≤ p, let Y n q := <sup>1</sup> n P<sup>n</sup> <sup>i</sup>=1 <sup>|</sup>X<sup>n</sup> i | q , n ∈ N. Then Theorem [2.7,](#page-7-0) the continuity of the map µ 7→ R ||x||qµ(dx) in the Wasserstein-p topology and the contraction principle [\[11,](#page-37-10) Theorem 4.2.1] together show that {Y n q } satisfies an LDP with speed β<sup>n</sup> = n and rate function

$$
H(y) := \inf_{\mu \in \mathcal{P}(\mathbb{R}^d)} \left\{ \mathcal{I}_{\star}^{\psi}(\mu) : y = \int_{\mathbb{R}^d} ||\mathbf{x}||^q \mu(dx) \right\}.
$$

Likewise, if <sup>V</sup> and <sup>W</sup> satisfy Assumptions [A,](#page-4-2) [C1](#page-8-2) and [C2,](#page-8-1) and Assumption [C3](#page-8-4) holds with <sup>ψ</sup>(x) := ||x||<sup>p</sup> and βn/n → ∞ as n → ∞, then Theorem [2.9](#page-9-2) shows that {Y n q } satisfies an LDP with speed β<sup>n</sup> and rate function <sup>H</sup>˜ (y) = infµ∈P(Rd){J <sup>ψ</sup> <sup>⋆</sup> (µ) : y = R <sup>R</sup><sup>d</sup> ||x||qµ(dx)}.

#### <span id="page-9-0"></span>2.4 Corollaries of the main results

In this section, we provide several illustrative examples for which the assumptions of Theorems [2.7](#page-7-0) and [2.9](#page-9-2) can be verified.

#### <span id="page-9-1"></span>2.4.1 Known examples covered by our assumptions

We start by considering potentials that have already been investigated in the literature for the weak topology, and showing that they satisfy our assumptions. In what follows, let K<sup>∆</sup> : R d 7→ R be the Coulomb potential given by K∆(x) = −|x| when d = 1, K∆(x) = − log(||x||) when d = 2 and K∆(x) = <sup>1</sup>/||x||d−<sup>2</sup> when d > 2.

<span id="page-9-3"></span>Example 2.11. Let <sup>ℓ</sup> be Lebesgue measure. The pair (V, W) given by <sup>V</sup> (x) = ||x||<sup>p</sup> for some p > 1 and W(x, y) = K∆(x − y) satisfies Assumptions [A,](#page-4-2) [C'1](#page-8-3) and [C3,](#page-8-4) and Assumptions [B](#page-7-2) and [C2](#page-8-1) also hold with <sup>ψ</sup>(x) = ||x||<sup>q</sup> , q < p.

Proof of Example [2.11.](#page-9-3) For d ≥ 3, it is trivial to verify that Assumption [A](#page-4-2) is satisfied with a = 0. For the case d = 2, we pick a = 1 2 , and observe that <sup>1</sup> 4 kxk <sup>p</sup> + 1 4 kyk <sup>p</sup> <sup>−</sup> log <sup>k</sup><sup>x</sup> <sup>−</sup> <sup>y</sup><sup>k</sup> is bounded from below by a constant c, since z 7→ − log z is convex and lims→∞(s <sup>p</sup> <sup>−</sup> log <sup>s</sup>) = <sup>∞</sup>. For the case <sup>d</sup> = 1, we observe that K∆(x) is continuous and also <sup>1</sup> 4 |x| <sup>p</sup> + 1 4 |y| <sup>p</sup> − |<sup>x</sup> <sup>−</sup> <sup>y</sup>| ≥ <sup>1</sup> 4 |x| <sup>p</sup> + 1 4 |y| <sup>p</sup> − |x| − |y<sup>|</sup> is bounded from below by a constant c, since lims→∞( 1 4 s <sup>p</sup> <sup>−</sup> <sup>s</sup>) = <sup>∞</sup>. We verify Assumption [C'1](#page-8-3) by picking <sup>φ</sup>(s) = <sup>1</sup> 4 s <sup>p</sup> + C, ¯ where C¯ is a suitable constant. Finally, it is also easy to see that the pair (V, W) satisfies Assumptions [B](#page-7-2) and [C3](#page-8-4) with <sup>ψ</sup>(x) = ||x||<sup>q</sup> , q < p, by applying Lemma [2.6](#page-7-1) for the first case and by picking φ(s) = <sup>1</sup> 4 s p/q + C, ¯ where C¯ is a suitable constant, for the second. Verification of Assumption [C2](#page-8-1) is a direct application of point (3) in [\[9,](#page-37-0) Proposition 2.8].

Example [2.11](#page-9-3) shows, in particular, that our assumptions are satisfied in the cases covered in [\[9\]](#page-37-0), including the popular case studied in [\[9,](#page-37-0) [4,](#page-37-2) [20,](#page-38-9) [24\]](#page-38-10), of V (x) = kxk 2 , W(x, y) = − log(x − y) and ℓ being Lebesgue measure.

#### <span id="page-10-0"></span>2.4.2 Non-diverging, weakly confining potentials

Given Assumption [A,](#page-4-2) Assumption [C'1](#page-8-3) is, at least seemingly, weaker than the condition limkxk→∞ V (x) = <sup>+</sup><sup>∞</sup> imposed in [\[9\]](#page-37-0). This can be directly seen if one takes <sup>φ</sup>(t) = (1−a) 2 infkxk=<sup>t</sup> V (x) + C ′ , where C ′ is chosen accordingly. However, the two assumptions have similar origins. More specifically, since W, V generate H<sup>n</sup> by a linear combination, one can transfer the confining attributes of V to W by taking for example any V ≥ 0 such that e −V ℓ is a probability measure and W(x, y) = kxk <sup>2</sup> <sup>+</sup> <sup>k</sup>y<sup>k</sup> 2 . The important point is that for these cases, W(x, y) + V (x) + V (y) is penalizing large values of kxk and kyk.

In [\[25,](#page-38-11) p. 38] there is an intuitive explanation for how this containment can be applied for the case where V is superlinear and W is the Coulomb potential in order to prove the LDP. The proof is based on the idea that in a closed subset of P(R d ), the minimizers of the rate function J can be approximated by minimizers of H<sup>n</sup> when n is sufficiently large. The approximation property is a consequence of the Γ−convergence of H<sup>n</sup> to J (see [\[7\]](#page-37-12)) together with the "coercivity" of H<sup>n</sup> (i.e., H<sup>n</sup> has minimizers in every closed set). To establish these properties of Hn, the confining properties of V play a crucial role.

We now provide the following example.

<span id="page-10-1"></span>Example 2.12. Let q > 1, d = 3, W (x, y) = 2/kx − yk, ℓ be Lebesgue measure and let V be given by

$$
V(\mathbf{x}) = \begin{cases} 0 & \mathbf{x} \in B_{\mathbf{z}} := B(\mathbf{z}, a_{\mathbf{z}}) = \{\mathbf{x} \in \mathbb{R}^3 : ||\mathbf{x} - \mathbf{z}|| \le a_{\mathbf{z}}\} \text{ for some } \mathbf{z} \in \mathbb{Z}^3, \\ ||\mathbf{x}||^q & otherwise, \end{cases}
$$

where the constants {az} satisfy a<sup>z</sup> ≤ e −3kzk 2q+3 , z ∈ Z 3 . Then for β<sup>n</sup> = n 2 , Assumption [C1](#page-8-2) and Assumption [C3](#page-8-4) hold with <sup>A</sup> <sup>=</sup> <sup>∪</sup>z∈Z<sup>3</sup>B(z, az), <sup>r</sup><sup>n</sup> <sup>=</sup> <sup>q</sup>+3<sup>√</sup> n, and φ(x) = <sup>1</sup> 2 x q . Finally, no minimizer of the rate function J<sup>∗</sup> has compact support.

Remark 2.13. For this example there are non-trivial regions of R 2d extending infinity on which W(x, y)+ V (x) +V (y) is close to zero, so there is not an obvious confining property. Also, since J is a rate function it exhibits minimizers on every closed ball <sup>B</sup>¯ of <sup>P</sup>(R<sup>d</sup> ). In contrast, H<sup>n</sup> not only does not have minimizers, but also

$$
\sup_{n \in \mathbb{N}} \inf_{\{\mathbf{x}^n \in (\mathbb{R}^{nd}) \neq : L_n(\mathbf{x}^n; \cdot) \in \bar{\mathcal{B}}\}} H_n < \inf_{\mu \in \bar{\mathcal{B}}} \mathcal{J}.\tag{2.23}
$$

However, for this example the LDP holds for example in the case β<sup>n</sup> = n 2 .

Remark 2.14. We can modify Example [2.12](#page-10-1) slightly to take V to be continuous, for example, if we set V equal to zero only in B(z, az/2), equal to kxk <sup>q</sup> outside <sup>∪</sup>z∈Z<sup>3</sup>B(z, az), and use Tietze's extension theorem to extend it to a continuous function. For such a continuous V , it is trivial to establish Assumption [C2](#page-8-1) by applying the results in [\[9,](#page-37-0) Proposition 2.8]. It will be clear from the proof of Example [2.12](#page-10-1) below that Assumptions [C1](#page-8-2) and [C3](#page-8-4) also continue to hold with this modification since V remains positive. Assumption [C2](#page-8-1) can be also proved directly for our initial example (with discontinuous V ) in a straightforward manner. We omit the proof.

Proof of Example [2.12.](#page-10-1) We start by verifying Assumption [C1,](#page-8-2) namely inequalities [\(2.17\)](#page-8-5)–[\(2.19\)](#page-8-6). Let γ¯(x) := <sup>1</sup> 2 ||x||<sup>q</sup> . It follows immediately from the definitions that [\(2.17\)](#page-8-5) holds with C = 0 and γ = C ′γ¯ for any C ′ <sup>≤</sup> 1. Next, let <sup>n</sup> <sup>∈</sup> <sup>N</sup>, and let <sup>A</sup><sup>n</sup> 1 := <sup>A</sup> <sup>∩</sup> <sup>B</sup>(0, rn), <sup>A</sup><sup>n</sup> <sup>2</sup> = A \ B(0, rn) be as in Assumption [C1.](#page-8-2) We split the set Z <sup>3</sup> <sup>∩</sup> <sup>A</sup><sup>n</sup> 1 , into two set Z n 1 and Z n 2 : Let Z n 1 contain the cubic integers Z <sup>3</sup> <sup>∩</sup> <sup>A</sup><sup>n</sup> 1 for which <sup>L</sup>n(B<sup>z</sup> <sup>∩</sup> <sup>A</sup><sup>n</sup> 1 ) ≤ 1 n and let Z n 2 contain the cubic integers for which <sup>L</sup>n(B<sup>z</sup> <sup>∩</sup> <sup>A</sup><sup>n</sup> 1 ) ≥ 2 n . The idea is to choose the cardinality |Z n 1 | sufficiently small such that particles in the corresponding sets do not contribute much to the interaction energy, and at the same time, choose the balls around Z n 2 to be so small that the pairs of particles that are in one of these sets create a significant interaction energy. We now verify [\(2.18\)](#page-8-7). Fix x <sup>n</sup> <sup>∈</sup> (<sup>R</sup> dn)6<sup>=</sup> and denote L<sup>n</sup> := Ln(x n , ·). For z ∈ Z n 2 , since W(x, y) = 2/||x−y|| ≥ 1/a<sup>z</sup> when x, y ∈ Bz, we have

$$
\int_{\left(B_{\mathbf{z}}\cap A_{1}^{n}\right)\times\left(B_{\mathbf{z}}\cap A_{1}^{n}\right)_{\neq}} W\left(\mathbf{x},\mathbf{y}\right)L_{n}\left(d\mathbf{x}\right)L_{n}\left(d\mathbf{y}\right) \geq \frac{2}{a_{\mathbf{z}}} \frac{1}{2} L_{n}^{2}(B_{\mathbf{z}}\cap A_{1}^{n}) = \frac{L_{n}^{2}(B_{\mathbf{z}}\cap A_{1}^{n})}{a_{\mathbf{z}}}.
$$

Combining this with the nonnegativity of W, the Cauchy-Schwarz inequality (in the third inequality below), the summability of ||z||2qaz, z <sup>∈</sup> <sup>Z</sup> 3 (in the fourth inequality), and using C ′′ > 0 to denote a constant that may change from line to line, we obtain

$$
\int_{(A_1^n \times A_1^n)_{\neq}} W(\mathbf{x}, \mathbf{y}) L_n(d\mathbf{x}) L_n(d\mathbf{y}) \ge \sum_{\mathbf{z} \in Z_2^n} \int_{(B_{\mathbf{z}} \cap A_1^n) \times (B_{\mathbf{z}} \cap A_1^n)_{\neq}} W(\mathbf{x}, \mathbf{y}) L_n(d\mathbf{x}) L_n(d\mathbf{y})
$$
\n
$$
\ge \sum_{\mathbf{z} \in Z_2^n} \frac{L_n^2(B_{\mathbf{z}} \cap A_1^n)}{a_{\mathbf{z}}}
$$
\n
$$
\ge \frac{\left(\sum_{\mathbf{z} \in Z_2^n} L_n(B_{\mathbf{z}} \cap A_1^n) \|\mathbf{z}\|^q\right)^2}{\sum_{\mathbf{z} \in Z_2^n} \|\mathbf{z}\|^{2q} a_{\mathbf{z}}}
$$
\n
$$
\ge C'' \left(\sum_{\mathbf{z} \in Z_2^n} L_n(B_{\mathbf{z}} \cap A_1^n) \|\mathbf{z}\|^q\right)^2
$$
\n
$$
\ge C'' \left(\int_{\bigcup_{\mathbf{z} \in Z_2^n} B_{\mathbf{z}} \cap A_1^n} \|\mathbf{x}\|^q L_n(d\mathbf{x})\right)^2.
$$

Expanding the last term and using the relations s <sup>2</sup> <sup>≥</sup> <sup>s</sup> <sup>−</sup> 1, <sup>|</sup><sup>Z</sup> n 1 | ≤ r 3 n , and <sup>r</sup><sup>n</sup> <sup>=</sup> <sup>q</sup>+3<sup>√</sup> n, we see that the left-hand side above is bounded below by

$$
C''\left(\int_{\substack{\bigcup\limits_{\mathbf{z}\in Z_2^n}}B_{\mathbf{z}}\cap A_1^n}\|\mathbf{x}\|^qL_n(d\mathbf{x})+\int_{\substack{\bigcup\limits_{\mathbf{z}\in Z_1^n}}B_{\mathbf{z}}\cap A_1^n}\|\mathbf{x}\|^qL_n(d\mathbf{x})-\left|Z_1^n\right| \frac{r_n^q}{n}\right)^2\geq C''\left(\int_{A_1^n}\|\mathbf{x}\|^qL_n(d\mathbf{x})-\frac{r_n^{q+3}}{n}-1\right)^q\\ =C''\int_{A_1^n}\bar{\gamma}(\mathbf{x})L_n(d\mathbf{x})-2C''.
$$

This implies that [\(2.18\)](#page-8-7) holds with γ = C ′γ¯ = min(C ′′ , 1)¯γ. Lastly, to prove [\(2.19\)](#page-8-6), recalling that β<sup>n</sup> = n 2 , r<sup>n</sup> <sup>=</sup> <sup>q</sup>+3<sup>√</sup> n and V = 0 on the set A, we have for any a ∈ [0, 1),

$$
\frac{n}{\beta_n} \int_{A_n^2} e^{\frac{\beta_n}{n} \gamma(\mathbf{x}) - (1-a)V(\mathbf{x})} \ell(d\mathbf{x}) \leq \frac{1}{n} \sum_{\mathbf{z} \in (\mathbb{Z}^3 \backslash B(0,r_n))} \int_{A_n^2 \cap B_{\mathbf{z}}} e^{n||\mathbf{x}||^q} d\mathbf{x}
$$
  
\n
$$
\leq \frac{1}{n} \sum_{\mathbf{z} \in (\mathbb{Z}^3 \backslash B(0,r_n))} e^{n2||\mathbf{z}||^q} a_{\mathbf{z}}
$$
  
\n
$$
\leq \frac{1}{n} \sum_{\mathbf{z} \in (\mathbb{Z}^3 \cap B^c(0,r_n))} e^{n2||\mathbf{z}||^q} e^{-3||\mathbf{z}||^{2q+3}}
$$
  
\n
$$
\leq \frac{1}{n} \sum_{\mathbf{z} \in (\mathbb{Z}^3 \cap B^c(0,r_n))} e^{n2||\mathbf{z}||^q} e^{-3n||\mathbf{z}||^q},
$$

which converges to zero as n → ∞, and hence, [\(2.19\)](#page-8-6) follows. This concludes the proof of Assumption [C1,](#page-8-2) and also verifies Assumption [C3](#page-8-4) for any <sup>ψ</sup> <sup>∈</sup> Ψ such that maxx:||x||=<sup>m</sup> <sup>ψ</sup>(x)/m<sup>q</sup> <sup>→</sup> 0.

We now argue by contradiction to prove that J (equivalently, J∗) does not have any minimizers with compact support. Let µmin be a minimizer with compact support K that is contained in B(0, R) for some R ∈ N. Let ˜z = (6R, 0, 0). We pick ˜x ∈ K such that µmin(B(˜x, a˜z)) > 0, and by choosing R sufficiently large so that a˜z is sufficiently small, we can assume without loss of generality that

<span id="page-12-0"></span>
$$
0 < \mu_{\min}(B(\tilde{\mathbf{x}}, a_{\tilde{\mathbf{z}}})) < 1. \tag{2.24}
$$

We define a new measure µ ∗ min := (µmin)|K\B(˜x,a˜z) + µ˜z, where µ˜z is the measure that minimizes the energy R B˜z×B˜z W(x, y)µ(dx)µ(dy) amongst all measures µ on R <sup>3</sup> with support in B˜z that have µ(B˜z) = µmin(B(˜x, a˜z)).

We now show that J (µ ∗ min) < J (µmin). First, note that since V is zero on the support of µ˜z,

$$
\mathcal{V}(\mu_{\min}) = \int_{\mathbb{R}^d} V(\mathbf{x}) \mu_{\min}(d\mathbf{x}) = \int_{\mathbb{R}^d \backslash B(\tilde{\mathbf{x}},a_{\tilde{\mathbf{z}}})} V(\mathbf{x}) \mu_{\min}(d\mathbf{x}) + \int_{B(\tilde{\mathbf{x}},a_{\tilde{\mathbf{z}}})} V(\mathbf{x}) \mu_{\min}(d\mathbf{x})
$$
$$
\geq \int_{\mathbb{R}^d} V(\mathbf{x}) (\mu_{\min})_{|_{K \backslash B(\tilde{\mathbf{x}},a_{\tilde{\mathbf{z}}})}} (d\mathbf{x}) + \int_{\mathbb{R}^d} V(\mathbf{x}) \mu_{\tilde{\mathbf{z}}}(d\mathbf{x}) = \mathcal{V}(\mu_{\min}^*).
$$

Next, by the symmetry and nonnegativity of W, we have

$$
\mathcal{W}(\mu_{\min}) = \int_{\mathbb{R}^d \times \mathbb{R}^d} W(\mathbf{x}, \mathbf{y}) \mu_{\min}(d\mathbf{x}) \mu_{\min}(d\mathbf{y}) = \widetilde{W}_1 + \widetilde{W}_2 + \widetilde{W}_3,
$$

where

$$
\widetilde{W}_1 := \int_{(\mathbb{R}^d \backslash B(\tilde{\mathbf{x}},a_{\tilde{\mathbf{z}}})) \times (\mathbb{R}^d \backslash B(\tilde{\mathbf{x}},a_{\tilde{\mathbf{z}}}))} W(\mathbf{x}, \mathbf{y}) \mu_{\min}(d\mathbf{x}) \mu_{\min}(d\mathbf{y}),
$$
\n
$$
\widetilde{W}_2 := \int_{B(\tilde{\mathbf{x}},a_{\tilde{\mathbf{z}}}) \times B(\tilde{\mathbf{x}},a_{\tilde{\mathbf{z}}})} W(\mathbf{x}, \mathbf{y}) \mu_{\min}(d\mathbf{x}) \mu_{\min}(d\mathbf{y}),
$$
\n
$$
\widetilde{W}_3 := 2 \int_{(\mathbb{R}^d \backslash B(\tilde{\mathbf{x}},a_{\tilde{\mathbf{z}}})) \times B(\tilde{\mathbf{x}},a_{\tilde{\mathbf{z}}})} W(\mathbf{x}, \mathbf{y}) \mu_{\min}(d\mathbf{x}) \mu_{\min}(d\mathbf{y}).
$$

Now, since µmin has support in K, we have

$$
\widetilde{W}_1 = \int_{\mathbb{R}^d \times \mathbb{R}^d} W(\mathbf{x}, \mathbf{y}) (\mu_{\min})_{|_{K \backslash B(\tilde{\mathbf{x}},a_{\tilde{\mathbf{z}}})}} (d\mathbf{x}) (\mu_{\min})_{|_{K \backslash B(\tilde{\mathbf{x}},a_{\tilde{\mathbf{z}}})}} (d\mathbf{y}).
$$

The definition of µ˜z and the fact that W(x, y) = W(x+˜z−z, y+˜z−z) ≥ 0 for every x, y, imply

$$
\widetilde{W}_2 \ge \int_{B_{\tilde{\mathbf{z}}} \times B_{\tilde{\mathbf{z}}}} W(\mathbf{x}, \mathbf{y}) \mu_{\tilde{\mathbf{z}}}(d\mathbf{x}) \mu_{\tilde{\mathbf{z}}}(d\mathbf{y}) = \int_{\mathbb{R}^d \times \mathbb{R}^d} W(\mathbf{x}, \mathbf{y}) \mu_{\tilde{\mathbf{z}}}(d\mathbf{x}) \mu_{\tilde{\mathbf{z}}}(d\mathbf{y}).
$$

Also, since W(x, y) = 2/||x − y||, µmin has support in K ⊂ B(0, R) and B˜z ∩ B(0, 5R) = ∅, we have ||x − y|| ≤ 2R for x, y ∈ K, and ||x − y|| ≥ 4R for x ∈ K, y ∈ B˜z. Therefore, we have

$$
\widetilde{W}_{3} \geq \frac{2}{R} \mu_{\min}(\mathbb{R}^{d} \setminus B(\tilde{\mathbf{x}}, a_{\tilde{\mathbf{z}}})) \mu_{\min}(B(\tilde{\mathbf{x}}, a_{\tilde{\mathbf{z}}}))
$$
\n
$$
= \frac{1}{R} \mu_{\min}(K \setminus B(\tilde{\mathbf{x}}, a_{\tilde{\mathbf{z}}})) \mu_{\min}(B(\tilde{\mathbf{x}}, a_{\tilde{\mathbf{z}}})) + \frac{1}{R} \mu_{\min}(\mathbb{R}^{d} \setminus B(\tilde{\mathbf{x}}, a_{\tilde{\mathbf{z}}})) \mu_{\min}(B(\tilde{\mathbf{x}}, a_{\tilde{\mathbf{z}}}))
$$
\n
$$
\geq 2 \int_{\mathbb{R}^{d} \times \mathbb{R}^{d}} W(\mathbf{x}, \mathbf{y}) (\mu_{\min})_{|_{K \setminus B(\tilde{\mathbf{x}}, a_{\tilde{\mathbf{z}}})}(d\mathbf{x}) \mu_{\tilde{\mathbf{z}}}(d\mathbf{y}) + \frac{1}{R} \mu_{\min}(\mathbb{R}^{d} \setminus B(\tilde{\mathbf{x}}, a_{\tilde{\mathbf{z}}})) \mu_{\min}(B(\tilde{\mathbf{x}}, a_{\tilde{\mathbf{z}}})).
$$

Combining the above relations, recalling that µ ∗ min := (µmin)|K\B(z,a˜z) + µ˜z, and invoking [\(2.24\)](#page-12-0), we conclude that

$$
\mathcal{W}(\mu_{\min}) \geq \mathcal{W}(\mu_{\min}^*) + \frac{1}{R} \mu_{\min}(\mathbb{R}^d \setminus B(\tilde{\mathbf{x}}, a_{\tilde{\mathbf{z}}})) \mu_{\min}(B(\tilde{\mathbf{x}}, a_{\tilde{\mathbf{z}}})) > \mathcal{W}(\mu_{\min}^*).
$$

Since we proved earlier that V(µmin) ≥ V(µ ∗ min), we conclude that J (µmin) > J (µ ∗ min), which contradicts that µmin is a minimizer of J .

Unlike Assumption [C](#page-8-3) ′1 (and most conditions imposed in the literature), which holds independently of {βn}, Assumption C[1](#page-8-2) is {βn} dependent. More specifically, for a fixed n, one can pick β<sup>n</sup> sufficiently large that (by the Laplace principle) the measure P<sup>n</sup> in [\(1.5\)](#page-2-2) mainly charges configurations that are nearinfimizers of Hn, which (as noted above) have strictly smaller values than the minimizer of J . In these cases, the LDP could not possibly hold in P(R d ) with rate function J⋆. One might expect that if J (the anticipated rate function) is a tightness function, then the LDP will hold for all speeds bigger than n. However, the comments above show that this is not true, and it is possible that J is a tightness function but the LDP does not hold on P(R d ) with rate function J . It is likely nevertheless, that a non-trivial LDP still holds true on some compactified space like P(R <sup>d</sup> ∪ {∞}). The following natural questions arise.

Open problem 2.15. When potentials are non-diverging, what is the right space to prove LDPs when the sequence {βn} diverges so fast that Assumption [C1](#page-8-2) is not satisfied, and are there different rate functions depending on the rate of divergence of {βn}? Also, does there exist a critical speed {β ∗ n } such that if the LDP holds in P(R d ) for {β ∗ <sup>n</sup>} then it also holds for every sequence {βn} with <sup>β</sup> ∗ n <sup>β</sup><sup>n</sup> → ∞ and <sup>β</sup><sup>n</sup> <sup>n</sup> → ∞?

<span id="page-13-2"></span>Remark 2.16 (Weak confinement on R 2 ). Another example in which the rate function J was shown to have a minimizer that does not have compact support can be found in [\[20\]](#page-38-9) or in the more recent [\[10\]](#page-37-7), where the particular case of the Coulomb potential in dimension d = 2 is studied. The proofs in [\[20\]](#page-38-9) are based on specific properties of the Coulomb potential − log |x − y| and the complex plane. Our result works for more general W, d, βn, and topological spaces Pψ(R d ). We expect that the weak convergence methods of [\[13\]](#page-37-1) that we use here can be used to study other problems with weakly confining potentials.

#### <span id="page-13-0"></span>2.4.3 Discontinuous interaction potentials

Our assumptions are also satisfied for cases where either V and/or W are discontinuous. Example [2.12](#page-10-1) already provides one example where V is discontinuous. We now given another illustrative example where W is discontinuous.

<span id="page-13-1"></span>Example 2.17. Suppose V (x) = kxk 2 , ℓ is Lebesgue measure, and

$$
W(\mathbf{x}, \mathbf{y}) = \sum_{i=1}^{N} I_{B_i}(\mathbf{x}) I_{B_i}(\mathbf{y}) h_i(\mathbf{x}, \mathbf{y}),
$$

where B<sup>i</sup> = B(x<sup>i</sup> , Ri), with R<sup>i</sup> > 0, x<sup>i</sup> ∈ R d , i = 1, . . . , N, is a collection of open balls with the property that the minimum distance between any two balls is D > 0, and each h<sup>i</sup> : R <sup>d</sup> <sup>×</sup> <sup>R</sup> <sup>d</sup> <sup>→</sup> <sup>R</sup><sup>+</sup> ∪ {∞} is any l.s.c. function for which Assumptions [A](#page-4-2) and C[2](#page-8-1) hold. Then Assumptions [A,](#page-4-2) [C'1](#page-8-3) and [C2](#page-8-1) are satisfied for (V, W).

Before we provide a justification of our assertions, note that in this example W can be interpreted as an interaction that takes place only when both particles are inside the same ball B<sup>i</sup> . For visualization purposes one can take h<sup>i</sup> = K<sup>∆</sup> for every i, with K<sup>∆</sup> from Example [2.11.](#page-9-3) A situation like this can arise with an electric potential between particles that are positioned in different regions with isolating boundaries.

Proof of Example [2.17.](#page-13-1) Since each h<sup>i</sup> satisfies Assumption [A,](#page-4-2) we get that Assumption [A](#page-4-2) holds for (V, W) with a = 0, and Assumption [C'1](#page-8-3) holds immediately due to the fact that V = kxk <sup>2</sup> and the definition of W. We now sketch a proof of why Assumption C[2](#page-8-1) also holds. Let µ ∈ P(R d ), and ǫ > 0. We set µi(·) = µ(· ∩ Bi), M = (∪ N <sup>i</sup>=1Bi) <sup>c</sup> and <sup>µ</sup>0(·) = <sup>µ</sup>(· ∩ <sup>M</sup>). Since interactions take place only inside <sup>B</sup><sup>i</sup> and R <sup>V</sup> (x)µ(dx) is linear with respect to µ, we have <sup>J</sup> (µ) = <sup>P</sup><sup>N</sup> <sup>i</sup>=0 J (µi). We would like to approximate each µ<sup>i</sup> by an absolutely continuous measure with the same total mass, and with energy close to the original and support inside its original support (so no new interaction occurs). By properties of integration, if µ δ i (·) = <sup>µ</sup>i(B(x<sup>i</sup> ,Ri)) <sup>µ</sup>i(B(xi,Ri−δ))µi(· ∩ B(x<sup>i</sup> , R<sup>i</sup> − δ)), then for all small δ > 0 we have |J (µ δ i ) − J (µi)| ≤ ǫ, for all i ∈ {1, . . . , N}. It is possible that µ0(∂M) > 0. However, we can move this mass to the interior of M by pushing µ<sup>0</sup> forward under

$$
f_{\delta}(\mathbf{x}) = \sum_{i=1}^{N} I_{\partial B_i}(\mathbf{x}) \left( \mathbf{x} + \frac{\delta D}{2} (\mathbf{x} - \mathbf{x}_i) \right) + I_{K \setminus \cup_i^N \partial B_i}(\mathbf{x}) \mathbf{x}
$$

with δ > 0 small. We can even assume that the resulting µ δ <sup>0</sup> has compact support in the interior of M by removing the mass in a small neighborhood of ∂M, and then renormalizing to keep the total mass constant as was done for the other µ<sup>i</sup> . For small δ > 0 it easy to see that, since only the continuous confined potential acts on it, |J (µ0) − J (µ δ 0 )| ≤ ǫ. Since Assumption C[2](#page-8-1) is satisfied for each h<sup>i</sup> , we can apply it to get a measure µ δ,n i , absolutely continuous with respect to the Lebesgue measure and with the same mass as µ i , that is supported only inside B<sup>i</sup> such that |J (µ δ,n i )−J (µ δ i )| ≤ ǫ, and µ δ,n i , µ<sup>δ</sup> i are close in the weak topology. We set µ δ,n <sup>0</sup> = µ δ 0 ∗ Gn, where G<sup>n</sup> is a truncated Gaussian of radius 1/n, which creates an absolutely continuous measure with support in K for which |J (µ δ,n 0 ) − J (µ δ 0 )| ≤ ǫ, for large enough n. Then µ δ,n = P<sup>N</sup> <sup>i</sup>=0 µ δ,n i , satisfies |J (µ δ,n) − J (µ)| ≤ (2<sup>N</sup> + 2)ǫ, and also by making <sup>n</sup> big enough and δ > 0 small enough we can have dw(µ δ,n, µ) <sup>≤</sup> ǫ.

Open problem 2.18. In [\[9\]](#page-37-0), the (extended) continuity of W was used as a sufficient condition for Assumption [C2](#page-8-1) to hold. Example [2.17](#page-13-1) above shows that continuity is not necessary for Assumption [C2](#page-8-1) to hold. Our preliminary investigations suggest that in some of these cases, it may be possible to establish LDPs with different rate functions, namely those that are given by some type of regularization of the J functional (like appropriate Γ-convergence relaxations but only with sequences that belong to specific subsets of the set of probability measures). We pose the existence of LDPs for cases where Assumption [C2](#page-8-1) fails as an open problem.

#### <span id="page-14-0"></span>2.5 Outline of the paper

The structure of the rest of the article is as follows. In Section [3](#page-14-1) we provide definitions and lemmas that are used throughout the paper and then show that the candidate rate functions introduced above are indeed rate functions. In Section [4](#page-17-0) we prove results for the speed β<sup>n</sup> = n, and in Section [5](#page-24-0) we consider the case of speeds β<sup>n</sup> that grow faster than n. An outline of the weak convergence approach and proofs of several lemmas that are needed for the main theorems are collected in the Appendices.

### <span id="page-14-1"></span>3 Rate Function Property

In what follows, recall the set Ψ defined in [\(2.3\)](#page-6-1). In Section [3.2,](#page-15-1) we show that under various combinations of Assumptions [A-](#page-4-2)C, the functions I<sup>⋆</sup> and J<sup>⋆</sup> defined in [\(2.14\)](#page-7-6) and [\(2.21\)](#page-9-4), and for ψ ∈ Ψ, the functions I ψ <sup>⋆</sup> and J ψ <sup>⋆</sup> defined in [\(2.15\)](#page-7-7) and [\(2.22\)](#page-9-5) are rate functions on the spaces P(R d ) and Pψ(R d ), respectively. To begin with, in Section [3.1](#page-15-0) we first introduce basic notions that will be used in the rest of the paper.

#### <span id="page-15-0"></span>3.1 Basic definitions

Definition 3.1. Let I be an index set and let {λa, a ∈ I} ⊂ P (S). The collection {λa, a ∈ I} is said to be tight if for every ǫ > 0, there is a compact set K<sup>ǫ</sup> ⊂ S, such that inf{λ<sup>a</sup> (Kǫ), a ∈ I} ≥ 1 − ǫ.

Furthermore, a sequence of random variables is said to be tight if and only if the corresponding distributions are tight. The proofs of the following three lemmas can be found in [\[8,](#page-37-13) Section 2.2].

<span id="page-15-4"></span>Lemma 3.2. A collection {λa, a ∈ I} ⊂ P(S) is tight if and only if there exists a tightness function g : S → [0,∞] such that supa∈<sup>I</sup> R S g(x)λa(dx) < ∞.

<span id="page-15-5"></span>Lemma 3.3. Let g be a tightness function on S. Define G : P(S) → [0,∞] by

$$
G(\mu) = \int_S g(x) \mu(dx).
$$

Then for each M < ∞ the set {µ ∈ P(S) : G(µ) ≤ M} is tight (and hence precompact), and moreover, G is a tightness function on P(S).

<span id="page-15-6"></span>Lemma 3.4. Let {Λa, a ∈ I} be random elements taking values in P(S) and let λ<sup>a</sup> = EΛa. Then {Λa, a ∈ I} is tight if and only if {λa, a ∈ I} is tight. In other words, a collection of random probability measures is tight if and only if the corresponding collection of "means" is tight in the space of (deterministic) probability measures.

The next result identifies a convenient tightness function on P<sup>ψ</sup> R d ; see Appendix [C](#page-32-0) for a proof.

<span id="page-15-2"></span>Lemma 3.5. Let ψ ∈ Ψ and φ ∈ Φ, with Ψ and Φ as defined in [\(2.3\)](#page-6-1) and [\(2.11\)](#page-7-5), respectively. Then

$$
\mathcal{T}(\mu) := \int_{\mathbb{R}^d} \phi\left(\psi\left(\mathbf{x}\right)\right) \mu\left(d\mathbf{x}\right)
$$

is a tightness function on P<sup>ψ</sup> R d .

Finally, it will be convenient to introduce the following projection operators to define marginal distributions.

<span id="page-15-7"></span>Definition 3.6. We denote by π k , k = 1, 2, the projection operators on a product space S<sup>1</sup> × S<sup>2</sup> defined by

$$
\pi^1 : (x_1, x_2) \to x_1 \in S_1
$$
,  $\pi^2 : (x_1, x_2) \to x_2 \in S_2$ .

#### <span id="page-15-1"></span>3.2 Verification of the rate function property

<span id="page-15-3"></span>Lemma 3.7. Suppose Assumption [A](#page-4-2) holds. Then I<sup>⋆</sup> and J<sup>⋆</sup> defined in [\(2.14\)](#page-7-6) and [\(2.21\)](#page-9-4), respectively, are lsc on P(R d ). Moreover, for ψ ∈ Ψ, I ψ <sup>∗</sup> and J ψ <sup>∗</sup> defined in [\(2.15\)](#page-7-7) and [\(2.22\)](#page-9-5), respectively, are lsc on Pψ(R d ).

Proof. We start by showing that the functional J<sup>a</sup> defined in [\(2.7\)](#page-6-3) is lsc. For µ ∈ P(R d ), let µ ⊗ µ denote the corresponding product measure on R <sup>d</sup> <sup>×</sup> <sup>R</sup> d , and recall from [\(2.7\)](#page-6-3) that Ja(µ) = Ja(µ ⊗ µ), with J<sup>a</sup> defined as in [\(2.6\)](#page-6-4). The map µ → µ ⊗ µ from P(R d ) to P(R <sup>d</sup> <sup>×</sup> <sup>R</sup> d ) is continuous, and by Fatou's lemma (for weak convergence) the map ζ 7→ Ja(ζ) is lower semicontinuous if W(x, y) + aV (x) + aV (y) is lower semicontinuous and bounded from below. Since the latter property holds under Assumption [A,](#page-4-2) it follows that J<sup>a</sup> is lsc. Since I = J<sup>a</sup> + R(·|e −(1−a)V ℓ) and, as is well known, R ·|e −(1−a)V ℓ is lsc on P(R d ), this shows that I, and hence I∗, are lsc. By the same argument, the lower semicontinuity of J can be deduced from the fact that J = J1(µ ⊗ µ) where J<sup>a</sup> is given in [\(2.6\)](#page-6-4), and the fact that (x, y) 7→ W(x, y) + V (x) + V (y) is lsc and uniformly bounded from below due to Assumption [A,](#page-4-2) and from [\(2.21\)](#page-9-4), it follows that J<sup>∗</sup> is lsc. Since the topology on Pψ(R d ) is stronger than that on P(R d ), it follows that both I ψ <sup>⋆</sup> and J ψ <sup>⋆</sup> defined in [\(2.15\)](#page-7-7) and [\(2.22\)](#page-9-5), respectively, are also lsc on Pψ(R d ).

<span id="page-16-3"></span>Lemma 3.8. Suppose Assumption [A](#page-4-2) is satisfied. Then I is a rate function on P(R d ). If, in addition, there exists ψ ∈ Ψ such that Assumption [B](#page-7-2) is satisfied, then I ψ <sup>⋆</sup> is a rate function on Pψ(R d ).

Proof. Since I<sup>⋆</sup> is lsc on P(R d ) by Lemma [3.7,](#page-15-3) it only remains to show that the level sets of I⋆, or equivalently I, are precompact on P(R d ). Since I = Ja+R(·|e −(1−a)V ℓ), this holds because R(·|e −(1−a)V ℓ) is a rate function on P(R d ) and J<sup>a</sup> is bounded below due to Assumption [A.](#page-4-2) Likewise, for ψ ∈ Ψ, to show that I ψ <sup>⋆</sup> is a rate function, due to Lemma [3.7](#page-15-3) it suffices to show that the level sets of I are compact in Pψ(R d ). This follows from Lemma [3.2](#page-15-4) and the fact that Assumption [B](#page-7-2) implies there exists a function <sup>φ</sup> <sup>∈</sup> Φ such that if I ≤ <sup>C</sup> then <sup>R</sup> <sup>R</sup><sup>d</sup> φ (ψ (x)) µ (dx) ≤ C.

In what follows, for a ∈ [0, 1] and µ ∈ P(R d ), let

<span id="page-16-4"></span>
$$
\mathcal{J}_{a,\neq}(\mu) := \frac{1}{2} \int_{(\mathbb{R}^d \times \mathbb{R}^d)_{\neq}} \left( W(\mathbf{x}, \mathbf{y}) + aV(\mathbf{x}) + aV(\mathbf{y}) \right) \mu(d\mathbf{x}) \mu(d\mathbf{y}), \tag{3.1}
$$

where we recall that A6<sup>=</sup> is the set A with its diagonal excised. Also, denote J1,6<sup>=</sup> simply as J6=.

Lemma 3.9. Let V and W satisfy Assumption [A](#page-4-2) and Assumption [C1](#page-8-2) (resp. Assumption [C3](#page-8-4) for some ψ ∈ Ψ), then J<sup>⋆</sup> (resp. J ψ <sup>⋆</sup> ) are tightness functions on P(R d ) (resp. Pψ(R d )).

Proof. From the definitions of J<sup>⋆</sup> and J ψ <sup>⋆</sup> in [\(2.21\)](#page-9-4) and [\(2.22\)](#page-9-5), it is clear that to prove the lemma, it suffices to show that under Assumptions [C1](#page-8-2) and [C3,](#page-8-4) J is a tightness function in the respective spaces P(R d ) and Pψ(R d ). The fact that J is lsc follows from Lemma [3.7.](#page-15-3) It remains to prove that the functionals have precompact level sets. For this, by Lemmas [3.2](#page-15-4) and [3.3,](#page-15-5) it suffices to prove that there exist C ′ > 0 and C<sup>1</sup> ∈ R such that for every µ ∈ P(R d )

<span id="page-16-2"></span>
$$
2\mathcal{J}(\mu) = \int_{\mathbb{R}^d \times \mathbb{R}^d} \left( V(\mathbf{x}) + V(\mathbf{y}) + W(\mathbf{x}, \mathbf{y}) \right) \mu(d\mathbf{x}) \mu(d\mathbf{y}) \ge C' \int_{\mathbb{R}^d} \gamma(\mathbf{x}) \mu(d\mathbf{x}) + C_1 \tag{3.2}
$$

for some tightness function γ. We will first prove that this is true for every µ ∈ P(R d ) without atoms and with compact support, and then use a limiting argument. By Assumption [C1](#page-8-2) (resp. Assumption [C3\)](#page-8-4), there exist a tightness function γ : R d 7→ R, A ∈ B(R d ) and C ∈ R such that the inequality [\(2.17\)](#page-8-5) holds:

<span id="page-16-0"></span>
$$
\gamma(\mathbf{x}) I_{A^c}(\mathbf{x}) + \gamma(\mathbf{y}) I_{A^c}(\mathbf{y}) \le V(\mathbf{x}) + V(\mathbf{y}) + W(\mathbf{x}, \mathbf{y}) + C.
$$
 (3.3)

Fix R < ∞ and µ ∈ P(R d ) whose support lies in B(0, R). Integrating both sides of [\(3.3\)](#page-16-0) with respect to µ, we have

<span id="page-16-1"></span>
$$
2\int_{A^c} \gamma(\mathbf{x})\,\mu(d\mathbf{x}) \le \int_{\mathbb{R}^d \times \mathbb{R}^d} \left( V(\mathbf{x}) + V(\mathbf{y}) + W(\mathbf{x}, \mathbf{y}) \right) \mu(d\mathbf{x})\,\mu(d\mathbf{y}) + C. \tag{3.4}
$$

Since µ has no atoms, by Lemma [E.1](#page-35-2) there exists a sequence x <sup>n</sup> <sup>∈</sup> <sup>R</sup> dn <sup>6</sup><sup>=</sup> , n ∈ N, such that L<sup>n</sup> := L(x n , ·) has support in B(0, R), and L<sup>n</sup> <sup>w</sup><sup>→</sup> <sup>µ</sup> and <sup>J</sup>6=(Ln) → J (µ) as <sup>n</sup> → ∞. Therefore, by Assumption [C1](#page-8-2) (resp. Assumption [C3\)](#page-8-4), and in particular [\(2.18\)](#page-8-7), there exists n<sup>0</sup> ∈ N, such that n ≥ n<sup>0</sup> implies r<sup>n</sup> > R, and hence

$$
\int_{A\cap B(0,R)} \gamma(\mathbf{x}) L_n(d\mathbf{x}) \le \int_{(A\cap B(0,R)\times A\cap B(0,R))_{\neq}} (V(\mathbf{x}) + V(\mathbf{y}) + W(\mathbf{x}, \mathbf{y})) L_n(d\mathbf{x}) L_n(d\mathbf{y}) + C
$$
\n
$$
\le \int_{(\mathbb{R}^d \times \mathbb{R}^d)_{\neq}} (V(\mathbf{x}) + V(\mathbf{y}) + W(\mathbf{x}, \mathbf{y})) L_n(d\mathbf{x}) L_n(d\mathbf{y}) + C + |c|
$$
\n
$$
= \mathcal{J}_{\neq}(L_n) + C + |c|,
$$

where c is the lower bound in Assumption [A.](#page-4-2) Combining this with the lower semicontinuity of γ, the fact that L<sup>n</sup> <sup>w</sup><sup>→</sup> <sup>µ</sup> and <sup>J</sup>6=(Ln) → J (µ) as <sup>n</sup> → ∞, we see that

<span id="page-17-1"></span>
$$
\int_{A} \gamma(\mathbf{x})\mu(d\mathbf{x}) = \int_{A \cap B(0,R)} \gamma(\mathbf{x})\mu(d\mathbf{x}) \le \liminf_{n \to \infty} \int_{A \cap B(0,R)} \gamma(\mathbf{x})L_n(d\mathbf{x})
$$
\n
$$
\le \lim_{n \to \infty} \mathcal{J}_{\neq}(L_n) + C + |c|
$$
\n
$$
= \mathcal{J}(\mu) + C + |c|.
$$
\n(3.5)

Together, [\(3.4\)](#page-16-1) and [\(3.5\)](#page-17-1) imply there exists C ′ <sup>&</sup>gt; 0, <sup>C</sup><sup>1</sup> <sup>∈</sup> <sup>R</sup> such that [\(3.2\)](#page-16-2) holds for any <sup>µ</sup> ∈ P(<sup>R</sup> d ) with compact support and without atoms. For general µ ∈ P(R d ) without atoms, we define the sequence of measures <sup>µ</sup><sup>N</sup> (·) = <sup>µ</sup>(·∩B(0,N)) <sup>µ</sup>(B(0,N)) , N ∈ N, each of which has compact support and is without atoms. The relation [\(3.2\)](#page-16-2) holds for each N ∈ N, from which we obtain

$$
C'\frac{\int_{\mathbb{R}^d}I_{B(0,N)}(\mathbf{x})\gamma(\mathbf{x})\,\mu\left(d\mathbf{x}\right)}{\mu(B(0,N))}+C_1\leq \frac{\int_{\mathbb{R}^d\times\mathbb{R}^d}I_{B(0,N)}(\mathbf{x})I_{B(0,N)}(\mathbf{y})\left(V\left(\mathbf{x}\right)+V\left(\mathbf{y}\right)+W\left(\mathbf{x},\mathbf{y}\right)\right)\mu\left(d\mathbf{x}\right)\mu\left(d\mathbf{y}\right)}{\mu^2(B(0,N))}.
$$

The integrands in the last inequality are bounded from below. Therefore, without loss of generality, we can assume that they are actually positive since otherwise we can just add and subtract their respective infima. By applying the monotone convergence theorem in the last relation, it follows that [\(3.2\)](#page-16-2) holds for any µ ∈ P(R d ) without atoms.

Finally, fix an arbitrary µ ∈ P(R d ). Assume without loss of generality that J (µ) < ∞, for if not, [\(3.2\)](#page-16-2) holds trivially. Then by Assumption [C2,](#page-8-1) there exists a sequence {µn} ⊂ P(R d ) such that each µ<sup>n</sup> is absolutely continuous with respect to the measure ℓ (and consequently, non-atomic since ℓ is non-atomic), µn <sup>w</sup><sup>→</sup> <sup>µ</sup> and <sup>J</sup> (µn) → J (µ). Since, as shown above, [\(3.2\)](#page-16-2) holds when <sup>µ</sup> is replaced with <sup>µ</sup><sup>n</sup> for each <sup>n</sup>, taking the limit inferior as <sup>n</sup> → ∞ of both sides and using the fact that lim infn→∞ <sup>R</sup> <sup>R</sup><sup>d</sup> γ(x)µ(dx) ≤ lim infn→∞ R <sup>R</sup><sup>d</sup> γ(x)µn(dx) since γ is lsc, it follows that [\(3.2\)](#page-16-2) also holds for any µ ∈ P(R d ).

### <span id="page-17-0"></span>4 Proof of Theorem [2.7](#page-7-0)

Throughout this section, we assume that Assumption [A](#page-4-2) is satisfied. To establish the LDP stated in Theorem [2.7,](#page-7-0) by [\[13,](#page-37-1) Theorem 1.2.3] we can equivalently verify the Laplace principle. For any probability measure P, we use E<sup>P</sup> to denote the corresponding expectation, and for conciseness denote E<sup>P</sup> by E. In view of the rate function property of I<sup>⋆</sup> and I ψ <sup>⋆</sup> already established in Lemmas [3.7](#page-15-3) and [3.8,](#page-16-3) it suffices to show the following: for any bounded and continuous function f on S, the Laplace principle

<span id="page-17-2"></span>
$$
\lim_{n \to \infty} -\frac{1}{n} \log \mathbb{E}_{Q_n} \left[ e^{-nf} \right] = \inf_{\mu \in S} \left\{ f \left( \mu \right) + \mathcal{I}_{\star} \left( \mu \right) \right\},\tag{4.1}
$$

holds both for S = P(R d ) and (under the additional condition stated as Assumption [B\)](#page-7-2) with S = Pψ(R d ) and I<sup>⋆</sup> replaced by I ψ ⋆ .

Remark 4.1. (Completeness of S is not necessary.) While the statement of [\[13,](#page-37-1) Theorem 1.2.3] assumes completeness of the space S, a review of the proof shows that this property is not needed (though compactness of the level sets of I<sup>⋆</sup> is used).

To establish the bound [\(4.1\)](#page-17-2), we first express − 1 n log EQ<sup>n</sup> e −nf in terms of a variational problem (equivalently, a stochastic control problem). We then prove tightness of nearly minimizing controls, and finally prove convergence of the values of the corresponding controlled problems to the value of the limiting variational problem. The last step is reminiscent of the notion of Γ-convergence that is often used for analyzing variational problems in the analysis community. For a nice exposition of the relationship between LDPs and Γ-convergence, the reader is referred to [\[23\]](#page-38-6).

#### <span id="page-18-0"></span>4.1 Representation formula

Recall that P<sup>n</sup> is the probability measure R dn defined in [\(1.5\)](#page-2-2) and Q<sup>n</sup> is the push forward of P<sup>n</sup> under Ln. Let a ∈ [0, 1) be the constant in Assumption [A](#page-4-2) and let P ⋆ <sup>n</sup> be the measure on R nd defined by

<span id="page-18-1"></span>
$$
P_n^{\star}(d\mathbf{x}_1,\ldots,d\mathbf{x}_n) := e^{-\sum_{i=1}^n (1-a)V(\mathbf{x}_i)} \ell(d\mathbf{x}_1) \cdots \ell(d\mathbf{x}_n),
$$
\n(4.2)

and note that it is a probability measure due to Assumption [A](#page-4-2) and Remark [2.1.](#page-5-3) Let Ja,6<sup>=</sup> be defined as in [\(3.1\)](#page-16-4): <sup>J</sup>a,6=(µ) = <sup>1</sup> 2 R (Rd×Rd)6<sup>=</sup> (W(x, y) + aV (x) + aV (y)) µ(dx)µ(dy). When β<sup>n</sup> = n, using [\(4.2\)](#page-18-1), [\(1.5\)](#page-2-2) and [\(1.3\)](#page-2-5) to calculate dPn/dP<sup>∗</sup> n , we see that for any measurable function f on P(R d ) (or on Pψ(R d )), we have

<span id="page-18-2"></span>
$$
-\frac{1}{n}\log \mathbb{E}_{Q_n}\left[e^{-nf}\right] = -\frac{1}{n}\log \mathbb{E}_{P_n}\left[e^{-nf\circ L_n}\right] = -\frac{1}{n}\log \mathbb{E}_{P_n^*}\left[\frac{1}{Z_n}e^{-n(f+\mathcal{J}_{a,\neq}+\frac{a}{n}\mathcal{V})\circ L_n}\right],\tag{4.3}
$$

where Z<sup>n</sup> is the normalizing constant defined in [\(1.6\)](#page-2-6) and V is the functional defined in [\(2.9\)](#page-6-5).

We next state a representation for the quantity on the right-hand side of [\(4.3\)](#page-18-2). To avoid confusion with the original distributions and random variables, we use an overbar (e.g., L¯ <sup>n</sup>) for quantities that will appear in the representation, and refer to them as "controlled" versions. Given a probability measure <sup>P</sup>¯<sup>n</sup> ∈ P(<sup>R</sup> dn), we can factor it into conditional distributions in the following manner:

$$
\bar{P}^n(dx_1,\ldots,d\mathbf{x}_n)=\bar{P}^n_{\{1\}}(d\mathbf{x}_1)\bar{P}^n_{\{2\}\{\{1\}}(d\mathbf{x}_2|\mathbf{x}_1)\cdots\bar{P}^n_{\{n\}\{\{1,\ldots,n-1\}}(d\mathbf{x}_n|\mathbf{x}_1,\ldots,\mathbf{x}_{n-1}),
$$

where for i = 1, ..., n, P¯ {i}|{1,...,i−1} (·|x1, ..., xi−1) denotes the conditional distribution of the i-th marginal given <sup>x</sup>1, ..., <sup>x</sup>i−1. Thus, if {X¯ n <sup>j</sup> }1≤j≤<sup>n</sup> are random variables with joint distribution <sup>P</sup>¯<sup>n</sup> (dx<sup>1</sup> · · · dxn) on some probability space (Ω, F, P), then ¯µ n i , the conditional distribution of X¯ <sup>n</sup> i given X¯ <sup>n</sup> 1 , . . . , X¯ <sup>n</sup> i−1 , can be expressed as

<span id="page-18-3"></span>
$$
\bar{\mu}_i^n(d\mathbf{x}_i) := \bar{P}_{\{i\}|\{1,\dots,i-1\}}^n(d\mathbf{x}_i|\bar{\mathbf{X}}_1^n,\dots,\bar{\mathbf{X}}_{i-1}^n). \tag{4.4}
$$

Note that ¯µ n i , 1 ≤ i ≤ n, are random probability measures, and the ith measure is measurable with respect to the <sup>σ</sup>-algebra generated by {X¯ n <sup>j</sup> }j<i. We refer to the collection {µ¯ n i , 1 ≤ i ≤ n} as a control, and let L¯ <sup>n</sup>(·) = <sup>L</sup>n(X¯ <sup>n</sup> ; ·), with <sup>L</sup><sup>n</sup> defined by [\(1.2\)](#page-2-3), be the (random) empirical measure of {X¯ n <sup>j</sup> }1≤j≤n, which we refer to as the controlled empirical measure.

Let f belong to the space of functions on P(R d ) (or Pψ(R d )) such that the map x n 7→ f(Ln(x n ; ·)) from R nd to R is measurable and bounded from below. This space clearly includes all bounded continuous functions on P(R d ) (respectively, Pψ(R d )). Then, since the functional Ja,6<sup>=</sup> is also measurable and bounded from below (due to Assumption [B\)](#page-7-2), we can apply [\[13,](#page-37-1) Proposition 4.5.1] to the function x <sup>n</sup> <sup>∈</sup> <sup>R</sup> d 7→ f(Ln(x n ; ·)) + Ja,6=(Ln(x n ; ·)), to obtain

$$
-\frac{1}{n}\log \mathbb{E}_{P_n^{\star}}\left[e^{-n(f+\mathcal{J}_{a,\neq}+\frac{a}{n}\mathcal{V})\circ L_n}\right] = \inf_{\{\bar{\mu}^n\}} \mathbb{E}\left[f\left(\bar{L}_n\right)+\mathcal{J}_{a,\neq}(\bar{L}_n)+\frac{a}{n}\mathcal{V}\left(\bar{L}_n\right)+\mathcal{R}\left(\bar{P}^n|\otimes_n e^{-(1-a)V}\ell\right)\right],\tag{4.5}
$$

where L¯ <sup>n</sup> is the controlled empirical measure associated with P¯<sup>n</sup> as defined above, and the infimum is over all controls {µ¯ n i } defined in terms of some joint distribution <sup>P</sup>¯<sup>n</sup> ∈ P(<sup>R</sup> dn) via [\(4.4\)](#page-18-3). Factoring P¯<sup>n</sup> as above and using the chain rule for relative entropy (see [\[13,](#page-37-1) Theorem B.2.1]), we then have

<span id="page-18-4"></span>
$$
-\frac{1}{n}\log \mathbb{E}_{P_n^{\star}}\Big[e^{-n(f+\mathcal{J}_{a,\neq}+\frac{a}{n}\mathcal{V})\circ L_n}\Big] = \inf_{\{\bar{\mu}_i^n\}} \mathbb{E}\Bigg[f\left(\bar{L}_n\right) + \mathcal{J}_{a,\neq}\left(\bar{L}_n\right) + \frac{a}{n}\mathcal{V}\left(\bar{L}_n\right) + \frac{1}{n}\sum_{i=1}^n \mathcal{R}\left(\bar{\mu}_i^n|e^{-(1-a)V}\ell\right)\Bigg],\tag{4.6}
$$

where the infimum is over all controls {µ¯ n i } (equivalently, joint distributions <sup>P</sup>¯<sup>n</sup> ∈ P(<sup>R</sup> nd)). Also, setting f = 0 in [\(4.6\)](#page-18-4) and recalling the definition of Z<sup>n</sup> from [\(1.6\)](#page-2-6) gives

<span id="page-18-5"></span>
$$
-\frac{1}{n}\log Z_n = -\frac{1}{n}\log \mathbb{E}_{P_n^*}\left[e^{-n\mathcal{J}_{a,\neq}(L_n) + \frac{a}{n}\mathcal{V}(L_n)}\right] = \inf_{\{\bar{\mu}_i^n\}} \mathbb{E}\left[\mathcal{J}_{a,\neq}(\bar{L}_n) + \frac{a}{n}\mathcal{V}(\bar{L}_n) + \frac{1}{n}\sum_{i=1}^n \mathcal{R}\left(\bar{\mu}_i^n | e^{-(1-a)V}\ell\right)\right].
$$
 (4.7)

We claim that to prove Theorem [2.7,](#page-7-0) it suffices to show that for every bounded and continuous (in the respective topology) function f, the lower bound

<span id="page-19-1"></span>
$$
\liminf_{n \to \infty} \inf_{\{\bar{\mu}_i^n\}} \mathbb{E}\left[f\left(\bar{L}_n\right) + \mathcal{J}_{a,\neq}\left(\bar{L}_n\right) + \frac{a}{n} \mathcal{V}\left(\bar{L}_n\right) + \frac{1}{n} \sum_{i=1}^n \mathcal{R}\left(\bar{\mu}_i^n | e^{-V} \ell\right)\right] \ge \inf_{\mu \in S} \{f\left(\mu\right) + \mathcal{I}\left(\mu\right)\} \tag{4.8}
$$

and upper bound

<span id="page-19-7"></span>
$$
\limsup_{n \to \infty} \inf_{\{\bar{\mu}_i^n\}} \mathbb{E}\left[f\left(\bar{L}_n\right) + \mathcal{J}_{a,\neq}\left(\bar{L}_n\right) + \frac{a}{n} \mathcal{V}\left(\bar{L}_n\right) + \frac{1}{n} \sum_{i=1}^n \mathcal{R}\left(\bar{\mu}_i^n | e^{-V} \ell\right)\right] \leq \inf_{\mu \in S} \{f\left(\mu\right) + \mathcal{I}\left(\mu\right)\} \tag{4.9}
$$

hold. Indeed, when combined with [\(4.6\)](#page-18-4), [\(4.7\)](#page-18-5) and [\(4.3\)](#page-18-2), these bounds imply the desired limit [\(4.1\)](#page-17-2). The lower and upper bounds are established in Sections [4.3](#page-22-0) and [4.4,](#page-23-0) respectively. First, in Section [4.2,](#page-19-0) we establish some tightness properties of the controls that will be used in the proofs of these bounds.

#### <span id="page-19-0"></span>4.2 Properties of the controls

We continue to use the notation for the controls introduced in the previous section. We start with a simplifying observation.

<span id="page-19-6"></span>Remark 4.2. In the proof of the lower bound [\(4.8\)](#page-19-1), we can assume that there exists C<sup>0</sup> < ∞ such that

<span id="page-19-2"></span>
$$
\sup_{n\in\mathbb{N}}\inf_{\{\bar{\mu}_i^n\}}\mathbb{E}\left[\mathcal{J}_{a,\neq}(\bar{L}_n)+\frac{a}{n}\mathcal{V}\left(\bar{L}_n\right)+\frac{1}{n}\sum_{i=1}^n\mathcal{R}\left(\bar{\mu}_i^n|e^{-(1-a)V}\ell\right)\right]\leq C_0.
$$
\n(4.10)

If this were not true, we could restrict to a subsequence that has such a property, because for any subsequence for which the left-hand side of [\(4.10\)](#page-19-2) is infinite, the lower bound [\(4.8\)](#page-19-1) is satisfied by default. Furthermore, since under Assumption [A,](#page-4-2) Ja,6<sup>=</sup> > min{0, 2c}, we can restrict to controls for which the relative entropy cost is bounded by C<sup>0</sup> + 2|c|: that is, for which

<span id="page-19-3"></span>
$$
\sup_{n} \mathbb{E}\left[\frac{1}{n}\sum_{i=1}^{n} \mathcal{R}\left(\bar{\mu}_{i}^{n} | e^{-(1-a)V} \ell\right)\right] \le C_{0} + 2|c|.
$$
\n(4.11)

<span id="page-19-4"></span>Lemma 4.3. Let V satisfy Assumption [A,](#page-4-2) let {µ¯ n i }, n ∈ N, be a sequence of controls for which [\(4.11\)](#page-19-3) holds, let L¯<sup>n</sup> be the associated sequence of controlled empirical measures and let

<span id="page-19-5"></span>
$$
\hat{\mu}_n := \frac{1}{n} \sum_{i=1}^n \bar{\mu}_i^n.
$$
\n(4.12)

Then L¯ <sup>n</sup>, µˆ<sup>n</sup> , n ∈ N is tight as a sequence of P(R d ) × P(R d )-valued random elements.

Proof. Let {µ¯ n i }, n ∈ N, be a sequence of controls that satisfies [\(4.11\)](#page-19-3). By the convexity of relative entropy and Jensen's inequality

$$
\sup_n \mathbb{E}\left[\mathcal{R}\left(\hat{\mu}^n|e^{-(1-a)V}\ell\right)\right]<\infty.
$$

We know that R ·|e −(1−a)V ℓ is a tightness function on P R d and hence, by Lemma [3.2,](#page-15-4) the sequence of random probability measures {µˆn, n ∈ N} is tight. By Lemma [3.4,](#page-15-6) the sequence of probability measures {E[ˆµn], n ∈ N} is tight. Since ¯µ n i is the conditional distribution of X¯ <sup>n</sup> i given (X¯ <sup>n</sup> 1 , ..., X¯ <sup>n</sup> i−1 ), for any measurable function g : R d 7→ R that is bounded from below, we have

$$
\mathbb{E}\left[\int_{\mathbb{R}^{d}} g\left(\mathbf{x}\right) \bar{L}_{n}\left(d\mathbf{x}\right)\right] = \mathbb{E}\left[\frac{1}{n} \sum_{i=1}^{n} g\left(\bar{\mathbf{X}}_{i}^{n}\right)\right] = \mathbb{E}\left[\frac{1}{n} \sum_{i=1}^{n} \int_{\mathbb{R}^{d}} g\left(\mathbf{x}\right) \bar{\mu}_{i}^{n}\left(d\mathbf{x}\right)\right] = \mathbb{E}\left[\int_{\mathbb{R}^{d}} g\left(\mathbf{x}\right) \hat{\mu}_{n}\left(d\mathbf{x}\right)\right].
$$

Thus, E -L¯ n <sup>=</sup> <sup>E</sup> [ˆµn] , and so {E[L¯ <sup>n</sup>], n ∈ N} is also tight. Another application of Lemma [3.4](#page-15-6) then shows that {L¯ <sup>n</sup>, n ∈ N}, is tight, which together with the tightness of {µˆ <sup>n</sup>} established above, implies µˆn,L¯ n , n ∈ N is tight.

The following lemma, which uses an elementary martingale argument, appears in [\[13\]](#page-37-1). For the reader's convenience the proof is given in Appendix [D.](#page-35-0)

<span id="page-20-5"></span>Lemma 4.4. Suppose L¯ <sup>n</sup>, <sup>µ</sup>ˆn, <sup>n</sup> <sup>∈</sup> <sup>N</sup>, are as defined in Lemma [4.3](#page-19-4) and further assume that L¯ <sup>n</sup>, µˆ<sup>n</sup> , n ∈ N converges along a subsequence to L, ¯ µˆ . Then L¯ = ˆµ w.p.1.

For the next result, it will be convenient to first define a collection of auxiliary random measures that extend the ones that appear in the representation [\(4.6\)](#page-18-4). Let P¯<sup>n</sup> be a probability measure on R dn, and let (X¯ <sup>n</sup> 1 , . . . , X¯ <sup>n</sup> n ) be random variables with joint distribution P¯<sup>n</sup> . For <sup>J</sup> ⊂ {1, ..., n}, let <sup>P</sup>¯<sup>n</sup> J equal the marginal distribution of <sup>P</sup>¯<sup>n</sup> on {x<sup>j</sup> , j <sup>∈</sup> <sup>J</sup>}, and for disjoint subsets <sup>I</sup><sup>1</sup> and <sup>I</sup><sup>2</sup> of {1, . . . , n}, let <sup>P</sup>¯<sup>n</sup> I1|I<sup>2</sup> denote the stochastic kernel defined as follows:

$$
\bar{P}_{I_1|I_2}^n(dx_i, i \in I_1|\mathbf{x}_k, k \in I_2) \bar{P}_{I_2}^n(dx_k, k \in I_2) = \bar{P}_{I_1 \cup I_2}^n(dx_j, j \in I_1 \cup I_2).
$$

Let K<sup>k</sup> := {1, . . . , k − 1}. In the sequel we fix i < j (the case j < i can be handled in a symmetric way), and define

<span id="page-20-1"></span>
$$
\bar{\mu}_{ij}^n(d\mathbf{x}_i d\mathbf{x}_j) := \bar{P}_{\{i,j\}|K_i}^n(d\mathbf{x}_i d\mathbf{x}_j | \bar{\mathbf{X}}_k^n, k \in K_i).
$$
\n(4.13)

Also, note that with this notation

<span id="page-20-2"></span>
$$
\bar{\mu}_i^n(d\mathbf{x}_i) = \bar{P}_{\{i\}|K_i}^n(d\mathbf{x}_i | \bar{\mathbf{X}}_1^n, \dots, \bar{\mathbf{X}}_{i-1}^n)
$$
\n(4.14)

are the controls used in the representation [\(4.6\)](#page-18-4). We claim that

<span id="page-20-0"></span>
$$
\pi_{\#}^1 \bar{\mu}_{ij}^n = \bar{\mu}_i^n \quad \text{and} \quad \pi_{\#}^2 \bar{\mu}_{ij}^n = \mathbb{E}[\bar{\mu}_j^n | \bar{\mathbf{X}}_k^n, k \in K_i], \tag{4.15}
$$

where π k , k = 1, 2, and # are the projection and push-forward operators introduced in Definition [3.6](#page-15-7) and Definition [2.2.](#page-5-1) The first relation in [\(4.15\)](#page-20-0) is an immediate consequence of the definitions of ¯µ n i and ¯µ n ij . Due to the asymmetry in the first and second (equivalently, i and j) coordinates in the definition of ¯µ n ij in [\(4.13\)](#page-20-1), the proof of the second equality in [\(4.15\)](#page-20-0) is a little more involved. Indeed, note that for every A ⊂ B(R d ),

$$
\pi_{\#}^{2} \bar{\mu}_{ij}^{n}(A) = \pi_{\#}^{2} \bar{P}_{\{i,j\}|K_{i}}^{n}(A | \bar{\mathbf{X}}_{k}^{n}, k \in K_{i}) = \int \bar{P}_{\{j\}|K_{i+1}}^{n}(A | \bar{\mathbf{X}}_{1}^{n}, ..., \bar{\mathbf{X}}_{i-1}^{n}, \mathbf{x}_{i}) \bar{P}_{\{i\}|K_{i}}^{n}(d\mathbf{x}_{i} | \bar{\mathbf{X}}_{k}^{n}, k \in K_{i})
$$
  
\n
$$
= \int \bar{P}_{\{j\}|K_{j}}^{n}(A | \bar{\mathbf{X}}_{1}^{n}, ..., \bar{\mathbf{X}}_{i-1}^{n}, \mathbf{x}_{i}, ..., \mathbf{x}_{j-1}) \bar{P}_{\{K_{j}\backslash K_{i}\}|K_{i}}^{n}(d\mathbf{x}_{i} \cdots d\mathbf{x}_{j-1} | \bar{\mathbf{X}}_{1}^{n}, ..., \bar{\mathbf{X}}_{i-1}^{n})
$$
  
\n
$$
= \mathbb{E}[\bar{P}_{\{j\}|K_{j}}^{n}(A | \bar{\mathbf{X}}_{k}^{n}, k \in K_{j}) | \bar{\mathbf{X}}_{k}^{n}, k \in K_{i}] = \mathbb{E}[\bar{\mu}_{j}^{n} | \bar{\mathbf{X}}_{k}^{n}, k \in K_{i}](A),
$$

from which the second equality in [\(4.15\)](#page-20-0) follows.

<span id="page-20-4"></span>Lemma 4.5. For ψ ∈ Ψ let V and W satisfy Assumptions [A](#page-4-2) and [B,](#page-7-2) and let {µ¯ n i }, n ∈ N, be a sequence of controls for which

<span id="page-20-3"></span>
$$
\sup_{n\in\mathbb{N}} \mathbb{E}\left[\mathcal{J}_{a,\neq}(\bar{L}_n) + \frac{a}{n}\mathcal{V}\left(\bar{L}_n\right) + \frac{1}{n}\sum_{i=1}^n \mathcal{R}\left(\bar{\mu}_i^n | e^{-V}\ell\right)\right] < \infty,\tag{4.16}
$$

and let µˆ<sup>n</sup> be as defined in [\(4.12\)](#page-19-5). Then L¯ <sup>n</sup>, µˆ<sup>n</sup> , n ∈ N is tight in Pψ(R d ) × Pψ(R d ).

Proof. Let θ be a probability measure on R d . By the chain rule for relative entropy, we have

$$
\mathcal{R}(\bar{P}_{\{i,j\}|K_i}^n(d\mathbf{x}_i d\mathbf{x}_j|\mathbf{x}_k, k \in K_i) \|\theta(d\mathbf{x}_i)\theta(d\mathbf{x}_j))
$$
  
= 
$$
\int \mathcal{R}(\bar{P}_{\{j\}|K_{i+1}}^n(d\mathbf{x}_j|\mathbf{x}_k, k \in K_{i+1}) \|\ell(d\mathbf{x}_j))\bar{P}_{\{i\}|K_i}^n(d\mathbf{x}_i|\mathbf{x}_k, k \in K_i)
$$
  
+ 
$$
\mathcal{R}(\bar{P}_{\{i\}|K_i}^n(d\mathbf{x}_i|\mathbf{x}_k, k \in K_i) \|\theta(d\mathbf{x}_i)).
$$

In addition, Jensen's inequality gives

$$
\mathcal{R}(\bar{P}_{\{j\}|K_{i+1}}^n(dx_j|\mathbf{x}_k, k \in K_{i+1}) \|\theta(dx_j))
$$
\n
$$
= \mathcal{R}\left(\int \bar{P}_{\{j\}|K_j}^n(dx_j|\mathbf{x}_k, k \in K_j) \bar{P}_{(K_j\setminus K_{i+1})|K_{i+1}}^n(dx_{i+1}\cdots dx_{j-1}|\mathbf{x}_k, k \in K_{i+1}) \middle\| \theta(dx_j)\right)
$$
\n
$$
\leq \int \mathcal{R}\left(\bar{P}_{\{j\}|K_j}^n(dx_j|\mathbf{x}_k, k \in K_j) \middle\| \theta(dx_j)\right) \bar{P}_{(K_j\setminus K_{i+1})|K_{i+1}}^n(dx_{i+1}\cdots dx_{j-1}|\mathbf{x}_k, k \in K_{i+1}).
$$

Combining the last two displays with [\(4.13\)](#page-20-1) and [\(4.14\)](#page-20-2), we obtain

<span id="page-21-0"></span>
$$
\mathbb{E}\left[\mathcal{R}(\bar{\mu}_{ij}^n(d\mathbf{x}_i d\mathbf{x}_j) \| \theta(d\mathbf{x}_i) \theta(d\mathbf{x}_j))\right] \leq \mathbb{E}[\mathcal{R}(\bar{\mu}_{j}^n(d\mathbf{x}_j) \| \theta(d\mathbf{x}_j)) + \mathcal{R}(\bar{\mu}_{i}^n(d\mathbf{x}_i) \| \theta(d\mathbf{x}_i))].
$$
\n(4.17)

Using [\(4.17\)](#page-21-0) with θ = e −(1−a)V ℓ, the definition of Ja,6<sup>=</sup> in [\(3.1\)](#page-16-4) and the tower property of conditional expectations to get the first inequality below, we have

<span id="page-21-1"></span>
$$
\mathbb{E}\left[\mathcal{J}_{a,\neq}(\bar{L}_{n})+\frac{a}{n}V(\bar{L}_{n})+\frac{1}{n}\sum_{i=1}^{n}\mathcal{R}\left(\bar{\mu}_{i}^{n}|e^{-(1-a)V}\ell\right)\right]
$$
\n
$$
=\mathbb{E}\left[\mathcal{J}_{a,\neq}(\bar{L}_{n})+\frac{a}{n}V(\bar{L}_{n})+\frac{1}{n(n-1)}(n-1)\sum_{i=1}^{n}\mathcal{R}\left(\bar{\mu}_{i}^{n}|e^{-(1-a)V}\ell\right)\right]
$$
\n
$$
\geq \mathbb{E}\left[\frac{1}{2n^{2}}\sum_{i\n
$$
+\frac{1}{2n^{2}}\sum_{j\n
$$
+\frac{1}{n(n-1)}\sum_{i\n
$$
=\mathbb{E}\left[\frac{1}{2n^{2}}\sum_{i
$$
$$
$$
$$

where J<sup>a</sup> is the functional defined in [\(2.6\)](#page-6-4) and c is a lower bound for V. Next, let

<span id="page-21-2"></span>
$$
\hat{\mu}^{2,n} := \frac{1}{n(n-1)} \sum_{i \neq j} \bar{\mu}_{ij}^n.
$$
\n(4.19)

<span id="page-21-3"></span>Then combining [\(4.18\)](#page-21-1) with the convexity of R in both arguments (see [\[13,](#page-37-1) Lemma 1.4.3]), the linearity of Ja, and the definition of ˆµ <sup>2</sup>,n in [\(4.19\)](#page-21-2), we obtain

$$
\mathbb{E}\left[\mathcal{J}_{a,\neq}(\bar{L}_n) + \frac{a}{n}V(\bar{L}_n) + \frac{1}{n}\sum_{i=1}^n \mathcal{R}\left(\bar{\mu}_i^n|e^{-(1-a)V}\ell\right)\right]
$$
\n
$$
\geq \mathbb{E}\left[\frac{n-1}{n}\mathfrak{J}_a\left(\hat{\mu}^{2,n}\right) + \frac{ac}{n} + \mathcal{R}\left(\hat{\mu}^{2,n}|e^{-(1-a)V}\ell\otimes e^{-(1-a)V}\ell\right)\right].
$$
\n(4.20)

We now use [\(4.20\)](#page-21-3) to establish tightness of both {L¯ <sup>n</sup>} and {µˆn} in the d<sup>ψ</sup> topology. Note that ˆµ 2,n is a random probability measure on R <sup>d</sup> <sup>×</sup> <sup>R</sup> <sup>d</sup> and that it has identical marginals. Since V and W satisfy Assumption [B](#page-7-2) and relative entropy is nonnegative, there exists a superlinear function φ for which we have the inequalities

<span id="page-22-1"></span>
$$
\mathbb{E}\left[\frac{n-1}{n}\mathfrak{J}_a\left(\hat{\mu}^{2,n}\right)+\mathcal{R}\left(\hat{\mu}^{2,n}|e^{-(1-a)V}\ell\otimes e^{-(1-a)V}\ell\right)\right] \n\geq \mathbb{E}\left[\frac{n-1}{n}\left[\mathfrak{J}_a\left(\hat{\mu}^{2,n}\right)+\mathcal{R}\left(\hat{\mu}^{2,n}|e^{-(1-a)V}\ell\otimes e^{-(1-a)V}\ell\right)\right]\right] \geq \frac{n-1}{n}\mathbb{E}\left[\int_{\mathbb{R}^d}\phi\left(\psi\left(\boldsymbol{x}\right)\right)\left(\pi_{\#}^1\hat{\mu}^{2,n}\right)\left(d\boldsymbol{x}\right)\right].
$$
\n(4.21)

For n ≥ 2, combining [\(4.20\)](#page-21-3) and [\(4.21\)](#page-22-1) gives

<span id="page-22-2"></span>
$$
2\mathbb{E}\left[\mathcal{J}_{a,\neq}\left(\bar{L}_n\right)+\frac{a}{n}\mathcal{V}\left(\bar{L}_n\right)+\frac{1}{n}\sum_{i=1}^n\mathcal{R}\left(\bar{\mu}_i^n|e^{-(1-a)V}\ell\right)\right]\geq \mathbb{E}\left[\int_{\mathbb{R}^d}\phi\left(\psi\left(\bm{x}\right)\right)\left(\pi_{\#\mu}^1\hat{\mu}^{2,n}\right)\left(d\bm{x}\right)\right]+\frac{2ac}{n}.\tag{4.22}
$$

Note that [\(4.15\)](#page-20-0) implies E[π 1 #µ¯ n ij ] = E[¯µ n i ] and E[π 2 #µ¯ n ij ] = E[¯µ n j ]. Further, recalling the definition of µˆ<sup>n</sup> in [\(4.12\)](#page-19-5) and ˆµ <sup>2</sup>,n in [\(4.19\)](#page-21-2), this shows that

$$
\mathbb{E}[\pi_{\#}^1 \hat{\mu}^{2,n}] = \mathbb{E}[\pi_{\#}^2 \hat{\mu}^{2,n}] = \mathbb{E}[\hat{\mu}_n].
$$
\n(4.23)

Substituting this into the right-hand side of [\(4.22\)](#page-22-2) and letting C<sup>0</sup> < ∞ denote the left-hand side of [\(4.16\)](#page-20-3), we obtain the bound

$$
\mathbb{E}\left[\int_{\mathbb{R}^d} \phi\left(\psi\left(\boldsymbol{x}\right)\right) \hat{\mu}_n\left(d\boldsymbol{x}\right)\right] \leq 2C_0 - \frac{2ac}{n} \leq 2C_0 + 1,
$$

for all sufficiently large n. However, since we know from Lemma [3.5](#page-15-2) that Φ(µ) = R <sup>R</sup><sup>d</sup> φ (ψ (x)) µ (dx) is a tightness function on P<sup>ψ</sup> R d , it follows that {µˆn} is tight as a collection of P<sup>ψ</sup> R d -valued random elements. Finally, note that we have the equality

$$
\mathbb{E}\left[\int_{\mathbb{R}^d} g\left(\mathbf{x}\right) \bar{L}_n\left(d\mathbf{x}\right)\right] = \mathbb{E}\left[\frac{1}{n} \sum_{i=1}^n g\left(\bar{\mathbf{X}}_i^n\right)\right] = \mathbb{E}\left[\frac{1}{n} \sum_{i=1}^n \int_{\mathbb{R}^d} g\left(\mathbf{x}\right) \bar{\mu}_i^n\left(d\mathbf{x}\right)\right] = \mathbb{E}\left[\int_{\mathbb{R}^d} g\left(\mathbf{x}\right) \hat{\mu}_n\left(d\mathbf{x}\right)\right].
$$

Setting <sup>g</sup>(x) = <sup>φ</sup>(ψ(x)), and again invoking Lemma [3.5,](#page-15-2) we see that {L¯ <sup>n</sup>} is also tight.

Remark 4.6. In the remainder of the proof, which is carried out in Sections [4.3](#page-22-0) and [4.4,](#page-23-0) the arguments for both P(R d ) and Pψ(R d ) are similar, and so we will treat both cases simultaneously. The functions f used will be considered continuous in the respective topology and any infimum taken should be with respect to the corresponding set P(R d ) or Pψ(R d ).

Remark 4.7. Due to Remark [4.2](#page-19-6) and Lemmas [4.3](#page-19-4) and [4.5,](#page-20-4) it is without loss of generality, for the lower bound [\(4.8\)](#page-19-1), to restrict to controls for which L¯ <sup>n</sup>, µˆ<sup>n</sup> , n ∈ N is tight in P(R d ) × P(R d ), or (with the additional Assumption [B\)](#page-7-2) in Pψ(R d ) × Pψ(R d ).

#### <span id="page-22-0"></span>4.3 Proof of the lower bound

For the proof of the lower bound [\(4.8\)](#page-19-1) we will use some auxiliary functionals. For d ′ <sup>∈</sup> <sup>N</sup>, an arbitrary function F : R d ′ <sup>→</sup> (−∞,∞] and <sup>M</sup> <sup>∈</sup> [0,∞), let <sup>F</sup> <sup>M</sup>(z) := min{F(z), M}. For <sup>µ</sup> ∈ P(<sup>R</sup> d ), let

$$
\mathcal{J}_a^M(\mu) := \frac{1}{2} \int_{\mathbb{R}^d \times \mathbb{R}^d} \left( W^M(\mathbf{x}, \mathbf{y}) + aV^M(\mathbf{x}) + aV^M(\mathbf{y}) \right) \mu(d\mathbf{x}) \mu(d\mathbf{y}),
$$
  
$$
\mathcal{J}_{a, \neq}^M(\mu) := \frac{1}{2} \int_{(\mathbb{R}^d \times \mathbb{R}^d)_{\neq}} \left( W^M(\mathbf{x}, \mathbf{y}) + aV^M(\mathbf{x}) + aV^M(\mathbf{y}) \right) \mu(d\mathbf{x}) \mu(d\mathbf{y}),
$$

and note that for every µ ∈ P(R d ),

<span id="page-23-1"></span>
$$
\mathcal{J}_a^M(\mu) \le \mathcal{J}_{a,\neq}^M(\mu) + \frac{3M}{2}(\mu \otimes \mu) \{ (x, x) : x \in \mathbb{R}^d \}. \tag{4.24}
$$

Let ǫ > 0 be given. Then by Remark [4.2](#page-19-6) and the boundedness of f, there exist C ′ <sup>∈</sup> <sup>R</sup> and a sequence of controls {µ˜ n i } with associated sequence of controlled empirical measures {L˜ <sup>n</sup>}, such that

<span id="page-23-2"></span>
$$
C' > \inf_{\{\bar{\mu}_i^n\}} \mathbb{E}\left[f\left(\bar{L}_n\right) + \mathcal{J}_{a,\neq}\left(\bar{L}_n\right) + \frac{a}{n} \mathcal{V}\left(\bar{L}_n\right) + \frac{1}{n} \sum_{i=1}^n \mathcal{R}\left(\bar{\mu}_i^n | e^{-(1-a)V}\ell\right)\right] + \epsilon
$$
  
\n
$$
\geq \mathbb{E}\left[f\left(\tilde{L}_n\right) + \mathcal{J}_{a,\neq}\left(\tilde{L}_n\right) + \frac{ac}{n} + \frac{1}{n} \sum_{i=1}^n \mathcal{R}\left(\tilde{\mu}_i^n | e^{-(1-a)V}\ell\right)\right]
$$
  
\n
$$
\geq \mathbb{E}\left[f\left(\tilde{L}_n\right) + \mathcal{J}_{a,\neq}^M\left(\tilde{L}_n\right) + \frac{ac}{n} + \frac{1}{n} \sum_{i=1}^n \mathcal{R}\left(\tilde{\mu}_i^n | e^{-(1-a)V}\ell\right)\right]
$$
  
\n
$$
\geq \mathbb{E}\left[f\left(\tilde{L}_n\right) + \mathcal{J}_a^M\left(\tilde{L}_n\right) - \frac{3M}{2n} + \frac{ac}{n} + \frac{1}{n} \sum_{i=1}^n \mathcal{R}\left(\tilde{\mu}_i^n | e^{-(1-a)V}\ell\right)\right],
$$
\n(4.25)

where <sup>J</sup>a,6<sup>=</sup> ≥ J <sup>M</sup> a,6= is used for the third inequality and the last inequality uses [\(4.24\)](#page-23-1) and the fact that <sup>L</sup>¯<sup>n</sup> <sup>⊗</sup> <sup>L</sup>¯<sup>n</sup> put mass at most 1/n on the diagonal of <sup>R</sup> <sup>d</sup> <sup>×</sup> <sup>R</sup> d .

Let ˆµ<sup>n</sup> := <sup>1</sup> n P<sup>n</sup> <sup>i</sup>=1 µ˜ n i . Since Lemma [4.5](#page-20-4) implies {(L˜ <sup>n</sup>, µˆn)} is tight, we can extract a further subsequence, which we denote again by {(L˜ <sup>n</sup>, <sup>µ</sup>ˆn)}, which converges in distribution to some limit (L, ˜ <sup>µ</sup>ˆ). If the lower bound is established for this subsequence, a standard argument by contradiction establishes the lower bound for the original sequence. Let {Mn} be an increasing sequence such that limn→∞ M<sup>n</sup> = ∞ and limn→∞ Mn <sup>n</sup> = 0, and let <sup>m</sup> <sup>∈</sup> <sup>N</sup>. By the monotonicity of <sup>n</sup> 7→ WM<sup>n</sup> , Jensen's inequality, the definition of ˆµn, and Fatou's lemma we have

$$
\liminf_{n \to \infty} \mathbb{E}\left[f\left(\tilde{L}_n\right) + \mathcal{J}_a^{M_n}\left(\tilde{L}_n\right) - \frac{3M_n}{2n} + \frac{ac}{n} + \frac{1}{n} \sum_{i=1}^n \mathcal{R}\left(\tilde{\mu}_i^n | e^{-(1-a)V}\ell\right)\right]
$$
\n
$$
\geq \liminf_{n \to \infty} \mathbb{E}\left[f\left(\tilde{L}_n\right) + \mathcal{J}_a^{M_m}\left(\tilde{L}_n\right) - \frac{3M_n}{2n} + \frac{ac}{n} + \mathcal{R}\left(\hat{\mu}_n | e^{-(1-a)V}\ell\right)\right]
$$
\n
$$
\geq \mathbb{E}\left[f\left(\tilde{L}\right) + \mathcal{J}_a^{M_m}\left(\tilde{L}\right) + \mathcal{R}\left(\hat{\mu}| e^{-(1-a)V}\ell\right)\right],
$$
\n(4.26)

<span id="page-23-3"></span>where the continuity of <sup>f</sup> and lower semicontinuity of <sup>J</sup> <sup>M</sup><sup>m</sup> a and R(·|e −(1−a))V ℓ) are also used in the last inequality. Since this inequality holds for arbitrary m ∈ N, the monotone convergence theorem, the property that <sup>L</sup>˜ = ˆ<sup>µ</sup> almost surely (due to Lemma [4.4\)](#page-20-5) and the definition of <sup>I</sup> in [\(2.14\)](#page-7-6), together imply

$$
\lim_{m \to \infty} \mathbb{E}\left[f\left(\tilde{L}\right) + \mathcal{J}_a^{M_m}\left(\tilde{L}\right) + \mathcal{R}\left(\hat{\mu}|e^{-(1-a)V}\ell\right)\right] = \mathbb{E}\left[f\left(\hat{\mu}\right) + \mathcal{J}_a\left(\hat{\mu}\right) + \mathcal{R}(\hat{\mu}|e^{-(1-a)V}\ell)\right] \ge \inf_{\mu \in S} \{f\left(\mu\right) + \mathcal{I}\left(\mu\right)\}.
$$
\n(4.27)

Since ǫ > 0 is arbitrary, [\(4.25\)](#page-23-2), [\(4.26\)](#page-23-3) and [\(4.27\)](#page-23-4) together imply the lower bound [\(4.8\)](#page-19-1).

#### <span id="page-23-0"></span>4.4 Proof of the upper bound

Again, fix f to be a bounded continuous function on P(R d ), let ǫ > 0 and let µ <sup>∗</sup> ∈ P(<sup>R</sup> d ) (respectively, Pψ(R d )) be such that

<span id="page-23-5"></span><span id="page-23-4"></span>
$$
f(\mu^*) + \mathcal{J}_a(\mu^*) + \mathcal{R}\left(\mu^*|e^{-(1-a)V}\ell\right) \le \inf_{\mu} \left[f(\mu) + \mathcal{I}(\mu)\right] + \epsilon. \tag{4.28}
$$

For n ∈ N, let {µ˜ n i , 1 ≤ i ≤ n} denote the particular control defined by ˜µ n i := µ ∗ for all n ∈ N and <sup>i</sup> ∈ {1, ..., n}, and let <sup>X</sup>˜ <sup>n</sup> i , i = 1, . . . , n, and L˜ <sup>n</sup> denote the associated controlled objects. Recall that ℓ and hence µ <sup>∗</sup> are non-atomic. From the definition of <sup>J</sup><sup>a</sup> and <sup>J</sup>a,6<sup>=</sup> in [\(2.7\)](#page-6-3) and [\(3.1\)](#page-16-4), respectively, we have

$$
\mathbb{E}\left[\mathcal{J}_{a,\neq}\left(\tilde{L}_n\right)\right] = \frac{1}{2}\mathbb{E}\left[\frac{1}{n^2}\sum_{i=1}^n\sum_{j=1,j\neq i}^n \left(W\left(\tilde{\mathbf{X}}_i^n,\tilde{\mathbf{X}}_j^n\right) + aV(\tilde{\mathbf{X}}_i^n) + aV(\tilde{\mathbf{X}}_j^n)\right)\right]
$$
  
=  $\frac{n-1}{2n}\int_{\mathbb{R}^d\times\mathbb{R}^d} \left(W\left(\mathbf{x},\mathbf{y}\right) + aV(\mathbf{x}) + aV(\mathbf{y})\right)\mu^*\left(d\mathbf{x}\right)\mu^*\left(d\mathbf{y}\right) = \frac{n-1}{n}\mathcal{J}_a(\mu^*).$  (4.29)

Define ˇµ<sup>n</sup> := <sup>1</sup> n P<sup>n</sup> <sup>i</sup>=1 µ˜ n <sup>i</sup> = µ ∗ . Then, due to [\(4.28\)](#page-23-5), the conditions of Lemma [4.5](#page-20-4) hold for {(L˜ <sup>n</sup>, µˇn)}. Together with Lemma [4.3,](#page-19-4) this shows that {L˜ <sup>n</sup>} is tight in P(R d ) and Pψ(R d ). When combined with the almost sure convergence L˜ <sup>n</sup> → µ ∗ , which holds due to Lemma [4.4](#page-20-5) (or the Glivenko-Cantelli lemma), this implies convergence of L˜ <sup>n</sup> to µ <sup>∗</sup> with respect to both d<sup>w</sup> and dψ, as appropriate. Since f is bounded and continuous, limn→∞ E[f(L˜ <sup>n</sup>)] = f (µ ∗ ) by the dominated convergence theorem. The above observations, together with [\(4.29\)](#page-24-2), the uniform lower bound on J<sup>a</sup> and V and [\(4.28\)](#page-23-5) show that

<span id="page-24-2"></span>
$$
\limsup_{n \to \infty} \inf_{\{\bar{\mu}_i^n\}} \mathbb{E}\left[f\left(\bar{L}_n\right) + \mathcal{J}_{a,\neq}\left(\bar{L}_n\right) + \frac{a}{n} \mathcal{V}(\bar{L}_n) + \frac{1}{n} \sum_{i=1}^n \mathcal{R}\left(\bar{\mu}_i^n | e^{-(1-a)V} \ell\right)\right]
$$
\n
$$
\leq \limsup_{n \to \infty} \mathbb{E}\left[f\left(\tilde{L}_n\right) + \frac{n-1}{n} \mathcal{J}_a(\mu^*) + \frac{a}{n} \mathcal{V}(\mu^*) + \frac{1}{n} \sum_{i=1}^n \mathcal{R}\left(\tilde{\mu}_i^n | e^{-(1-a)V} \ell\right)\right]
$$
\n
$$
\leq f(\mu^*) + \mathcal{J}_a(\mu^*) + \mathcal{R}\left(\mu^* | e^{-(1-a)V} \ell\right) \leq \inf_{\mu \in S} \{f(\mu) + \mathcal{I}(\mu)\} + \epsilon.
$$

Since ǫ is arbitrary, this implies the upper bound [\(4.9\)](#page-19-7), which together with [\(4.8\)](#page-19-1) and the discussion at the end of Section [4.1](#page-18-0) completes the proof of Theorem [2.7.](#page-7-0)

### <span id="page-24-0"></span>5 Proof of Theorem [2.9](#page-9-2)

This section is devoted to the proof of Theorem [2.9.](#page-9-2) The structure of the proof is similar to that of the case with speed β<sup>n</sup> = n. In view of Lemmas [3.7](#page-15-3) and [3.8](#page-16-3) and Theorem 1.2.3 in [\[13\]](#page-37-1), it suffices to prove that for any bounded and continuous function f on S (where S = P(R d ) or S = Pψ(R d ), as appropriate), as n → ∞,

$$
-\frac{1}{n}\log \mathbb{E}_{Q_n}\left[e^{-\beta_n f}\right] \to \inf_{\mu \in S} \left\{f\left(\mu\right) + \mathcal{J}_{\star}\left(\mu\right)\right\}.
$$
\n(5.1)

#### <span id="page-24-1"></span>5.1 Representation formula

As before, fix a ∈ [0, 1) as in Assumption [A,](#page-4-2) and let P ⋆ n (dx n ) = e −(1−a) P<sup>n</sup> <sup>i</sup>=1 <sup>V</sup> (xi) <sup>⊗</sup><sup>n</sup> <sup>i</sup>=1 ℓ(dxi) be the probability measure on R dn defined in [\(4.2\)](#page-18-1). We now introduce the functional <sup>J</sup>n,6<sup>=</sup> : <sup>P</sup>(<sup>R</sup> d ) → (−∞,∞] given by

<span id="page-24-3"></span>
$$
\mathcal{J}_{n,\neq}(\mu) := \frac{1}{2} \int_{(\mathbb{R}^d \times \mathbb{R}^d)_{\neq}} \left( \left( 1 - \frac{(1-a)n}{\beta_n} \right) (V(\mathbf{x}) + V(\mathbf{y})) + W(\mathbf{x}, \mathbf{y}) \right) \mu(d\mathbf{x}) \mu(d\mathbf{y}). \tag{5.2}
$$

Note that Jn,6<sup>=</sup> (µ) is bounded below for all sufficiently large n due to Assumption [C1](#page-8-2) and the fact that βn/n → ∞. When x <sup>n</sup> <sup>∈</sup> (<sup>R</sup> dn)6=, using [\(5.2\)](#page-24-3) we can rewrite βnHn, where H<sup>n</sup> was defined in [\(1.1\)](#page-2-7), as follows:

$$
\beta_n H_n(\mathbf{x}^n) = \frac{\beta_n}{2} \int_{(\mathbb{R}^d \times \mathbb{R}^d)_{\neq}} \left( \left( 1 - \frac{(1-a)n}{\beta_n} \right) [V(\mathbf{x}) + V(\mathbf{y})] + W(\mathbf{x}, \mathbf{y}) \right) L_n(\mathbf{x}^n; d\mathbf{x}) L_n(\mathbf{x}^n; d\mathbf{y}) \n+ \left( \frac{\beta_n}{n} - (1-a) \right) \int_{\mathbb{R}^d} V(\mathbf{x}) L_n(\mathbf{x}^n; d\mathbf{x}) + (1-a)n \int_{\mathbb{R}^d} V(\mathbf{x}) L_n(\mathbf{x}^n; d\mathbf{x}) \n= \beta_n \left( \mathcal{J}_{n,\neq} (L_n(\mathbf{x}^n; \cdot)) + \left( \frac{1}{n} - \frac{(1-a)}{\beta_n} \right) \mathcal{V}(L_n(\mathbf{x}^n; \cdot)) \right) + (1-a) \sum_{i=1}^n V(\mathbf{x}_i).
$$

Let f be a measurable function on P(R d ) (or on Pψ(R d )) that is bounded below (in particular f could be bounded and continuous). Then by the definition of P ∗ n , we have

<span id="page-25-3"></span>
$$
-\frac{1}{\beta_n}\log \mathbb{E}_{Q_n}\left[e^{-\beta_n f}\right] = -\frac{1}{\beta_n}\log \mathbb{E}_{P_n}\left[e^{-\beta_n f \circ L_n}\right] = -\frac{1}{\beta_n}\log \mathbb{E}_{P_n^{\star}}\left[\frac{1}{Z_n}e^{-\beta_n \left(f + \mathcal{J}_{n,\neq} + \left(\frac{1}{n} - \frac{(1-a)}{\beta_n}\right)\mathcal{V}\right) \circ L_n}\right], (5.3)
$$

where Z<sup>n</sup> is the normalization constant defined in [\(1.6\)](#page-2-6).

Using the same notation and arguments as in Section [4.1,](#page-18-0) the following representations are valid. Fix any function f on P(R d ) (or Pψ(R d )), such that f ◦ L<sup>n</sup> is measurable in R dn and bounded from below (this includes all continuous and bounded functions on P(R d ) or Pψ(R d ). Then, since the function (x, y) 7→ 1 − (1−a)n βn <sup>V</sup> (x) + 1 − (1−a)n βn V (y) + W (x, y) is measurable and bounded from below, we can apply [\[13,](#page-37-1) Proposition 4.5.1] to f(Ln(x n ; ·)) + <sup>J</sup>n,6=(Ln(<sup>x</sup> n ; ·)) + 1 n − 1−a βn <sup>V</sup>(Ln(<sup>x</sup> n ; ·)), to obtain

$$
-\frac{1}{\beta_n} \log \mathbb{E}_{P_n^*} \left[ e^{-\beta_n \left( f + \mathcal{J}_{n, \neq} + \left( \frac{1}{n} - \frac{1 - a}{\beta_n} \right) \mathcal{V} \right) \circ L_n} \right]
$$
  
= 
$$
\inf_{\{\bar{\mu}_i^n\}} \mathbb{E} \left[ f(\bar{L}_n) + \mathcal{J}_{n, \neq} (\bar{L}_n) + \left( \frac{1}{n} - \frac{1 - a}{\beta_n} \right) \mathcal{V}(\bar{L}_n) + \frac{1}{\beta_n} \sum_{i=1}^n \mathcal{R} \left( \bar{\mu}_i^n | e^{-(1 - a)V} \ell \right) \right].
$$
  
(5.4)

<span id="page-25-2"></span><span id="page-25-1"></span>Setting f = 0 in the last display, we have

$$
-\frac{1}{\beta_n} \log (Z_n) = -\frac{1}{\beta_n} \log \mathbb{E}_{P_n^*} \left[ e^{-\beta_n \left( \mathcal{J}_{n, \neq} + \left( \frac{1}{n} - \frac{1 - a}{\beta_n} \right) \mathcal{V} \right) \circ L_n} \right]
$$
  
= 
$$
\inf_{\{\bar{\mu}_i^n\}} \mathbb{E} \left[ \mathcal{J}_{n, \neq} \left( \bar{L}_n \right) + \left( \frac{1}{n} - \frac{1 - a}{\beta_n} \right) \mathcal{V}(\bar{L}_n) + \frac{1}{\beta_n} \sum_{i=1}^n \mathcal{R} \left( \bar{\mu}_i^n | e^{-(1 - a)V} \ell \right) \right].
$$
 (5.5)

As before, to establish Theorem [2.9,](#page-9-2) in view of [\(5.4\)](#page-25-1), [\(5.5\)](#page-25-2) and [\(5.3\)](#page-25-3), it suffices to establish the lower bound

<span id="page-25-6"></span>
$$
\liminf_{n \to \infty} \inf_{\{\bar{\mu}_i^n\}} \mathbb{E}\left[f\left(\bar{L}_n\right) + \mathcal{J}_{n,\neq}\left(\bar{L}_n\right) + \left(\frac{1}{n} - \frac{1-a}{\beta_n}\right) \mathcal{V}(\bar{L}_n) + \frac{1}{\beta_n} \sum_{i=1}^n \mathcal{R}\left(\bar{\mu}_i^n | e^{-(1-a)V} \ell\right)\right] \tag{5.6}
$$
\n
$$
\geq \inf_{\mu \in S} \{f\left(\mu\right) + \mathcal{J}\left(\mu\right)\},
$$

and the upper bound

<span id="page-25-7"></span>
$$
\limsup_{n \to \infty} \inf_{\{\bar{\mu}_i^n\}} \mathbb{E}\left[f\left(\bar{L}_n\right) + \mathcal{J}_{n,\neq}\left(\bar{L}_n\right) + \left(\frac{1}{n} - \frac{1-a}{\beta_n}\right) \mathcal{V}(\bar{L}_n) + \frac{1}{\beta_n} \sum_{i=1}^n \mathcal{R}\left(\bar{\mu}_i^n | e^{-(1-a)V} \ell\right)\right] \tag{5.7}
$$
\n
$$
\leq \inf_{\mu \in S} \{f\left(\mu\right) + \mathcal{J}\left(\mu\right)\},
$$

for all bounded and continuous functions f (with respect to the corresponding topologies).

#### <span id="page-25-0"></span>5.2 Tightness of controls

As in Remark [4.2,](#page-19-6) we have the following observation that simplifies the proof of the lower bound.

<span id="page-25-5"></span>Remark 5.1. Without loss of generality we can assume that

<span id="page-25-4"></span>
$$
\sup_{n \in \mathbb{N}} \inf_{\{\bar{\mu}_i^n\}} \mathbb{E}\left[J_{n,\neq}(\bar{L}_n) + \left(\frac{1}{n} - \frac{1-a}{\beta_n}\right) \mathcal{V}(\bar{L}_n) + \frac{1}{\beta_n} \sum_{i=1}^n \mathcal{R}\left(\bar{\mu}_i^n | e^{-(1-a)V} \ell\right)\right] < \infty. \tag{5.8}
$$

<span id="page-26-0"></span>Lemma 5.2. Let {µ¯ n i } be a sequence of controls such that the associated controlled empirical measures satisfy [\(5.8\)](#page-25-4). Assume also that <sup>V</sup> and <sup>W</sup> satisfy Assumptions [A](#page-4-2) and [C1.](#page-8-2) Then {L¯ <sup>n</sup>} is tight in P R d . Further, if Assumption <sup>C</sup>[3](#page-8-4) is also satisfied for some <sup>ψ</sup> <sup>∈</sup> <sup>Ψ</sup>, then {L¯ <sup>n</sup>} is tight on P<sup>ψ</sup> R d .

Proof. First, note that by [\(5.2\)](#page-24-3), <sup>J</sup>n,6=(L¯ <sup>n</sup>) can be rewritten as

$$
\frac{1}{2}\mathcal{J}_{\neq}(\bar{L}_n) + \frac{1}{4} \int_{(\mathbb{R}^d \times \mathbb{R}^d)_{\neq}} \left( \left( 1 - \frac{2(1-a)n}{\beta_n} \right) (V(\mathbf{x}) + V(\mathbf{y})) + W(\mathbf{x}, \mathbf{y}) \right) \bar{L}_n \left( d\mathbf{x} \right) \bar{L}_n \left( d\mathbf{y} \right)
$$

For large enough n, Assumption [A](#page-4-2) implies that all the integrands are bounded from below. Therefore, we have

<span id="page-26-1"></span>
$$
\sup_{n \in \mathbb{N}} \mathbb{E} \left[ \mathcal{J}_{\neq}(\bar{L}_n) \right] < \infty \qquad \text{and} \qquad \sup_{n \in \mathbb{N}} \mathbb{E} \left[ \frac{1}{\beta_n} \sum_{i=1}^n \mathcal{R} \left( \bar{\mu}_i^n | e^{-(1-a)V} \ell \right) \right] < \infty. \tag{5.9}
$$

Now, let the set A, sequence {rn} and lsc function γ : R d 7→ <sup>R</sup> be as in Assumption C1, and let <sup>A</sup><sup>1</sup> n and A<sup>2</sup> <sup>n</sup> be the associated sets defined therein. Then the integral J6=(Ln) can be decomposed as the sum of integrals over the following sets:

$$
A_n^1 \times A_n^2
$$
,  $(A_n^1 \times A_n^1)_{\neq}$ ,  $(A_n^2 \times A_n^2)_{\neq}$ ,  $A_n^2 \times A_n^1$ ,  $(A^c \times A^c)_{\neq}$ ,  $A \times A^c$ ,  $A^c \times A$ .

Each of these terms is bounded from below by direct application of Assumption [A,](#page-4-2) and since E[J6=(Ln)] is uniformly bounded from above we have that the expectation of each of them is also bounded from above.

To prove that {L¯ <sup>n</sup>} is tight, by Lemmas [3.2](#page-15-4) and [3.3](#page-15-5) it suffices to prove that E -R <sup>R</sup><sup>d</sup> <sup>γ</sup>(x)L¯ <sup>n</sup>(dx) is uniformly bounded in n. Note that

<span id="page-26-2"></span>
$$
\mathbb{E}\left[\int_{\mathbb{R}^d} \gamma(\mathbf{x}) \bar{L}_n(d\mathbf{x})\right] = \mathbb{E}\left[\int_{A^c} \gamma(\mathbf{x}) \bar{L}_n(d\mathbf{x})\right] + \mathbb{E}\left[\int_{A_n^1} \gamma(\mathbf{x}) \bar{L}_n(d\mathbf{x})\right] + \mathbb{E}\left[\int_{A_n^2} \gamma(\mathbf{x}) \bar{L}_n(d\mathbf{x})\right].
$$
 (5.10)

We now show that each of the three terms in the last inequality is uniformly bounded from above. By applying [\(2.17\)](#page-8-5) of Assumption [C1,](#page-8-2) we obtain for n ≥ 2,

$$
\mathbb{E}\left[\int_{A^c} \gamma(\mathbf{x}) \bar{L}_n(d\mathbf{x})\right] = \frac{1}{2} \mathbb{E}\left[\int_{\mathbb{R}^d \times \mathbb{R}^d} \left(\gamma(\mathbf{x}) I_{A^c}(\mathbf{x}) + \gamma(\mathbf{y}) I_{A^c}(\mathbf{y})\right) \bar{L}_n(d\mathbf{x}) \bar{L}_n(d\mathbf{y})\right]
$$
  
\n
$$
= \frac{n}{2(n-1)} \mathbb{E}\left[\int_{(\mathbb{R}^d \times \mathbb{R}^d)_{\neq}} \left(\gamma(\mathbf{x}) I_{A^c}(\mathbf{x}) + \gamma(\mathbf{y}) I_{A^c}(\mathbf{y})\right) \bar{L}_n(d\mathbf{x}) \bar{L}_n(d\mathbf{y})\right]
$$
  
\n
$$
\leq \frac{n}{2(n-1)} \mathbb{E}\left[\int_{(\mathbb{R}^d \times \mathbb{R}^d)_{\neq}} \left(V(\mathbf{x}) + V(\mathbf{y}) + W(\mathbf{x}, \mathbf{y})\right) \bar{L}_n(d\mathbf{x}) \bar{L}_n(d\mathbf{y})\right] + C
$$
  
\n
$$
\leq \mathbb{E}\left[\mathcal{J}_{\neq}(\bar{L}_n)\right] + C + |c|.
$$

By Assumption [C1](#page-8-2) we also have

$$
\mathbb{E}\left[\int_{A_n^1} \gamma(\mathbf{x}) \bar{L}_n(d\mathbf{x})\right] \leq \mathbb{E}\left[\int_{(A_n^1 \times A_n^1)_{\neq}} \left(V(\mathbf{x}) + V(\mathbf{y}) + W(\mathbf{x}, \mathbf{y})\right) \bar{L}_n(d\mathbf{x}) \bar{L}_n(d\mathbf{y})\right] + C
$$
  
$$
\leq \mathbb{E}[\mathcal{J}_{\neq}((\bar{L}_n)] + C + |c|.
$$

Due to [\(5.9\)](#page-26-1), the last two displays show that the first two terms on the right-hand side of [\(5.10\)](#page-26-2) are uniformly bounded. Finally for the third term, since ˆµ <sup>n</sup> = 1 n P<sup>n</sup> <sup>i</sup>=1 µ¯ n i , recalling (from Section [4.1\)](#page-18-0) that {X¯ <sup>n</sup> j }1≤j≤<sup>n</sup> are the controlled random variables with joint distribution <sup>P</sup>¯<sup>n</sup> (dx1, . . . , dxn), and using the tower property of conditional expectations, we have

$$
\mathbb{E}\left[\int_{A_n^2} \gamma(\mathbf{x}) \bar{L}_n(d\mathbf{x})\right] = \mathbb{E}\left[\frac{1}{n} \sum_{i=1}^n \int_{A_n^2} \gamma(\mathbf{x}) \delta_{X_i}(d\mathbf{x})\right] = \mathbb{E}\left[\frac{1}{n} \sum_{i=1}^n \int_{A_n^2} \gamma(\mathbf{x}) \bar{\mu}_i^n(d\mathbf{x})\right]
$$
$$
= \mathbb{E}\left[\int_{A_n^2} \gamma(\mathbf{x}) \hat{\mu}^n(d\mathbf{x})\right].
$$

Recalling that IA<sup>2</sup> n denotes the indicator function of the set A<sup>2</sup> n , by an extension of the formula that relates exponential integrals and relative entropy [\[13,](#page-37-1) Proposition 4.5.1], the bound [\(2.19\)](#page-8-6) in Assumption [C1](#page-8-2) (resp. Assumption [C3\)](#page-8-4), and [\(5.9\)](#page-26-1), we see that

$$
\mathbb{E}\left[\int_{A_n^2} \gamma(\mathbf{x})\hat{\mu}^n(d\mathbf{x})\right] \leq \frac{n}{\beta_n} \log \left(\mathbb{E}\left[\int_{\mathbb{R}^d} e^{\frac{\beta_n}{n} I_{A_n^2}(\mathbf{x})\gamma(\mathbf{x}) - (1-a)V(\mathbf{x})} \ell(d\mathbf{x})\right]\right) + \frac{n}{\beta_n} \mathbb{E}\left[\mathcal{R}\left(\hat{\mu}^n|e^{-(1-a)V}\ell\right)\right] \leq \frac{n}{\beta_n} \log \left(\int_{A_n^2} e^{\frac{\beta_n}{n}\gamma(\mathbf{x}) - (1-a)V(\mathbf{x})} \ell(d\mathbf{x}) + 1\right) + \frac{1}{\beta_n} \sum_{i=1}^n \mathbb{E}\left[\mathcal{R}\left(\bar{\mu}_i^n|e^{-(1-a)V}\ell\right)\right].
$$

The first term on the right-hand side is uniformly bounded by [\(2.19\)](#page-8-6) in Assumption [C1](#page-8-2) (resp. Assumption [C2\)](#page-8-1) and the second term is uniformly bounded by [\(5.9\)](#page-26-1). This concludes the proof.

#### <span id="page-27-0"></span>5.3 Proof of the lower bound

For the proof of the lower bound we use some auxiliary functionals on P(R d ). For a function F on R d ′ and M < <sup>∞</sup> we define <sup>F</sup> <sup>M</sup>(z) := min{F(z), M}. Let

$$
\mathcal{J}_{n,\neq}^{M}(\mu) := \frac{1}{2} \int_{(\mathbb{R}^{d} \times \mathbb{R}^{d})_{\neq}} \left( \left( 1 - \frac{(1-a)n}{\beta_{n}} \right) \left[ V^{M}(\mathbf{x}) + V^{M}(\mathbf{y}) \right] + W^{M}(\mathbf{x}, \mathbf{y}) \right) \bar{L}_{n}(\mathbf{dx}) \, \bar{L}_{n}(\mathbf{dy}),
$$
  
$$
\mathcal{J}_{n}^{M}(\mu) := \frac{1}{2} \int_{\mathbb{R}^{d} \times \mathbb{R}^{d}} \left( \left( 1 - \frac{(1-a)n}{\beta_{n}} \right) \left[ V^{M}(\mathbf{x}) + V^{M}(\mathbf{y}) \right] + W^{M}(\mathbf{x}, \mathbf{y}) \right) \bar{L}_{n}(\mathbf{dx}) \, \bar{L}_{n}(\mathbf{dy}),
$$
  
$$
\mathcal{J}^{M}(\mu) := \frac{1}{2} \int_{\mathbb{R}^{d} \times \mathbb{R}^{d}} \left( V^{M}(\mathbf{x}) + V^{M}(\mathbf{y}) + W^{M}(\mathbf{x}, \mathbf{y}) \right) \mu(\mathbf{dx}) \mu(\mathbf{dy}).
$$

These integrals are well defined for sufficiently large n because of Assumption [A.](#page-4-2) For every M, n ∈ N,

<span id="page-27-1"></span>
$$
\inf_{\{\bar{\mu}_i^n\}} \mathbb{E}\left[f\left(\bar{L}_n\right) + \mathcal{J}_{n,\neq}\left(\bar{L}_n\right) + \left(\frac{1}{n} - \frac{1-a}{\beta_n}\right) \mathcal{V}(\bar{L}_n) + \frac{1}{\beta_n} \sum_{i=1}^n \mathcal{R}\left(\bar{\mu}_i^n | e^{-(1-a)V} \ell\right)\right] \tag{5.11}
$$
\n
$$
\geq \inf_{\{\bar{\mu}_i^n\}} \mathbb{E}\left[f\left(\bar{L}_n\right) + \mathcal{J}_{n,\neq}^M\left(\bar{L}_n\right) + \left(\frac{1}{n} - \frac{1-a}{\beta_n}\right) \mathcal{V}(\bar{L}_n) + \frac{1}{\beta_n} \sum_{i=1}^n \mathcal{R}\left(\bar{\mu}_i^n | e^{-(1-a)V} \ell\right)\right].
$$

Let ǫ > 0 and {µ˜ n i } be such that

$$
C' > \inf_{\{\overline{\mu}_i^n\}} \mathbb{E}\left[f\left(\overline{L}_n\right) + \mathcal{J}_{n,\neq}\left(\overline{L}_n\right) + \left(\frac{1}{n} - \frac{1-a}{\beta_n}\right) \mathcal{V}(\overline{L}_n) + \frac{1}{\beta_n} \sum_{i=1}^n \mathcal{R}\left(\overline{\mu}_i^n | e^{-V}\ell\right)\right] + \epsilon
$$
  
\n
$$
\geq \mathbb{E}\left[f\left(\tilde{L}_n\right) + \mathcal{J}_{n,\neq}\left(\tilde{L}_n\right) + \left(\frac{1}{n} - \frac{1-a}{\beta_n}\right) \mathcal{V}(\tilde{L}_n) + \frac{1}{\beta_n} \sum_{i=1}^n \mathcal{R}\left(\tilde{\mu}_i^n | e^{-(1-a)V}\ell\right)\right]
$$
  
\n
$$
\geq \mathbb{E}\left[f\left(\tilde{L}_n\right) + \mathcal{J}_n^M\left(\tilde{L}_n\right) - \frac{3M}{n} + \left(\frac{1}{n} - \frac{1-a}{\beta_n}\right) \mathcal{V}(\tilde{L}_n) + \frac{1}{\beta_n} \sum_{i=1}^n \mathcal{R}\left(\tilde{\mu}_i^n | e^{-(1-a)V}\ell\right)\right],
$$

where C ′ is a finite upper bound, which exists by Remark [5.1](#page-25-5) and the boundedness of f, and the last inequality follows from [\(5.11\)](#page-27-1) and the fact L˜ <sup>n</sup> (dx) L˜ <sup>n</sup> (dy) puts mass 1/n on the diagonal x = y.

Owing to tightness (see Lemma [5.2\)](#page-26-0) we can extract a further subsequence of {(L˜ <sup>n</sup>, µˆn)}, which (with some abuse of notation) we denote again by {(L˜ <sup>n</sup>, <sup>µ</sup>ˆn)}, for which ˆµ<sup>n</sup> := <sup>1</sup> n P<sup>n</sup> <sup>i</sup>=1 µ˜ n i , that converges weakly to some limit (L, ˜ µˆ). Let M<sup>n</sup> be a sequence that goes to infinity such that limn→∞ Mn <sup>n</sup> = 0 and let m ∈ N. By Fatou's lemma, the nonnegativity of R(·|e −V ), the definition of V in [\(2.9\)](#page-6-5), and the fact that n/β<sup>n</sup> → 0, we have

$$
\liminf_{n \to \infty} \mathbb{E}\left[f\left(\tilde{L}_n\right) + \mathcal{J}_n^{M_n}\left(\tilde{L}_n\right) - \frac{3M_n}{n} + \left(\frac{1}{n} - \frac{1-a}{\beta_n}\right)\mathcal{V}(\bar{L}_n) + \frac{1}{\beta_n}\sum_{i=1}^n \mathcal{R}\left(\tilde{\mu}_i^n|e^{-(1-a)V}\ell\right)\right]
$$
\n
$$
\geq \liminf_{n \to \infty} \mathbb{E}\left[f\left(\tilde{L}_n\right) + \mathcal{J}_n^{M_m}\left(\tilde{L}_n\right)\right] = \mathbb{E}\left[f\left(\tilde{L}\right) + \mathcal{J}^{M_m}\left(\tilde{L}\right)\right].
$$

Since the above inequality holds for arbitrary m, using the monotone convergence theorem

$$
\liminf_{n \to \infty} \mathbb{E}\left[f\left(\tilde{L}_n\right) + \mathcal{J}_n^{M_n}\left(\tilde{L}_n\right) - \frac{3M_n}{n} + \left(\frac{1}{n} - \frac{1-a}{\beta_n}\right)\mathcal{V}(\bar{L}_n) + \frac{1}{\beta_n}\sum_{i=1}^n \mathcal{R}\left(\tilde{\mu}_i^n|e^{-(1-a)V}\ell\right)\right]
$$
\n
$$
\geq \mathbb{E}\left[f\left(\tilde{L}\right) + \mathcal{J}\left(\tilde{L}\right)\right] \geq \inf_{\mu \in S} \{f(\mu) + \mathcal{J}(\mu)\}.
$$

Since ǫ > 0 is arbitrary, this establishes [\(5.6\)](#page-25-6).

#### <span id="page-28-0"></span>5.4 Proof of the upper bound

We start by making an observation, whose proof is deferred to Appendix [F.](#page-36-0)

<span id="page-28-1"></span>Lemma 5.3. Suppose Assumptions [A](#page-4-2) and C hold, and let a ∈ [0, 1) be the associated constant. Given any µ ∈ P(R d ), there exists a sequence {µn} with each µ<sup>n</sup> ≪ ℓ such that the density ρ<sup>n</sup> := e (1−a)<sup>V</sup> dµn/dℓ is uniformly bounded, µ<sup>n</sup> <sup>w</sup><sup>→</sup> <sup>µ</sup> and <sup>J</sup> (µn) → J (µ). Furthermore, if <sup>µ</sup> ∈ Pψ(<sup>R</sup> d ) for some ψ ∈ Ψ, then we can assume in addition that dψ(µn, µ) → 0.

Now, let f be a bounded and continuous function on P(R d ) (or Pψ(R d )), let ǫ > 0 and let µ <sup>∗</sup> be such that

$$
f(\mu^*) + \mathcal{J}(\mu^*) \le \inf_{\mu \in S} \{ f(\mu) + \mathcal{J}(\mu) \} + \epsilon.
$$

We can also assume that R µ ∗ |e −(1−a)V ℓ < ∞, due to Assumption [C2](#page-8-1) and Lemma [5.3.](#page-28-1) Then let ˜µ n <sup>i</sup> = µ ∗ for all <sup>n</sup> <sup>∈</sup> <sup>N</sup> and <sup>i</sup> ∈ {1, ..., n}, and let the random variables <sup>X</sup>˜ <sup>n</sup> i , 1 ≤ i ≤ n, n ∈ N, be iid with distribution µ ∗ . By Lemma [4.4,](#page-20-5) the weak limit of L˜ <sup>n</sup> equals µ ∗ . Calculations very similar to those of [\(4.29\)](#page-24-2) yield

$$
\mathbb{E}\left[f\left(\tilde{L}_n\right) + \mathcal{J}_{n,\neq}\left(\tilde{L}_n\right) + \left(\frac{1}{n} - \frac{1-a}{\beta_n}\right)\mathcal{V}(\bar{L}_n) + \frac{1}{\beta_n}\sum_{i=1}^n \mathcal{R}\left(\mu^*|e^{-(1-a)V}\ell\right)\right] \n= \mathbb{E}\left[f\left(\tilde{L}_n\right)\right] + \frac{n-1}{n}\mathcal{J}(\mu^*) + \left(\frac{1}{n} - \frac{1-a}{\beta_n}\right)\mathcal{V}(\mu^*) + \frac{n}{\beta_n}\mathcal{R}\left(\mu^*|e^{-(1-a)V}\ell\right).
$$

Thus, L˜ n <sup>w</sup><sup>→</sup> <sup>µ</sup>, the dominated convergence theorem and the fact that n/β<sup>n</sup> <sup>→</sup> 0 imply

$$
\limsup_{n \to \infty} \left( \mathbb{E}\left[f\left(\tilde{L}_n\right)\right] + \frac{n}{n-1} \mathcal{J}(\mu^*) + \left(\frac{1}{n} - \frac{1-a}{\beta_n}\right) \mathcal{V}(\mu^*) + \frac{n}{\beta_n} \mathcal{R}\left(\mu^*|e^{-(1-a)V}\ell\right) \right)
$$

is equal to f (µ ∗ ) + J (µ ∗ ). Thus, we have shown that

$$
\limsup_{n \to \infty} \inf_{\{\bar{\mu}_i^n\}} \mathbb{E}\left[f\left(\bar{L}_n\right) + \mathcal{J}_{n,\neq}\left(\bar{L}_n\right) + \left(\frac{1}{n} - \frac{1-a}{\beta_n}\right) \mathcal{V}(\bar{L}_n) + \frac{1}{\beta_n} \sum_{i=1}^n \mathcal{R}\left(\bar{\mu}_i^n | e^{-(1-a)V} \ell\right)\right]
$$
\n
$$
\leq \limsup_{n \to \infty} \mathbb{E}\left[f\left(\tilde{L}_n\right) + \mathcal{J}_{n,\neq}\left(\tilde{L}_n\right) + \left(\frac{1}{n} - \frac{1-a}{\beta_n}\right) \mathcal{V}(\tilde{L}_n) + \frac{1}{\beta_n} \sum_{i=1}^n \mathcal{R}\left(\mu^* | e^{-(1-a)V} \ell\right)\right]
$$
\n
$$
= f(\mu^*) + \mathcal{J}(\mu^*)
$$
\n
$$
\leq \inf_{\mu \in S} \{f(\mu) + \mathcal{J}(\mu)\} + \epsilon.
$$

Since ǫ > 0 is arbitrary, we obtain the upper bound [\(5.7\)](#page-25-7), thus completing the proof of Theorem [2.9.](#page-9-2)

Acknowledgments. We would like to thank a referee of the first version of this article [\[14\]](#page-37-5) for pointing out a small technical error in Lemma 1.8 therein. However, this did not affect the validity of the core arguments in [\[14\]](#page-37-5) and, since we had in the meanwhile identified ways to extend the paper more substantially resulting in the current version, which no longer relied on this lemma, this did not have any ramifications for the current version. We would also like to thank both referees of the present article for their valuable feedback that led to improvements in the exposition.

### <span id="page-29-0"></span>A The Weak Convergence Approach to Large Deviations

Here, we provide a brief outline to the weak convergence approach to large deviations. The weak convergence approach to large deviations was initiated in the book [\[13\]](#page-37-1). Using a test function characterization and representations for exponential integrals in terms of relative entropy, it converts the problem of proving an LDP to that of analyzing the asymptotics of related variational problems, with the asymptotic analysis done via weak convergence. One of the original motivations for the approach was the expectation that, since weak convengence methods are well suited to the analysis of problems involving nonsmoothness and singular behaviors, it would be a natural tool for large deviation problems with similar features, as in the present paper.

A conceptual picture of the approach is as follows. Suppose we want to show a sequence of random variables {Xn} that take values in some space <sup>X</sup> satisfies a large deviation principle with rate function I : X → [0,∞] and speed {n}. Then under suitable structural assumptions on X , it is enough to show that for every bounded and continuous function f : X → R, as n → ∞,

<span id="page-29-1"></span>
$$
-\frac{1}{n}\log \mathbb{E}\left[e^{-f(X^n)}\right] \to \inf_{x \in \mathcal{X}}\left[f(x) + I(x)\right].\tag{A.1}
$$

Under minimal conditions for discrete index models and mild conditions for continuous models, one can prove convenient relative entropy-based variational representations of the form

$$
-\frac{1}{n}\log \mathbb{E}\left[e^{-f(X^n)}\right] = \inf \mathbb{E}\left[f(\bar{X}^n) + C(X^n : \bar{X}^n)\right],
$$

where X¯<sup>n</sup> is a "controlled" version of X<sup>n</sup> , C(X<sup>n</sup> : X¯<sup>n</sup> ) is a non-negative cost for perturbing from the original distribution to that of X¯<sup>n</sup> , and the infimum is over all possible perturbations. (For the most complete account of such representations, see [\[13\]](#page-37-1).) Typically, one can show that boundedness of the expected costs E -C(X<sup>n</sup> : X¯<sup>n</sup> ) will imply tightness of {X¯n}, and when proving a lower bound such boundedness can be assumed without loss since f is bounded. Assuming tightness, one then establishes the lower bound (which corresponds to the large deviation upper bound) by showing that if <sup>X</sup>¯<sup>n</sup> <sup>→</sup> <sup>X</sup>¯ in distribution, then lim infn→∞ E -C(X<sup>n</sup> : X¯<sup>n</sup> ) <sup>≥</sup> <sup>E</sup>[I(X¯)], and therefore

$$
\liminf_{n \to \infty} \mathbb{E}\left[f(\bar{X}^n) + C(X^n : \bar{X}^n)\right] \geq \mathbb{E}\left[f(\bar{X}) + I(\bar{X})\right] \geq \inf_{x \in \mathcal{X}} \left[f(x) + I(x)\right].
$$

Since {X¯n} is arbitrary, this gives the needed bound (in fact, in this part of the analysis one often identifies a candidate for the rate function).

The reverse bound is obtained as follows. Given any x ∗ that is within ε > 0 of the infimum of infx∈X [f(x) + I(x)], one identifies controls that will drive X¯<sup>n</sup> to x ∗ (recall that large deviations uses a law of large numbers scaling), and with costs that satisfy lim supn→∞ E -C(X<sup>n</sup> : X¯<sup>n</sup> ) ≤ I(x ∗ ). The reverse bound follows since ε > 0 is arbitrary, and together the bounds give [\(A.1\)](#page-29-1). To successfully carry out these steps, one typically needs a very good understanding of the law of large numnbers analysis of the original system {Xn}, since the weak convergence analysis ends up being a law of large numbers analysis of the controlled versions, and methods that are useful for the first problem can often be adapted to deal with the second.

### <span id="page-30-0"></span>B Proof of Lemma [2.6](#page-7-1)

The proof of Lemma [2.6](#page-7-1) is based on two preliminary results, established in Lemma [B.1](#page-30-1) and Lemma [B.2](#page-30-2) below.

<span id="page-30-1"></span>Lemma B.1. Let ν ∈ P (R <sup>m</sup>) and let ψ¯ : R <sup>m</sup> <sup>→</sup> <sup>R</sup><sup>+</sup> be measurable. Then

<span id="page-30-3"></span>
$$
\int_{\mathbb{R}^m} e^{\lambda \bar{\psi}(\mathbf{z})} \nu(d\mathbf{z}) < \infty \tag{B.1}
$$

for all λ < <sup>∞</sup> if and only if there exists a convex, increasing and superlinear function <sup>φ</sup>¯ : <sup>R</sup><sup>+</sup> <sup>→</sup> <sup>R</sup> such that

<span id="page-30-5"></span>
$$
\int_{\mathbb{R}^m} e^{\bar{\phi}(\bar{\psi}(\mathbf{z}))} \nu(d\mathbf{z}) < \infty. \tag{B.2}
$$

Proof. (⇒) If [\(B.1\)](#page-30-3) holds, for every k ∈ N we can find M<sup>k</sup> ∈ (0,∞) such that

$$
\int_{\{\mathbf{z}:\,\bar{\psi}(\mathbf{z})\geq M_k\}} e^{k\bar{\psi}(\mathbf{z})} \nu(d\mathbf{z}) < \frac{1}{2^k}.
$$

Without loss of generality, we can assume Mk+1 ≥ Mk, and limk→∞ M<sup>k</sup> = ∞. We then define a continuous function <sup>φ</sup>¯ according to dφ¯ (s) /ds <sup>=</sup> k, s <sup>∈</sup> (Mk, Mk+1), and <sup>φ</sup>¯ (s) = <sup>M</sup>1, s <sup>∈</sup> [0, M1], which implies lims→∞ φ¯(s) <sup>s</sup> <sup>=</sup> <sup>∞</sup> and also that <sup>φ</sup>¯ is convex and increasing. Finally, we have

$$
\int_{\mathbb{R}^m} e^{\bar{\phi}(\bar{\psi}(\mathbf{z}))} \nu(d\mathbf{z}) \leq e^{M_1} + \sum_{k=1}^{\infty} \int_{\{\mathbf{z} : \bar{\psi}(\mathbf{z}) \geq M_k\}} e^{k\bar{\psi}(\mathbf{z})} \nu(d\mathbf{z}) \leq e^{M_1} + \sum_{k=1}^{\infty} \frac{1}{2^k} < \infty.
$$

(⇐) Let <sup>φ</sup>¯ be as in the statement of the lemma. Since <sup>φ</sup>¯ satisfies lims→∞ φ¯(s) <sup>s</sup> = ∞, for every λ < ∞ there exists <sup>M</sup><sup>λ</sup> <sup>&</sup>lt; <sup>∞</sup> such that <sup>φ</sup>¯ (s) <sup>≥</sup> λs if <sup>s</sup> <sup>≥</sup> <sup>M</sup>λ. Then we have

$$
\int_{\mathbb{R}^m} e^{\lambda \bar{\psi}(\mathbf{z})} \nu(d\mathbf{z}) = \int_{\mathbb{R}^m} 1_{\{\bar{\psi}(\mathbf{z}) < M_\lambda\}} e^{\lambda \bar{\psi}(\mathbf{z})} \nu(d\mathbf{z}) + \int_{\mathbb{R}^m} 1_{\{\bar{\psi}(\mathbf{z}) \ge M_\lambda\}} e^{\lambda \bar{\psi}(\mathbf{z})} \nu(d\mathbf{z})
$$
\n
$$
\le e^{\lambda M_\lambda} + \int_{\mathbb{R}^m} e^{\bar{\phi}(\bar{\psi}(\mathbf{z}))} \nu(d\mathbf{z}) < \infty.
$$

<span id="page-30-2"></span>Lemma B.2. Let ν ∈ P (R <sup>m</sup>) and let ψ¯ : R <sup>m</sup> <sup>→</sup> <sup>R</sup><sup>+</sup> be measurable. Then

<span id="page-30-4"></span>
$$
\int_{\mathbb{R}^m} e^{\lambda \bar{\psi}(\mathbf{z})} \nu(d\mathbf{z}) < \infty \tag{B.3}
$$

for all λ < <sup>∞</sup> if and only if there exists a convex, increasing and superlinear function <sup>φ</sup>¯ : <sup>R</sup><sup>+</sup> <sup>→</sup> <sup>R</sup> and a constant C < ∞ such that for any µ ∈ P (R <sup>m</sup>),

<span id="page-30-6"></span>
$$
\int_{\mathbb{R}^m} \bar{\phi} \left( \bar{\psi} \left( \mathbf{z} \right) \right) \mu \left( d\mathbf{z} \right) \leq \mathcal{R} \left( \mu | \nu \right) + C. \tag{B.4}
$$

Proof. (⇒) First assume that [\(B.3\)](#page-30-4) holds. Then by the previous lemma there exists a positive convex function <sup>φ</sup>¯ : <sup>R</sup> <sup>→</sup> <sup>R</sup>, with lims→∞ φ¯(s) <sup>s</sup> <sup>=</sup> <sup>∞</sup> such that [\(B.2\)](#page-30-5) holds. Since <sup>−</sup>φ¯ <sup>≤</sup> 0, by using Proposition 4.5.1 in [\[13\]](#page-37-1) with <sup>k</sup> <sup>=</sup> <sup>−</sup>φ¯, we get

<span id="page-31-0"></span>
$$
\sup_{\mu \in \mathcal{P}(\mathbb{R}^m): \mathcal{R}(\mu|\nu) < \infty} \left\{ \int_{\mathbb{R}^m} \bar{\phi} \left( \bar{\psi} \left( \mathbf{z} \right) \right) \mu \left( d\mathbf{z} \right) - \mathcal{R} \left( \mu | \nu \right) \right\} = \log \int_{\mathbb{R}^m} e^{\bar{\phi} \left( \bar{\psi} \left( \mathbf{z} \right) \right)} \nu \left( d\mathbf{z} \right) < \infty, \tag{B.5}
$$

from which we obtain

$$
\int_{\mathbb{R}^m} \bar{\phi} \left( \bar{\psi} \left( \mathbf{z} \right) \right) \mu \left( d\mathbf{z} \right) \leq \mathcal{R} \left( \mu | \nu \right) + \log \int_{\mathbb{R}^m} e^{\bar{\phi} \left( \bar{\psi} \left( \mathbf{z} \right) \right)} \nu \left( d\mathbf{z} \right)
$$

for all µ ∈ P (R <sup>m</sup>) with <sup>R</sup> (µ|ν) <sup>&</sup>lt; <sup>∞</sup>. Thus, [\(B.4\)](#page-30-6) follows.

(⇐) For the converse, if we assume that [\(B.4\)](#page-30-6) is true, then we have

$$
\sup_{\mu \in \mathcal{P}(\mathbb{R}^m)} \left\{ \int_{\mathbb{R}^m} \bar{\phi} \left( \bar{\psi} \left( \mathbf{z} \right) \right) \mu \left( d\mathbf{z} \right) - \mathcal{R} \left( \mu | \nu \right) \right\} \leq C,
$$

and [\(B.5\)](#page-31-0) implies that log R <sup>R</sup><sup>m</sup> e <sup>φ</sup>¯(ψ¯(z))ν (dz) is bounded, which proves [\(B.3\)](#page-30-4).

Proof of Lemma [2.6.](#page-7-1) Consider the probability measure on R <sup>d</sup> <sup>×</sup> <sup>R</sup> <sup>d</sup> defined by

$$
\nu(d\mathbf{x}d\mathbf{y}) = \frac{1}{Z}e^{-(V(\mathbf{x})+V(\mathbf{y})+W(\mathbf{x},\mathbf{y}))}\ell(d\mathbf{x})\ell(d\mathbf{y}),
$$

where Z is the normalization constant that makes ν a probability measure; the finiteness of Z follows on setting λ = 0 in [\(2.13\)](#page-7-3). Since ψ satisfies [\(2.13\)](#page-7-3), we can apply Lemma [B.2](#page-30-2) with ψ¯(x, y) = ψ(x) + ψ(y) to conclude that there exists a convex and increasing function <sup>φ</sup>¯ : <sup>R</sup><sup>+</sup> 7→ <sup>R</sup> with lims→∞ <sup>φ</sup>¯(s)/s <sup>=</sup> <sup>∞</sup> such that for any ζ ∈ P(R <sup>d</sup> <sup>×</sup> <sup>R</sup> d ),

<span id="page-31-2"></span>
$$
\int_{\mathbb{R}^d \times \mathbb{R}^d} \bar{\phi} \left( \psi \left( \mathbf{x} \right) + \psi \left( \mathbf{y} \right) \right) \zeta \left( d\mathbf{x} d\mathbf{y} \right) \leq \mathcal{R} \left( \zeta | e^{-(V(\mathbf{x}) + V(\mathbf{y}) + W(\mathbf{x}, \mathbf{y}))} \ell(d\mathbf{x}) \ell(d\mathbf{y}) / Z \right) + C. \tag{B.6}
$$

We claim, and prove below, that for every ζ we have

$$
\int_{\mathbb{R}^d \times \mathbb{R}^d} \bar{\phi} \left( \psi \left( \mathbf{x} \right) + \psi \left( \mathbf{y} \right) \right) \zeta \left( d\mathbf{x} d\mathbf{y} \right) \leq 2\mathfrak{J}_a \left( \zeta \right) + \mathcal{R} \left( \zeta | e^{-(1-a)V} \ell \otimes e^{-(1-a)V} \ell \right) + \log Z + C. \tag{B.7}
$$

If the claim holds, then since <sup>φ</sup>¯ is increasing and since <sup>ψ</sup> and <sup>R</sup> are positive, for <sup>i</sup> = 1, <sup>2</sup>, we have

<span id="page-31-1"></span>
$$
\int_{\mathbb{R}^d} \bar{\phi} \left( \psi \left( \mathbf{x} \right) \right) \left( \pi^i_{\#} \zeta \right) \left( d\mathbf{x} \right) \le 2 \mathfrak{J}_a \left( \zeta \right) + 2 \mathcal{R} \left( \zeta | e^{-(1-a)V} \ell \otimes e^{-(1-a)V} \ell \right) + C + \log Z, \tag{B.8}
$$

where recall from Definition [3.6](#page-15-7) and Definition [2.2](#page-5-1) that π i #ζ represents the ith marginal of ζ. Adding the inequality [\(B.8\)](#page-31-1) for i = 1 and i = 2 we have

$$
\int_{\mathbb{R}^d} \bar{\phi} \left( \psi \left( \mathbf{x} \right) \right) \left( \pi^1_{\#} \zeta \right) \left( d\mathbf{x} \right) + \int_{\mathbb{R}^d} \bar{\phi} \left( \psi \left( \mathbf{x} \right) \right) \left( \pi^2_{\#} \zeta \right) \left( d\mathbf{x} \right) \le 4 \mathfrak{J}_a \left( \zeta \right) + 4 \mathcal{R} \left( \zeta | e^{-(1-a)V} \ell \otimes e^{-(1-a)V} \ell \right) + 2(C + \log Z).
$$

If ζ ∈ Π(µ, µ) then π 1 #ζ = π 2 #ζ = µ. Dividing both sides by 2, equation [\(2.12\)](#page-7-8), which is the conclusion of Lemma [2.6,](#page-7-1) holds with <sup>φ</sup> := [φ¯ <sup>−</sup> <sup>C</sup> <sup>−</sup> log <sup>Z</sup>]/2.

We now turn to the proof of the claim [\(B.8\)](#page-31-1). We can assume without loss of generality that ζ(dxdy) has a density with respect to the measure e −(1−a)V ℓ ⊗ e −(1−a)V ℓ, because otherwise [\(B.8\)](#page-31-1) holds trivially,

since W(x, y) + aV (x) + aV (y) is bounded from below. Denoting this density (with some abuse of notation) by ζ(x, y), [\(B.6\)](#page-31-2) then gives

$$
\int_{\mathbb{R}^d \times \mathbb{R}^d} \bar{\phi} \left( \psi (\mathbf{x}) + \psi (\mathbf{y}) \right) \zeta (d\mathbf{x} d\mathbf{y})
$$
\n
$$
\leq \int_{\mathbb{R}^d \times \mathbb{R}^d} \zeta (\mathbf{x}, \mathbf{y}) \log \frac{\zeta (\mathbf{x}, \mathbf{y})}{e^{-W(\mathbf{x}, \mathbf{y}) + a(V(\mathbf{x}) + V(\mathbf{y}))}/Z} e^{-(1-a)(V(\mathbf{x}) + V(\mathbf{y}))} \ell(d\mathbf{x}) \ell(d\mathbf{y}) + C
$$
\n
$$
\leq \int_{\mathbb{R}^d \times \mathbb{R}^d} \left( W (\mathbf{x}, \mathbf{y}) + a \left( V (\mathbf{x}) + V (\mathbf{y}) \right) \right) \zeta (\mathbf{x}, \mathbf{y}) e^{-(1-a)(V(\mathbf{x}) + V(\mathbf{y}))} \ell(d\mathbf{x}) \ell(d\mathbf{y})
$$
\n
$$
+ \int_{\mathbb{R}^d \times \mathbb{R}^d} \zeta (\mathbf{x}, \mathbf{y}) \log \zeta (\mathbf{x}, \mathbf{y}) e^{-(1-a)(V(\mathbf{x}) + V(\mathbf{y}))} \ell(d\mathbf{x}) \ell(d\mathbf{y}) + \log Z + C.
$$

Therefore, recalling the definition of J<sup>a</sup> in [\(2.6\)](#page-6-4), we have

$$
\int_{\mathbb{R}^d \times \mathbb{R}^d} \bar{\phi} \left( \psi \left( \mathbf{x} \right) + \psi \left( \mathbf{y} \right) \right) \zeta \left( d\mathbf{x} d\mathbf{y} \right) \leq 2\mathfrak{J}_a \left( \zeta \right) + \mathcal{R} \left( \zeta | e^{-(1-a)V} \ell \otimes e^{-(1-a)V} \ell \right) + \log Z + C,
$$

<span id="page-32-0"></span>which completes the proof of the claim, and therefore the lemma.

### C Proof of Lemma [3.5](#page-15-2)

We first establish a preliminary result in Lemma [C.1](#page-32-1) below. Let B(0, r) denote the closed ball about 0 of radius r, and let B<sup>c</sup> (0, r) denote its complement.

<span id="page-32-1"></span>Lemma C.1. Let ψ,Pψ(R d ), and d<sup>ψ</sup> be defined as in [\(2.3\)](#page-6-1)-[\(2.5\)](#page-6-6). Then dψ(µn, µ) → 0 as n → ∞ if and only if

<span id="page-32-3"></span>
$$
d_w(\mu_n, \mu) \to 0 \text{ and } \lim_{r \to \infty} \sup_n \left\{ \int_{B^c(0,r)} \psi(\mathbf{x}) \mu_n(d\mathbf{x}) \right\} = 0.
$$
 (C.1)

Furthermore, the metric space (Pψ(R d ), dψ) is separable.

Proof. (⇒). Let µn, n ∈ N, µ ∈ Pψ(R d ) be such that dψ(µn, µ) → 0. Since dw(µn, µ) ≤ dψ(µn, µ), this implies dw(µn, µ) → 0. Let ǫ > 0. By the integrability of ψ there exists r < ∞ such that R Bc(0,r) ψ(x)µ(dx) < <sup>ǫ</sup> 3 , and also µ(∂B(0, r)) = 0. Hence, we have

<span id="page-32-2"></span>
$$
\int_{B^c(0,r)} \psi(\mathbf{x})\mu_n(d\mathbf{x}) = \int_{B^c(0,r)} \psi(\mathbf{x})(\mu_n(d\mathbf{x}) - \mu(d\mathbf{x})) + \int_{B^c(0,r)} \psi(\mathbf{x})\mu(d\mathbf{x})
$$
\n
$$
\leq \left| \int_{\mathbb{R}^d} \psi(\mathbf{x})\mu_n(d\mathbf{x}) - \int_{\mathbb{R}^d} \psi(\mathbf{x})\mu(d\mathbf{x}) \right| + \left| \int_{B(0,r)} \psi(\mathbf{x})\mu_n(d\mathbf{x}) - \int_{B(0,r)} \psi(\mathbf{x})\mu(d\mathbf{x}) \right| + \frac{\epsilon}{3}.
$$
\n(C.2)

From the definition of d<sup>ψ</sup> in [\(2.5\)](#page-6-6) and the nonnegativity of dw, we can find n<sup>0</sup> ∈ N such that ∀n > n0, we have

$$
\left| \int_{\mathbb{R}^d} \psi(\mathbf{x}) \mu_n(d\mathbf{x}) - \int_{\mathbb{R}^d} \psi(\mathbf{x}) \mu(d\mathbf{x}) \right| < \frac{\epsilon}{3}.
$$

Since µ(∂B(0, r)) = 0, the µ-measure of the discontinuity points of x → ψ(x)1B(0,r) (x) is zero. Since ψ(x) can be extended outside of B(0, r) to obtain a bounded and continuous function on R d , the fact that dw(µn, µ) → 0 implies that there exists n ′ <sup>0</sup> < ∞ such that ∀n ≥ n ′ 0 ,

$$
\left| \int_{B(0,r)} \psi(\mathbf{x}) \mu_n(d\mathbf{x}) - \int_{B(0,r)} \psi(\mathbf{x}) \mu(d\mathbf{x}) \right| < \frac{\epsilon}{3}.\tag{C.3}
$$

Combining the above estimates for all terms in [\(C.2\)](#page-32-2) we obtain

$$
\sup_{n\geq \max\{n_0,n_0'\}}\left\{\int_{B^c(0,r)}\psi(\mathbf{x})\mu_n(d\mathbf{x})\right\}<\epsilon.
$$

Since <sup>ψ</sup> is integrable with respect to each <sup>µ</sup>n, for all <sup>n</sup> <sup>≤</sup> max{n0, n′ 0 } we can find an r<sup>n</sup> < ∞ such that R Bc(0,rn) ψ(x)µn(dx) < ǫ. Taking r ′ = max{r1, ..., rmax{n0,n′ 0 } , r} yields

<span id="page-33-0"></span>
$$
\sup_{n}\left\{\int_{B^{c}(0,r')}\psi(\mathbf{x})\mu_{n}(d\mathbf{x})\right\}<\epsilon.
$$

Since ǫ is arbitrary, the conclusion follows.

(⇐) To prove the converse, let µn, n ∈ N, µ ∈ Pψ(R d ), be such that [\(C.1\)](#page-32-3) holds. For ǫ > 0 there exists r < ∞ such that µ(∂B(0, r)) = 0 and

$$
\sup_n \left\{ \int_{B^c(0,r)} \psi(\mathbf{x}) \mu_n(d\mathbf{x}) \right\} < \frac{\epsilon}{3} \quad \text{and} \quad \int_{B^c(0,r)} \psi(\mathbf{x}) \mu(d\mathbf{x}) < \frac{\epsilon}{3},
$$

where the latter inequality holds because µ ∈ P<sup>ψ</sup> implies that ψ is µ-integrable. Thus, we have

$$
\left| \int_{\mathbb{R}^d} \psi(\mathbf{x}) \mu_n(d\mathbf{x}) - \int_{\mathbb{R}^d} \psi(\mathbf{x}) \mu(d\mathbf{x}) \right| \le \left| \int_{B(0,r)} \psi(\mathbf{x}) \mu_n(d\mathbf{x}) - \int_{B(0,r)} \psi(\mathbf{x}) \mu(d\mathbf{x}) \right| + \left| \int_{B^c(0,r)} \psi(\mathbf{x}) \mu_n(d\mathbf{x}) - \int_{B^c(0,r)} \psi(\mathbf{x}) \mu(d\mathbf{x}) \right| \le \left| \int_{B(0,r)} \psi(\mathbf{x}) \mu_n(d\mathbf{x}) - \int_{B(0,r)} \psi(\mathbf{x}) \mu(d\mathbf{x}) \right| + \frac{2\epsilon}{3}.
$$
 (C.4)

Since dw(µn, µ) → 0 and µ puts no mass on the set of discontinuities of the bounded function ψ(x)1B(0,r) (x), there exists n ′ <sup>0</sup> < ∞ such that

$$
\left| \int_{B(0,r)} \psi(\mathbf{x}) \mu_n(d\mathbf{x}) - \int_{B(0,r)} \psi(\mathbf{x}) \mu(d\mathbf{x}) \right| < \frac{\epsilon}{3}, \qquad \forall n \ge n_0'.
$$

Since ǫ is arbitrary, when substituted back into [\(C.4\)](#page-33-0), this shows that

$$
\lim_{n\to\infty}\left|\int_{\mathbb{R}^d}\psi(\mathbf{x})\mu_n(d\mathbf{x})-\int_{\mathbb{R}^d}\psi(\mathbf{x})\mu(d\mathbf{x})\right|=0.
$$

We now turn to the proof that Pψ(R d ) is separable. Let {xn} be a countable dense subset of <sup>R</sup> d , and define

$$
\mathcal{A}:=\left\{\sum_{i=1}^N c_n \delta_{\boldsymbol{x}_n} : c_n \in \mathbb{Q}_+, n=1,\ldots,N, \sum_{n=1}^N c_n = 1, \sum_{n=1}^N c_n \psi(\boldsymbol{x}_n) < \infty, N \in \mathbb{N}\right\},\
$$

where Q<sup>+</sup> is the set of nonnegative rational numbers, and observe that A is a countable subset of Pψ. We now show that A is dense in Pψ. Fix µ ∈ P<sup>ψ</sup> and ε > 0. Also, consider the space F of bounded, Lipschitz continuous functions on R d , equipped with the norm

$$
||f||_{BL} := \max \left( \sup_{\mathbf{x}, \mathbf{y} \in \mathbb{R}^d, \mathbf{x} \neq \mathbf{y}} \frac{|f(\mathbf{x}) - f(\mathbf{y})|}{|\mathbf{x} - \mathbf{y}|}, 2 \sup_{\mathbf{x} \in \mathbb{R}^d} |f(\mathbf{x})| \right),
$$

and let F<sup>1</sup> be the subspace of functions with ||f||BL ≤ 1. Then consider the metric on P(R d ) given by

$$
d_{BL}(\mu,\nu) := \sup_{f \in \mathbb{F}_1} \left| \int_{\mathbb{R}^d} f(\mathbf{x}) \mu(\mathbf{dx}) - \int_{\mathbb{R}^d} f(\mathbf{x}) \nu(\mathbf{dx}) \right|.
$$

In view of the definition of d<sup>ψ</sup> in [\(2.5\)](#page-6-6) and the fact that there exists a constant C < ∞ such that dw(µ, ν) ≤ C p dBL(µ, ν) (see [\[12,](#page-37-14) p. 396]), it suffices to show that there exists ν ∈ A such that

<span id="page-34-5"></span>
$$
\sup_{f \in \mathbb{F}_1 \cup \{\psi\}} \left| \int_{\mathbb{R}^d} f(\mathbf{x}) \mu(d\mathbf{x}) - \int_{\mathbb{R}^d} f(\mathbf{x}) \nu(d\mathbf{x}) \right| \le \varepsilon.
$$
 (C.5)

Recalling that ψ is continuous, for each n ∈ N, choose r<sup>n</sup> ∈ (0, ε/2) such that

<span id="page-34-0"></span>
$$
\sup_{\mathbf{x}\in B_{r_n}(\mathbf{x}_n)} |\psi(\mathbf{x}) - \psi(\mathbf{x}_n)| \le \frac{\varepsilon}{2},\tag{C.6}
$$

and note that then we also have

<span id="page-34-1"></span>
$$
\sup_{\mathbf{x}\in B_{r_n}(\mathbf{x}_n)}|f(\mathbf{x}) - f(\mathbf{x}_n)| \le r_n \le \frac{\varepsilon}{2}, \quad f \in \mathbb{F}_1.
$$
\n(C.7)

Now define B˜ <sup>n</sup> := Br<sup>n</sup> (xn) \ ∪n−<sup>1</sup> <sup>k</sup>=1Br<sup>k</sup> (xk) and b<sup>n</sup> := µ(B˜ <sup>n</sup>). Clearly, {B˜ <sup>n</sup>}n∈<sup>N</sup> forms a disjoint partition of R <sup>d</sup> and hence, P<sup>∞</sup> <sup>n</sup>=1 b<sup>n</sup> = 1. Moreover, by [\(C.6\)](#page-34-0) and [\(C.7\)](#page-34-1) we have for all f ∈ F<sup>1</sup> ∪ {ψ},

<span id="page-34-4"></span>
$$
\left|\sum_{n=1}^{\infty} b_n f(\mathbf{x}_n) - \int_{\mathbb{R}^d} f(\mathbf{x}) \mu(d\mathbf{x})\right| \le \sum_{n=1}^{\infty} b_n \sup_{\mathbf{x} \in \tilde{B}_n} |f(\mathbf{x}_n) - f(\mathbf{x})| \le \frac{\varepsilon}{2}.
$$
 (C.8)

We can assume without loss of generality that ψ is uniformly bounded from below away from zero. Since R <sup>R</sup><sup>d</sup> <sup>ψ</sup>(x)µ(dx) is finite, this implies <sup>P</sup><sup>∞</sup> <sup>n</sup>=1 bnψ(xn) < ∞, and hence there exists N ∈ N such that

<span id="page-34-3"></span>
$$
\sum_{n=N+1}^{\infty} b_n \le \frac{\varepsilon}{8(\psi(\mathbf{x}_1) \vee 1)} \quad \text{and} \quad \sum_{n=N+1}^{\infty} b_n \psi(\mathbf{x}_n) \le \frac{\varepsilon}{8}.
$$
 (C.9)

Now, for n = 2, . . . , N, choose c<sup>n</sup> ∈ Q<sup>+</sup> such that

<span id="page-34-2"></span>
$$
0 \le b_n - c_n \le \left(\frac{b_n}{\max(|\psi(\mathbf{x}_1) + \psi(\mathbf{x}_n)|, |\mathbf{x}_n - \mathbf{x}_1|)}\right) \frac{\varepsilon}{4},\tag{C.10}
$$

and set

$$
c_1 := b_1 + \sum_{n=2}^{N} (b_n - c_n) + \sum_{n=N+1}^{\infty} b_n.
$$

Observe that P<sup>N</sup> <sup>n</sup>=1 c<sup>n</sup> = P<sup>∞</sup> <sup>n</sup>=1 <sup>b</sup><sup>n</sup> = 1, and hence, <sup>c</sup><sup>1</sup> also lies in <sup>Q</sup>+. Set <sup>ν</sup> := <sup>P</sup><sup>N</sup> <sup>n</sup>=1 cnδx<sup>n</sup> . Then, for f ∈ F<sup>1</sup> ∪ {ψ}, using [\(C.10\)](#page-34-2) and [\(C.9\)](#page-34-3), we have

$$
\left| \int_{\mathbb{R}^d} f(\mathbf{x}) \nu(d\mathbf{x}) - \sum_{n=1}^{\infty} b_n f(\mathbf{x}_n) \right| = \left| \sum_{n=1}^N c_n f(\mathbf{x}_n) - \sum_{n=1}^{\infty} b_n f(\mathbf{x}_n) \right|
$$
  
$$
\leq \sum_{n=2}^N (b_n - c_n) |f(\mathbf{x}_n) - f(\mathbf{x}_1)| + \sum_{n=N+1}^{\infty} b_n |f(\mathbf{x}_1) - f(\mathbf{x}_n)|
$$
  
$$
\leq \frac{\varepsilon}{4} + |f(\mathbf{x}_1)| \sum_{n=N+1}^{\infty} b_n + \sum_{n=N+1}^{\infty} b_n |f(\mathbf{x}_n)| \leq \frac{\varepsilon}{2}.
$$

When combined with [\(C.8\)](#page-34-4) this establishes the desired inequality [\(C.5\)](#page-34-5).

Proof of Lemma [3.5.](#page-15-2) Let C < ∞ and let {µn} ⊂ Pψ(R d ) be a sequence such that T (µn) ≤ C for all n. Now limc→∞ infx:kxk=<sup>c</sup> φ(ψ(x)) = ∞ because limc→∞ infx:kxk=<sup>c</sup> ψ (x) = ∞ and lims→∞ φ(s) <sup>s</sup> = ∞. Hence, by Lemma [3.2](#page-15-4) with g = φ ◦ ψ, the sequence {µn} is tight in the weak topology, and we have

$$
\lim_{r \to \infty} \sup_{n} \left\{ \int_{B^c(0,r)} \psi(\mathbf{x}) \mu_n(d\mathbf{x}) \right\}
$$
\n
$$
= \lim_{r \to \infty} \sup_{n} \left\{ \int_{B^c(0,r)} \phi(\psi(\mathbf{x})) \frac{\psi(\mathbf{x})}{\phi(\psi(\mathbf{x}))} \mu_n(d\mathbf{x}) \right\}
$$
\n
$$
\leq \lim_{r \to \infty} \sup_{n} \left\{ \left( \sup_{x \in B^c(0,r)} \frac{\psi(\mathbf{x})}{\phi(\psi(\mathbf{x}))} \right) \int_{B^c(0,r)} \phi(\psi(\mathbf{x})) \mu_n(d\mathbf{x}) \right\} \leq C \lim_{r \to \infty} \sup_{\mathbf{x} \in B^c(0,r)} \frac{\psi(\mathbf{x})}{\phi(\psi(\mathbf{x}))} = 0.
$$

Thus, by the first assertion of Lemma [C.1,](#page-32-1) {µn} is tight in Pψ(R d ).

### <span id="page-35-0"></span>D Tightness Results

Proof of Lemma [4.4.](#page-20-5) Since R d is a Polish space, to verify weak convergence of a sequence of measures in P(R d ) it suffices to consider convergence of integrals with respect to the measures of functions f that are uniformly continuous. We use the fact [\[26,](#page-38-12) Lemma 3.1.4] that there is an equivalent metric m on R d , such that if Ub(R d , m) is the space of bounded uniformly continuous functions with respect to this metric, then there is a countable dense subset {fm}m∈<sup>N</sup> ⊂ Ub(R d , m). Define K<sup>m</sup> := supx∈R<sup>d</sup> |f<sup>m</sup> (x)| and ∆<sup>n</sup> m,i := f<sup>m</sup> X¯ <sup>n</sup> i − R <sup>R</sup><sup>d</sup> f<sup>m</sup> (x) ¯µ n i (dx). For any ε > 0, Chebyshev's inequality shows that

$$
\mathbb{P}\left[\left|\frac{1}{n}\sum_{i=1}^{n}\int_{\mathbb{R}^{d}}f_{m}\left(\mathbf{x}\right)\delta_{\bar{\mathbf{X}}_{i}^{n}}\left(d\mathbf{x}\right)-\frac{1}{n}\sum_{i=1}^{n}\int_{\mathbb{R}^{d}}f_{m}\left(x\right)\bar{\mu}_{i}^{n}\left(dx\right)\right|>\varepsilon\right]\leq\frac{1}{\varepsilon^{2}}\mathbb{E}\left[\frac{1}{n^{2}}\sum_{i,j=1}^{n}\Delta_{m,i}^{n}\Delta_{m,j}^{n}\right].
$$

Let F n <sup>j</sup> <sup>=</sup> <sup>σ</sup>(X¯ <sup>n</sup> i , i = 1, . . . , j). As we show below, by a standard conditioning argument, the off-diagonal terms vanish: for i > j,

$$
\mathbb{E}\left[\Delta_{m,i}^n \Delta_{m,j}^n\right] = \mathbb{E}\left[\mathbb{E}\left[\Delta_{m,i}^n \Delta_{m,j}^n \middle| \mathcal{F}_i^n\right]\right] = \mathbb{E}\left[\mathbb{E}\left[\Delta_{m,i}^n \middle| \mathcal{F}_i^n\right] \Delta_{m,j}^n\right] = 0.
$$

Since <sup>|</sup>∆<sup>n</sup> m,i| ≤ 2Km,

$$
\mathbb{P}\left[\left|\frac{1}{n}\sum_{i=1}^{n}\int_{\mathbb{R}^{d}}f_{m}\left(x\right)\delta_{\bar{X}_{i}^{n}}\left(dx\right)-\frac{1}{n}\sum_{i=1}^{n}\int_{\mathbb{R}^{d}}f_{m}\left(\mathbf{x}\right)\bar{\mu}_{i}^{n}\left(d\mathbf{x}\right)\right|>\varepsilon\right] \leq \frac{4K_{m}^{2}}{n\varepsilon^{2}}.
$$

Since (L¯<sup>n</sup> , µˆ n ) ⇒ L, ¯ µˆ and ε > 0 is arbitrary, by Fatou's lemma,

$$
\mathbb{P}\left[\int_{\mathbb{R}^d} f_m(x) \,\bar{L}\,(dx) = \int_{\mathbb{R}^d} f_m(x) \,\hat{\mu}\,(dx)\right] = 1.
$$

Now use the property that {fm, m <sup>∈</sup> <sup>N</sup>} is countable and dense to conclude that <sup>L</sup>¯ = ˆ<sup>µ</sup> a.s.

### <span id="page-35-1"></span>E Auxiliary Lemmas

<span id="page-35-2"></span>Lemma E.1. For every µ ∈ P(R d ) with no atoms, there exists a sequence {x <sup>n</sup>}n∈<sup>N</sup> <sup>⊂</sup> (<sup>R</sup> dn)6<sup>=</sup> such that J6=(Ln(x n ; ·)) → J (µ).

Proof. Let {Xn}n∈<sup>N</sup> be a sequence of independent R d -valued random variables with common law µ. For every <sup>n</sup> <sup>∈</sup> <sup>N</sup> let <sup>X</sup><sup>n</sup> := (X1, . . . , Xn), and denote Ln(X<sup>n</sup> , ·) simply by Ln. Then we have

$$
\mathbb{E}[\mathcal{J}_{\neq}(L_n)] = \frac{1}{2} \mathbb{E} \left[ \int_{(\mathbb{R}^d \times \mathbb{R}^d)_{\neq}} (V(\mathbf{x}) + V(\mathbf{y}) + W(\mathbf{x}, \mathbf{y})) L_n(\,d\mathbf{x}) L_n(\,d\mathbf{y}) \right]
$$
  
\n
$$
= \mathbb{E} \left[ \frac{1}{2n^2} \sum_{i=1}^n \sum_{j=1, j \neq i} (V(\mathbf{X}_i) + V(\mathbf{X}_j) + W(\mathbf{X}_i, \mathbf{X}_j)) \right]
$$
  
\n
$$
= \mathbb{E} \left[ \frac{1}{2n^2} \sum_{i=1}^n \sum_{j=1, j \neq i} \frac{1}{2} \int_{\mathbb{R}^d \times \mathbb{R}^d} (V(\mathbf{x}) + V(\mathbf{y}) + W(\mathbf{x}, \mathbf{y})) \mu(\,d\mathbf{x}) \mu(\,d\mathbf{y}) \right]
$$
  
\n
$$
= \frac{n}{n-1} \mathcal{J}(\mu).
$$

By the Glivenko-Cantelli Lemma (or Lemma [4.4\)](#page-20-5), L<sup>n</sup> converges in distribution to the deterministic measure µ. Hence using the Skorokhod Representation (and by introducing a new probability space if needed, but which we still denote as (Ω, F, P)) we can assume the almost sure convergence to µ. By Fatou's Lemma, we have

$$
\mathcal{J}(\mu) = \lim_{n \to \infty} \frac{n}{n-1} \mathcal{J}(\mu) = \liminf_{n \to \infty} \mathbb{E}[\mathcal{J}_{\neq}(L_n)] \geq \mathbb{E}[\liminf_{n \to \infty} \mathcal{J}_{\neq}(L_n)] \geq \mathbb{E}[\mathcal{J}_{\neq}(\mu)] = \mathbb{E}[\mathcal{J}(\mu)].
$$

From the above we get that a.s. lim infn→∞ J6=(Ln) = J (µ), and therefore trivially there exists a realization ω such that by setting x<sup>n</sup> = Xn(ω), J6=(Ln(xn; ·)) → J (µ).

### <span id="page-36-0"></span>F Proof of Lemma [5.3](#page-28-1)

Suppose Assumptions [A](#page-4-2) and C hold. Then there exists at least one probability measure µ such that J(µ) < ∞ (e.g., µ := ℓ|B/ℓ(B)) where B ⊂ A, with A as defined in Assumption [A,](#page-4-2) satisfies 0 < ℓ(B) < ∞). Also, by Assumption [C2,](#page-8-1) there exists a sequence {µn}, with each µ<sup>n</sup> ≪ ℓ, such that µ<sup>n</sup> <sup>w</sup><sup>→</sup> <sup>µ</sup> and J (µn) → J (µ). We now argue that we can assume without loss of generality that ρ<sup>n</sup> := e (1−a)<sup>V</sup> dµn/dℓ is uniformly bounded. For <sup>M</sup> <sup>∈</sup> <sup>N</sup>, define <sup>µ</sup><sup>M</sup> n (A) := R A ρ<sup>M</sup> n (x)e −(1−a)V (x)ℓ(dx)/ R R ρ<sup>M</sup> n (x)e −(1−a)V (x) ℓ(dx), where ρ<sup>M</sup> n := min(M, ρn) is clearly bounded. Since ρ<sup>M</sup> n is increasing with respect to M and the map (x, y) 7→ W(x, y) + V (x) + V (y) is bounded from below, by an application of the monotone convergence theorem, µ<sup>M</sup> n <sup>w</sup><sup>→</sup> <sup>µ</sup><sup>n</sup> and <sup>J</sup> (µ<sup>M</sup> n ) → J (µn) as M → ∞. The first claim of the lemma then follows from a standard diagonalization argument.

Next, fix ψ ∈ Ψ and suppose µ ∈ Pψ(R d ). We now show that the approximating sequence {µn} can be taken to satisfy dψ(µn, µ) → 0. To see this, first assume that µ has compact support K, and let Ke be the closure of Nǫ(K), the ǫ-neighborhood of K for some ǫ > 0. let {µn} be the approximating sequence obtained in the first part of the lemma, and set ˜µn(·) := µn(· ∩ Ke)/µn(Ke). Note that ˜µ<sup>n</sup> is well defined for all sufficiently large n since limn→∞ µn(Ke) = limn→∞ µn(Nǫ(K)) = µ(Nǫ(K)) = 1 because µ<sup>n</sup> <sup>w</sup><sup>→</sup> <sup>µ</sup>, µ(∂Nǫ(K)) = 0, and K is the support of µ. Similarly, for any closed set F, F ∩Ke is also closed, and hence by Portmanteau's theorem, lim sup<sup>n</sup> µn(F ∩ Ke) ≤ µ(F ∩ Ke) = µ(F). Since ˜µn(Ke) → 1, this implies that lim sup<sup>n</sup> µ˜n(F) ≤ µ(F), which (by another application of Portmanteau's theorem) shows that ˜µ<sup>n</sup> <sup>w</sup><sup>→</sup> <sup>µ</sup>. Furthermore, since all ˜µ<sup>n</sup> have the same compact support and converge to µ, and since ψ is continuous, dψ(˜µn, µ) → 0. Moreover,

$$
\lim_{n \to \infty} \mathcal{J}(\tilde{\mu}_n) = \lim_{n \to \infty} \int_{\mathbb{R}^d \times \mathbb{R}^d} (V(\mathbf{x}) + V(\mathbf{y}) + W(\mathbf{x}, \mathbf{y})) \tilde{\mu}_n(d\mathbf{x}) \tilde{\mu}_n(d\mathbf{y})
$$
  
\n
$$
= \lim_{n \to \infty} \frac{1}{\mu_n^2(K)} \lim_{n \to \infty} \frac{1}{2} \int_{\mathbb{R}^d \times \mathbb{R}^d} (V(\mathbf{x}) + V(\mathbf{y}) + W(\mathbf{x}, \mathbf{y})) \mu_n(d\mathbf{x}) \mu_n(d\mathbf{y})
$$
  
\n
$$
= \lim_{n \to \infty} \mathcal{J}(\mu_n) = \mathcal{J}(\mu).
$$

Finally, consider an arbitrary µ ∈ Pψ(R d ) (not necessarily with compact support) and let νn(·) := µ(·∩B(0,n)) <sup>µ</sup>(B(0,n)) . By dominated convergence <sup>R</sup> B(0,n) ψ (x) ν<sup>n</sup> (dx) → R <sup>R</sup><sup>d</sup> ψ (x) µ (dx), which shows that dψ(νn, µ) → 0. Since we also have J (νn) → J (µ), the desired approximating measures can be found by combining the two approximations and using a diagonalization argument.

### <span id="page-37-9"></span>References

- [1] L. Ambrosio, N. Gigli, G. Savare. Gradient Flows in Metric Spaces and in the Spaces of Probability Measures. In Computer Vision, 1995. Proceedings., Fifth International Conference on, Lectures in Mathematics. ETH Z¨urich, page 334, Basel, 2008. Birkhauser.
- <span id="page-37-11"></span><span id="page-37-3"></span>[2] M. Anttila, K. Ball and I. Perisinnaki. The central limit problem for convex bodies, Transactions of the American Mathematical Society, 355, 12:4723–2735, 2003.
- <span id="page-37-2"></span>[3] G. Ben Arous and A. Guionnet. Large deviations for Wigner's law and Voiculescu's non-commutative entropy. Probability Theory and Related Fields, 108(4):517–542, 1997.
- <span id="page-37-6"></span>[4] G. Ben Arous and O. Zeitouni. Large deviations from the circular law. ESAIM: Probability and Statistics, 2:123–134, 1998.
- <span id="page-37-8"></span>[5] R. J. Berman. On Large Deviations for Gibbs Measures, Mean Energy and Gamma-Convergence. Constructive Approximation, 48:3–30, 2018.
- <span id="page-37-12"></span>[6] P. Billingsley. Convergence of Probability Measures, Wiley Series in Probability and Mathematical Statistics, John Wiley and Sons, 1968.
- <span id="page-37-13"></span>[7] A. Braides. Gamma-Convergence for Beginners. Oxford University Press, 2002.
- <span id="page-37-0"></span>[8] A. Budhiraja and P. Dupuis. Analysis and Approximation of Rare Events: Representations and Weak Convergence Methods. Springer-Verlag, 2019.
- [9] D. Chafa¨ı, N. Gozlan, and PA. Zitt. First-order global asymptotics for confined particles with singular pair repulsion. The Annals of Applied Probability, 24(6):2371–2413, 2014.
- <span id="page-37-7"></span>[10] D. Chafa¨ı, D. Garc´ıa-Zelada and P. Jung, Macroscopic and edge behavior of a planar jellium <http://arxiv.org/abs/1909.00613>, 2019.
- <span id="page-37-10"></span>[11] A. Dembo and O. Zeitouni. Large Deviations Techniques and Applications, volume 38 of Stochastic Modelling and Applied Probability. Springer, New York, 2nd edition, 1987.
- <span id="page-37-14"></span><span id="page-37-1"></span>[12] R. M. Dudley. Real analysis and probability, volume 74 of Cambridge Studies in Advanced Mathematics. Cambridge University Press, 2002.
- <span id="page-37-5"></span>[13] P. Dupuis and RS S. Ellis. A Weak Convergence Approach to the Theory of Large Deviations. John Wiley & Sons, 1997.
- [14] P. Dupuis, V. Laschos and K. Ramanan. Large deviations for empirical measures generated by Gibbs measures with singular energy functionals. Arxiv Preprint, https://arxiv.org/abs/1511.06928v1, 2015.
- <span id="page-37-4"></span>[15] N. Gantert, S.Soojin Kim and K. Ramanan. Large deviations for random projections of ℓ <sup>p</sup> balls, Annals of Probability, 45, 4419–4476, 2017.

- <span id="page-38-3"></span>[16] N. Gantert, S.Soojin Kim and K. Ramanan. Cram´er's theorem is atypical, In "Advances in the mathematical sciences: Research from the 2015 association for women in mathematics symposium", Editors, G. Letzter, K. Lauter, E. Chambers, N. Flournoy, J.E. Grigsby, C. Martin, K. Ryan and K. Trivisa, Springer International Publishing, pp. 253–270, 2016.
- <span id="page-38-4"></span><span id="page-38-0"></span>[17] C. Gardiner. Stochastic Methods: A Handbook for the Natural and Social Sciences. Springer, 2010.
- <span id="page-38-5"></span>[18] D. Garc´ıa-Zelada. A large deviation principle for a natural sequence of point processes on a Riemannian two-dimensional manifoldPro Mathematica ,30(5):23–50, 2018
- [19] D. Garc´ıa-Zelada. A large deviation principle for empirical measures on Polish spaces: Application to singular Gibbs measures on manifolds. Annales de l'institut Henri Poincare (B) Probability and Statistics, 55(3):1377-1401, 2018.
- <span id="page-38-9"></span><span id="page-38-2"></span>[20] A. Hardy. A note on large deviations for 2D Coulomb gas with weakly confining potential. Electronic Communications in Probability, 17:1–12, 2012.
- <span id="page-38-1"></span>[21] S.S. Kim. Problems at the Interface of Probability and Convex Geometry: Random Projections and Constrained Processes. PhD thesis, Brown University, 2017.
- <span id="page-38-6"></span>[22] S.S. Kim and K. Ramanan. An asymptotic thin shell condition and large deviations for multidimensional projections. Arxiv Preprint, https://arxiv.org/abs/1912.13447, 2019.
- <span id="page-38-10"></span>[23] M. Mariani. A Gamma-convergence approach to large deviations. arXiv preprint [arXiv:1204.0640](http://arxiv.org/abs/1204.0640), 2012.
- <span id="page-38-11"></span>[24] D.Petz and F.Hiai. Logarithmic energy as an entropy functional. Contemporary Mathematics, 1998.
- <span id="page-38-12"></span>[25] S. Serfaty. Coulomb Gases and GinzburgLandau Vortices. European Mathematical Society Publishing House, Zuerich, Switzerland, 2015.
- <span id="page-38-8"></span>[26] D.W. Stroock. Probability theory, an analytic view. Cambridge University Press, 1993.
- <span id="page-38-7"></span>[27] R. Wang, X. Wang, and L. Wu. Sanov's theorem in the Wasserstein distance: A necessary and sufficient condition. Statistics & Probability Letters, 80(5-6):505–512, 2010.
- [28] C. Villani. Topics in Optimal Transportation Graduate Studies in Mathematics 58,2003.