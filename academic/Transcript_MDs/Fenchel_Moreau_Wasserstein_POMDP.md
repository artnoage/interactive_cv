# A Fenchel-Moreau-Rockafellar type theorem on the Kantorovich-Wasserstein space with Applications in Partially Observable Markov Decision Processes

Vaios Laschos<sup>∗</sup> Klaus Obermayer<sup>∗</sup> Yun Shen<sup>∗</sup> Wilhelm Stannat†

March 16, 2018

#### Abstract

By using the fact that the space of all probability measures with finite support can be somehow completed in two different fashions, one generating the Arens-Eells space and another generating the Kantorovich-Wasserstein (Wasserstein-1) space, and by exploiting the duality relationship between the Arens-Eells space with the space of Lipschitz functions, we provide a dual representation of Fenchel-Moreau-Rockafellar type for proper convex functionals on Wasserstein-1. We retrieve dual transportation inequalities as a Corollary and we provide examples where the theorem can be used to easily prove dual expressions like the celebrated Donsker-Varadhan variational formula. Finally our result allows to write convex functions as the supremum over all linear functions that are generated by roots of its conjugate dual, something that we apply to the field of Partially observable Markov decision processes (POMDPs) to approximate the value function of a given POMDP by iterating level sets. This extends the method used in [Smallwood and Sondik](#page-19-0) [\(1973](#page-19-0)) for finite state spaces to the case were the state space is a Polish metric space.

Key words: Wasserstein metric; conjugate duality; Fenchel-Moreau-Rockafellar theorem; Donsker-Varadhan variational formula; weighted norm; optimal control; partially observable Markov decision processes

MSC2000: 90C40, 90C46, 90C25, 46B10

### 1 Introduction

Dual representation, of the Fenchel-Moreau-Rockafellar type (see e.g., [Bot \(2010](#page-18-0)); [Ioan-Bot et al.](#page-18-1) [\(2009](#page-18-1)); [Z˘alinescu \(2002](#page-19-1))), plays an important role in convex analysis and has wide applications in various fields [\(Borwein and Lewis, 2006;](#page-18-2) [Boyd and Vandenberghe](#page-18-3), [2004](#page-18-3)). In this paper, we are interested in a conjugate dual representation of functions on probability measures, for which the "choice of dual space" will allow for real-world applications in the field of Partially observable Markov decision processes (POMDPs) along the lines of [Smallwood and Sondik \(1973\)](#page-19-0). In that direction, we are going to use the special connection of the Wasserstein-1 space with the space of Lipschitz functions.

More specifically, for (X, d) being a Polish space, (P1(X), W1) the Wasserstein-1 space over X, and L (X) the space of all real-valued Lipschitz functions on (X, d), the *conjugate function* ρ : L (X) → R¯ of a function φ : P1(X) → R¯ is defined as

<span id="page-0-0"></span>
$$
\rho(f) := \sup_{\mu \in \mathscr{P}_1(\mathsf{X})} \left( \int f d\mu - \phi(\mu) \right) \tag{1}
$$

<sup>∗</sup>Fakult¨at Elektrotechnik und Informatik, and Bernstein Center for Computational Neuroscience, Technische Universit¨at Berlin, Marchstr. 23, 10587, Berlin, Germany (yun.shen3@gmail.com, vaios.laschos@tu-berlin.de, klaus.obermayer@mailbox.tu-berlin.de).

<sup>†</sup> Institut f¨ur Mathematik, and Bernstein Center for Computational Neuroscience, Technische Universit¨at Berlin, Straße des 17. Juni 136, 10623, Berlin, Germany (stannat@math.tu-berlin.de).

and the *second conjugate function* φ c : P1(X) → R¯ is defined as

$$
\phi^{c}(\mu) := \sup_{f \in \mathscr{L}(X)} \left( \int f d\mu - \rho(f) \right). \tag{2}
$$

<span id="page-1-0"></span>A justification that ρ is well defined and proper can be found in the proof of [\(Ioan-Bot et al.](#page-18-1), [2009,](#page-18-1) Theorem 2.3.5). The first main result of this paper is the following conjugate duality. Theorem 1.1. *Let* φ : P1(X) → R¯ *be a proper convex function on* (P1(X), W1), *i.e. a convex and lower semicontinuous function, satisfying* φ(µ) > −∞ *for all* µ ∈ P1(X) *and* φ(µ0) ∈ R *for some* µ<sup>0</sup> ∈ P1(X)*. Then* φ(µ) = φ c (µ)*,* ∀µ ∈ P1(X)*.*

In [Villani \(2009](#page-19-2), Theorem 5.26), one has to assume that φ(µ) = φ c (µ), were the conjugates there are defined by taking the supremum over Cb(X), in order to establish a pair of dual inequalities connecting an optimal transport distance to φ(µ). Theorem [1.1](#page-1-0) implies that, in the case of the Wasserstein-1 distance, this assumption is always satisfied, provided that L (X) is used in place of Cb(X) for defining the conjugate dual. We will continue by providing a Wasserstein-1 specific version of [Villani \(2009,](#page-19-2) Theorem 5.26), and an example of a pair of well known dual functions where is it very simple to calculate ρ(µ), but the known proofs of φ <sup>c</sup> = φ, are technically more complicated.

<span id="page-1-3"></span>Corollary 1.2. *Let* φ : P1(X) → R¯ *be a proper convex function on* (P1(X), W1). *Let also* ρ *be its conjugate as in* [\(1\)](#page-0-0)*. Let finally* Φ *a real increasing and convex function with* Φ(0) = 0. *We have*

$$
\Phi(W_1(\mu,\nu)) \le \phi(\mu), \forall \mu \in \mathcal{P}_1(\mathsf{X}) \Leftrightarrow \rho\left(\int_X t f d\nu - tf - \Phi^*(t)\right) \le 0, \forall f \in [\mathscr{L}(\mathsf{X})]_1, t \in \mathbb{R}
$$

*where* Φ ∗ *is the Legendre dual, i.e. is given by the formula* Φ ∗ (s) = sup{st − Φ(t)}, *and* [L (X)]<sup>1</sup> *is the set of all Lipschitz functions with constant 1 (see next section for definition).*

The proof of the Corollary is straightforward and can be found in the Appendix. We would like to remark that [L (X)]<sup>1</sup> can be substituted with any subset A of [L (X)]<sup>1</sup> that satisfies A + R = [L (X)]1. We proceed now with an example.

*Example* 1.3*.* We will show that a direct application of Theorem [1.1](#page-1-0) can provide the celebrated Donsker-Varadhan variational formula, which has many fundamental applications in the theory of large deviations (see for example [Dupuis and](#page-18-4) Ellis [\(1997](#page-18-4)), where a whole class of large deviation principles are proved by applying the formula) and in statistical physics in general.

It is known that the following pair of dual equation hold:

$$
\log \int_{\mathsf{X}} e^g d\nu = \sup_{\mu \in \mathcal{P}(\mathsf{X})} \left\{ \int_{\mathsf{X}} g d\mu - \mathcal{R}(\mu|\nu) \right\}, \qquad \forall g \in C_b(\mathsf{X}) \tag{3}
$$

<span id="page-1-1"></span>and

$$
\mathcal{R}(\mu|\nu) = \sup_{g \in C_b(\mathsf{X})} \left\{ \int_{\mathsf{X}} g d\mu - \log \int_{\mathsf{X}} e^g d\nu \right\}, \qquad \forall \mu \in \mathcal{P}(\mathsf{X}) \tag{4}
$$

where R(µ|ν) is the relative entropy functional given by

$$
\mathcal{R}(\mu|\nu) = \begin{cases} \int_{X} \frac{d\mu}{d\nu} \log\left(\frac{d\mu}{d\nu}\right) d\nu & \text{if } \mu << \nu, \\ \infty & \text{otherwise.} \end{cases}
$$

As it is shown in Lemma [5.1](#page-16-0) in the Appendix, the first formula is straightforward to prove, even when Cb(X) is replaced by L (X) (the original proof is even simpler and can be found in page 34 of [Dupuis and Ellis \(1997](#page-18-4)) ). On the other hand, the second requires a more technical proof as one can see in [\(Dupuis and Ellis, 1997,](#page-18-4) Lemma 1.4.3.). By applying Theorem [1.1,](#page-1-0) we get the following alternative variational form for the relative entropy, i.e.:

<span id="page-1-2"></span>
$$
\mathcal{R}(\mu|\nu) = \sup_{g \in \mathcal{L}(X)} \left\{ \int_X g d\mu - \log \int_X e^g d\nu \right\}.
$$
 (5)

If one wishes to further retrieve [\(4\)](#page-1-1) from [\(5\)](#page-1-2), then it is a matter of a simple approximation argument as it is illustrated in Lemma [5.2.](#page-17-0) Finally, applying Corollary [1.2](#page-1-3) with Φ(t) = <sup>1</sup> 2 t 2 on our example, we can retrieve Bobkov and G¨otze theorem [\(Bobkov and G¨otze](#page-18-5), [1999](#page-18-5), Theorem 1.3), i.e.

$$
\int_{X} e^{tf} d\nu \le e^{ct^2/2}, \quad \forall f \in \left\{ f \in [\mathcal{L}(X)]_1 \middle| \int_{X} f d\nu = 0 \right\}, t \in \mathbb{R} \quad \Leftrightarrow
$$
$$
W_1(\mu, \nu) \le \frac{1}{c} \sqrt{\mathcal{R}(\mu|\nu)}, \quad \forall \mu \in \mathcal{P}_1(X).
$$

One could probably derive more refined versions of the inequality by playing around with the choice of Φ.

Another fundamental application of Theorem [1.1](#page-1-0) is to derive a conjugate dual form for the optimality equation for POMDPs. In order to do that we first are going to show that each function that satisfies the condition in Theorem [1.1](#page-1-0) has a representation as a supremum over a suitable class of linear functionals. More specifically we have the following.

Let φ be a function on P1(X) and ρ be its conjugate as in [\(1\)](#page-0-0). Consider the following sets

$$
\mathcal{N}_{\phi} := \{ f \in \mathscr{L}(\mathsf{X}) | \rho(f) = 0 \}, \text{ and}
$$
  
$$
\mathcal{N}_{\phi} := \{ f \in \mathscr{L}(\mathsf{X}) | \rho(f) \le 0 \} = \left\{ f \in \mathscr{L}(\mathsf{X}) \middle| \int f d\mu \le \phi(\mu), \forall \mu \in \mathscr{P}_1(\mathsf{X}) \right\}.
$$

We call N<sup>φ</sup> the *null level-set of* φ, whereas the latter set N¯<sup>φ</sup> is called the *acceptance set of* φ (cf. [\(F¨ollmer and Schied](#page-18-6), [2004](#page-18-6), Section 4.1)). Note that since ρ is convex and lower semicontinuous, N¯<sup>φ</sup> is convex and closed (see e.g. [\(Ioan-Bot et al.](#page-18-1), [2009](#page-18-1), Theorem 2.2.9)). We have the following dual representation.

<span id="page-2-0"></span>Corollary 1.4. *Let* φ : P1(X) → R¯ *be a function satisfying the condition in Theorem [1.1.](#page-1-0) Then*

$$
\phi(\mu) = \sup_{f \in \mathcal{N}_{\phi}} \int f d\mu = \sup_{f \in \bar{\mathcal{N}}_{\phi}} \int f d\mu.
$$

The proof is given in the end of the next section. Before we proceed we will provide some background on POMDPS and we are going to explain how Corollary [1.4](#page-2-0) is meant to be used in that setting.

A POMDP is a tupe of contrroled stochastic processes where it is assumed that the system dynamics are determined by a *Markov process*, but the agent cannot directly observe the underlying state. POMDPs have important applications in various fields, such as operations research [\(Lovejoy, 1991](#page-19-3)), robotics [\(Pineau et al., 2006](#page-19-4)) and artificial intelligence [\(Kaelbling et al.](#page-19-5), [1998](#page-19-5)). It is known that a POMDP can be reduced to a standard *Markov decision process* (MDP) by using appropriate probability distributions over the hidden states. We refer to [Sondik \(1978](#page-19-6)) for finite spaces, to [Sawaragi and Yoshikawa \(1970](#page-19-7)) for countable spaces, and to [Hern´andez-Lerma \(1989](#page-18-7), Chapter 4) and [Feinberg et al. \(2016](#page-18-8)) for Borel spaces.

In the setting of finite state spaces with a discounted infinite-horizon objective, the value function encoding the maximum reward can be found by solving the following equation

$$
\phi(\mu) = \max_{a} \left\{ \tilde{r}(\mu, a) + \alpha \sum_{y} \phi(\mu'(\mu, a, y)) \left( \sum_{x'} P(x'|\mu, a) Q(y|x', a) \right) \right\}, \forall \mu \in \mathscr{P}(\mathsf{X}).
$$
 (6)

Here, x ′ , a and y denote the hidden (or latent) state, the action and the observation, respectively, and µ ∈ P(X) is the distribution over states, while µ ′ is the posterior distribution of the successive state given by

<span id="page-2-1"></span>
$$
\mu'(\cdot|\mu, a, y) = \frac{P(\cdot|\mu, a)Q(y|\cdot, a)}{\sum_{x'} P(x'|\mu, a)Q(y|x', a)}.
$$

P controls the transition probability between states, Q models the observation probability of y given states and actions, r denotes the reward function, and α ∈ (0, 1) serves as a discount factor. A formal introduction of POMDPs on Borel spaces can be found in Section [3.2.](#page-9-0)

In spite of knowing the existence of such a theoretical solution, POMDPs were notoriously difficult to solve in practice [\(Shani et al., 2013\)](#page-19-8). In the case where the underlying space is finite, a fast algorithm called *point-based value iteration* [\(Pineau et al., 2006](#page-19-4)) was designed to overcome this numerical difficulty. This algorithm is mainly based on the property first observed by [Smallwood and Sondik \(1973](#page-19-0)), that the optimal solution to equation [\(6\)](#page-2-1) can be arbitrarily well approximated by a function of the following *dual representation*

<span id="page-3-0"></span>
$$
\phi(\mu) = \max_{h \in N} \sum_{x} h(x)\mu(x),\tag{7}
$$

where N can be chosen to be a finite collection of real functions on the hidden state space.

To our best knowledge, it is still an open question whether a similar approximation is also possible for POMDPs on continuous state spaces. The second major contribution of this paper is to provide an affirmative answer to this open question (see Theorem [4.19\)](#page-16-1), by applying the conjugate duality on Wasserstein-1 spaces that we obtained in Theorem [1.1.](#page-1-0) We would like to remark, that contrary to the finite state space case, the set N appearing in the counterpart of [\(7\)](#page-3-0) is uncountable, so a computable algorithm is still elusive, and it remains an open problem to find one. However, new advances in the field of neural networks involving the Wasserstein-1 distance, made substitution of collections of Lipschitz functions by appropriate finite sets a necessity [\(Arjovsky, Chintala and Bottou](#page-18-9), [2017\)](#page-18-9), and we are planning to perform further research in the immediate future.

Preliminaries A *Polish space* (X, d) is a complete separable metric space and a *Borel space* is a Borel subset of a Polish space. We denote by Cb(X) the set of all real bounded continuous functions on X. We further denote the set of all probability measures on X by P(X). Furthermore, we define the set

<span id="page-3-1"></span>
$$
\mathscr{P}_1(\mathsf{X}) := \left\{ \mu \in \mathscr{P}(\mathsf{X}) \; \middle| \; \int d(x_0, x) \mu(dx) < \infty \right\},\tag{8}
$$

where x<sup>0</sup> ∈ X is arbitrary. If Y is a Borel space, its Borel σ-algebra is denoted by B(Y).

### 2 A conjugate duality on the Wasserstein-1 space

### 2.1 The Wasserstein-1 space

Let (X, d) be a Polish space with metric d. The Wasserstein-1 space over (X, d) is the set P1(X), defined in [\(8\)](#page-3-1), equipped with the *Wasserstein-1 metric* given by

$$
W_1(\mu, \nu) := \inf \{ \mathbb{E} \left[ d(X, Y) \right] \mid \text{law}(X) = \mu, \text{law}(Y) = \nu \}.
$$
 (9)

For any real-valued function f : X → R, its Lipschitz seminorm is defined as

$$
||f||_{\text{Lip}} := \sup_{x \neq y} \frac{|f(x) - f(y)|}{d(x, y)}
$$

Denote by L (X) := {f : X → R | kfkLip < ∞} the space of all real-valued Lipschitz functions on X and by [L (X)]<sup>1</sup> := {f ∈ L | kfkLip ≤ 1} the unit ball of L (X). Then, it can be shown [\(Villani](#page-19-2), [2009](#page-19-2), Chapter 5) that W<sup>1</sup> has the following representation:

$$
W_1(\mu,\nu) = \sup_{f \in [\mathscr{L}(X)]_1} \left( \int f d\mu - \int f d\nu \right). \tag{10}
$$

<span id="page-3-2"></span>.

We have the following property [\(Villani, 2009](#page-19-2), Theorem 6.18): *If* (X, d) *is Polish,* (P1(X), W1) *is also Polish*. In the sequel, we are going to make use of the following set D(X) of all probability measures with finite support. More specifically, we define

$$
\mathscr{D}(\mathsf{X}) := \left\{ \sum_{i=1}^{n} a_i \delta_{x_i} \middle| n \in \mathbb{N}, a_i \in \mathbb{R}_+, x_i \in \mathsf{X}, i = 1, 2, \dots, n, \sum_{i=1}^{n} a_i = 1 \right\}.
$$
 (11)

By Theorem 6.18 in [Villani \(2009](#page-19-2)), D(X) is dense in (P1(X), W1).

### 2.2 The Arens-Eells space

We recall some results of the Arens-Eells space based on [Weaver \(1999,](#page-19-9) Section 2.2 and 2.3).

Definition 2.1. *Let* (X, d) *be a metric space. A* molecule *of* X *is a function* m : X → R *which is supported on a finite set and which satisfies* P <sup>x</sup>∈<sup>X</sup> m(x) = 0.

For any x, y ∈ X define the molecule mxy = 1<sup>x</sup> − 1y, where 1<sup>x</sup> denotes the indicator function on the singleton set {x}. Define the following seminorm for every molecule m:

<span id="page-4-3"></span>
$$
||m||_{\mathcal{L}(X)} := \inf \left\{ \sum_{i=1}^{n} |a_i| d(x_i, y_i) \middle| m = \sum_{i=1}^{n} a_i m_{x_i y_i} \right\},
$$
\n(12)

and let Æ(X) be the completion of the space of molecules, which is also called *Arens-Eells space*.

The following theorem states that Æ(X) is a predual of the space of Lipschitz functions L (X). This predual is unique in many important cases [\(Weaver](#page-19-10), [2016](#page-19-10)).

<span id="page-4-4"></span>Theorem 2.2. *[\(Weaver](#page-19-9), [1999](#page-19-9), Theorem 2.2.2) Let* (X, d) *be a metric space with at least one point* x0*. Then* (*Æ*(X), k · kÆ) <sup>∗</sup> ∼= (L (X), k · kLip).

For any f ∈ L (X) and m ∈ Æ(X), we define

$$
\langle f, m \rangle := \sum_{x \in \mathsf{X}} f(x) m(x).
$$

<span id="page-4-1"></span>Corollary 2.3. *(i)* kmk<sup>Æ</sup>(X) = maxf∈[L(X)]<sup>1</sup> hf, mi*. (ii)* k·k<sup>Æ</sup>(X) *is a norm on Æ* .

For the proof, see [Weaver \(1999,](#page-19-9) Corollary 2.2.3).

Replacing the Dirac measure in D(X) by the indicator function, we define the following set of real-valued functions on X

$$
\mathcal{D}(\mathsf{X}) := \left\{ \sum_{i=1}^{n} a_i \mathbf{1}_{x_i} \middle| n \in \mathbb{N}, a_i \in \mathbb{R}_+, i = 1, 2, x \in \mathsf{X}, \dots, n, \sum_{i=1}^{n} a_i = 1 \right\}.
$$
 (13)

Let ψ : D(X) → D(X) be defined by

<span id="page-4-0"></span>
$$
\psi(\nu)(x) := \nu(\{x\})\tag{14}
$$

Obviously, ψ is a bijection between D(X) and D(X). Let now Ψ : D(X)×D(X) → Æ(X) be defined by

$$
\Psi(\nu,\nu_0) := \psi(\nu) - \psi(\nu_0). \tag{15}
$$

To see that Ψ(ν, ν0) is actually an element of Æ(X), notice that

$$
\sum_{x \in \mathsf{X}} \Psi(\nu, \nu_0)(x) = \sum_{x \in \mathsf{X}} (\psi(\nu)(x) - \psi(\nu_0)(x)) = 0, \forall \nu, \nu_0 \in \mathscr{D}(\mathsf{X}).
$$

We remark that for every ν<sup>0</sup> ∈ D(X), Ψ is an injection from D(X) × {ν0} into Æ(X). However, this obviously is not true for the whole product D(X) × D(X). Furthermore, Ψ is a surjection into the set of molecules with "total mass" P x∈X |m(x)| equal or less than 2.

### 2.3 Connecting Arens-Eells and Wasserstein-1 spaces.

Recall that D(X) is the subset of P(X), that contains all probability measures with finite support, and D(X) defined in [\(13\)](#page-4-0) is its corresponding space of functions on X, with ψ : D(X) → D(X) being the bijective map.

<span id="page-4-2"></span>Proposition 2.4. W1(ν, ν0) = kΨ(ν, ν0)k<sup>Æ</sup>(X) = kψ(ν) − ψ(ν0)k<sup>Æ</sup>(X) *, for every* ν, ν<sup>0</sup> ∈ D(X).

Proof. By the dual representation [\(10\)](#page-3-2) of W1, we have

$$
W_1(\nu, \nu_0) = \sup_{f \in [\mathcal{L}(X)]_1} \left( \int f d\nu - \int f \nu_0 \right) = \sup_{f \in [\mathcal{L}(X)]_1} \sum_{x \in X} (\psi(\nu)(x) - \psi(\nu_0)(x)) f(x)
$$
  
=  $||\psi(\nu) - \psi(\nu_0)||_{E(X)} = ||\Psi(\nu, \nu_0)||_{E(X)},$ 

where the second to the last equality is due to Corollary [2.3\(](#page-4-1)i).

Before we proceed, we would like to highlight the connection of the Wasserstein-1 space with the Arens-Eells space and its dual, namely the space of Lipschitz functions. We saw in the previous subsection and in Proposition [2.4](#page-4-2) that we can embed the set D(X)×D(X) of pairs (ν, ν0) ∈ P1(X) × P1(X) in the vector space (Æ(X), k·kÆ(X)), in a way that the Wasserstein-1 distance W1(ν, ν0) is equal to the norm of the vector kΨ(ν, ν0)kÆ(X) . Moreover, for every element m of the set of molecules (which is dense in Æ(X)), one can find a pair (ν (m) , ν (m) 0 ) ∈ D(X) × D(X), and a positive number a (m) , such that m = a (m)Ψ(ν (m) , ν (m) 0 ), and kmkÆ(X) = a (m)W1(ν (m) , ν (m) 0 ). One can picture D(X)×D(X) as an absorbing set [\(Schaefer , 1971\)](#page-19-11) of a dense subspace of Æ(X), which hints that D(X)×D(X) may be enough for characterizing its dual space L (X).

In the case where X is compact, one can get a better intuition by reading the exposition on the relation between the so-called Kantorovich-Rubenstein space, the Arens-Eells space and the space of Lipschitz functions in [Weaver \(1999,](#page-19-9) Chapter 2, Section 3) or [Kantorovich and Akilov \(1982,](#page-19-12) Section VIII.4).

In addition, due to [\(10\)](#page-3-2), the Wasserstein-1 space can be considered as a subspace of the dual of L (X). In what follows, we are going to exploit these relationships to prove a separation theorem on the Wasserstein space, and then our first main result, Theorem [1.1.](#page-1-0)

Open Problem. It is tempting to generalize our approach to establish duality w.r.t. the Wasserstein-p distance with p > 1. To this end, one could try to generalize the Arens-Eells space to some "p-version", for example by using d(xi, yi) p instead of d(xi, yi) in [\(12\)](#page-4-3). However, in this case, the seminorm constructed in an analogous way to [\(12\)](#page-4-3), is equal to zero everywhere. The approach we are following in order to prove the duality result, heavily depends on the fact that adding the same finite measure on two measures ν, ν<sup>0</sup> does not change its distance; here, one can understand the Wasserstein distance not between probability measures anymore, but between measures with the same total mass. Therefore, it remains an open problem, how one can generalize the result for Wasserstein-p spaces with p > 1.

## 2.4 A separation theorem on D(X)

We are now ready to state a separation theorem on D(X). We first restate the Nirenberg-Luenberger theorem (see [Luenberger \(1969](#page-19-13), Section 5.13), also known as the *minimum norm duality theorem*).

Definition 2.5. *Let* K *be a convex set in a real normed vector space* X*. Let* X<sup>∗</sup> *be its dual space. The function* hK(x ∗ ) = supx∈Khx, x<sup>∗</sup> i *on* X ∗ *is called the support functional of* K*.*

<span id="page-5-0"></span>Theorem 2.6. *Let* x<sup>1</sup> *be a point in a real normed space* X *and let* d > 0 *denote its distance from the convex set* K *having support functional* hK*. Then*

$$
d = \inf_{x \in K} ||x - x_1|| = \max_{||x^*|| \le 1} [\langle x_1, x^* \rangle - h_K(x^*)]
$$

*where the maximum on the right is attained by some* x ∗ <sup>0</sup> ∈ X ∗ *.*

<span id="page-5-1"></span>Theorem 2.7. *Let* K *be a convex set of* D(X) *and* ν<sup>0</sup> ∈ D(X) *be a point not contained in* K *satisfying* W1(ν, ν0) ≥ ǫ > 0, ∀ν ∈ K*. Then, there exists a function* f ∈ [L (X)]<sup>1</sup> *such that* R fdν ≥ R fdν<sup>0</sup> + ǫ, ∀ν ∈ K.

Proof. Since K is convex, K′ := {ψ(ν)−ψ(ν0) | ν ∈ K} is also convex in Æ(X). To apply Theorem [2.6,](#page-5-0) we set X = Æ(X) and its dual is X<sup>∗</sup> = Æ<sup>∗</sup> (X) = L (X). By the definition of hK′ , we have

$$
h_{K'}(f) = \sup_{m \in K'} \langle f, m \rangle = \sup_{\nu \in K} \left\{ \int f d\nu - \int f d\nu_0 \right\}, \forall f \in \mathscr{L}(\mathsf{X}).
$$

Then, by Theorem [2.6](#page-5-0) and Proposition [2.4,](#page-4-2) we obtain

$$
\epsilon \leq \inf_{\nu \in K} W_1(\nu, \nu_0) = \inf_{m \in K'} ||m||_{\mathcal{R}} = \max_{f \in [\mathcal{L}(X)]_1} [-h_{K'}(f)],
$$

which yields maxf∈[L(X)]<sup>1</sup> infν∈<sup>K</sup> R (−f)dν − R (−f)dν<sup>0</sup> ≥ ǫ. Suppose the maximum is attained at f0. Then infν∈<sup>K</sup> R (−f0)dν − R (−f0)dν<sup>0</sup> ≥ ǫ, which implies R (−f0)dν ≥ R (−f0)dν<sup>0</sup> + ǫ, ∀ν ∈ K.

In the following sections, we consider the dual space of the Cartesian product Æ(X)×R, where we can obtain a similar result as above. The operator ∨ is defined as a ∨ b := max(a, b).

Theorem 2.8. *Let* K˜ *be a convex subset of* D(X) × R *and* (ν0, r0) ∈ D(X) × R *be a point not contained in* K˜ *. Suppose* W1(ν, ν0) ∨ |r − r0| ≥ ǫ > 0, ∀(ν, r) ∈ K˜ *. Then, there exists a tuple* (f, α) ∈ [L (X)]<sup>1</sup> × [−1, 1] *satisfying*

$$
||f||_{\text{Lip}} + |\alpha| \le 1 \quad and \quad \int f d\nu + \alpha r \ge \int f d\nu_0 + \alpha r_0 + \epsilon, \forall (\nu, r) \in \tilde{K}.
$$

Proof. Let Æ(X) × R be equipped with the canonical norm k(m, r)k := kmkÆ(X) ∨ |r|. An extension of Theorem [2.2](#page-4-4) shows that its dual space is isometric to L (X) × R with the norm k(f, r)k = kfkLip +|r|, i.e. (Æ(X)×R) <sup>∗</sup> = L (X)×R. The rest of the proof is similar to the proof of Theorem [2.7.](#page-5-1)

### 2.5 A separation theorem on Wasserstein-1 space

In this subsection, we extend Theorem [2.7](#page-5-1) to the whole Wasserstein-1 space.

<span id="page-6-1"></span>Theorem 2.9. *Let* A *be a convex and closed subset of* (P1(X), W1)*. Let* µ<sup>0</sup> ∈ P1(X) *be a point not contained in* A*. Then, there exists a function* f ∈ [L (X)]<sup>1</sup> *such that*

$$
\int f d\mu > \int f d\mu_0, \quad \forall \mu \in A.
$$

Proof.

Step 1. Since A is closed and µ<sup>0</sup> ∈/ A, there exists a positive constant ǫ<sup>0</sup> > 0 satisfying W1(µ, µ0) ≥ ǫ0, ∀µ ∈ A.

Step 2. By Theorem 6.18 in [Villani \(2009\)](#page-19-2), we can approximate µ by a point ν ∈ D(X) with any accuracy. Finally, Theorem [2.7](#page-5-1) can be applied to find the required separation function in L (X). More specifically, take ǫ<sup>1</sup> = ǫ0/5 and define subsets of D(X) as follows

$$
B_{\epsilon_1}(\mu) := \{ \nu \in \mathscr{D}(\mathsf{X}) \mid W_1(\mu, \nu) < \epsilon_1 \}, \quad A_{\epsilon_1} := \bigcup_{\mu \in A} B_{\epsilon_1}(\mu).
$$

Since D(X) is dense in (P1(X), W1), B<sup>ǫ</sup><sup>1</sup> (µ) 6= ∅, ∀µ ∈ P1(X). Hence, for any ν<sup>i</sup> ∈ A<sup>ǫ</sup><sup>1</sup> there exists a µ<sup>i</sup> ∈ A such that W1(νi, µi) < ǫ1, i = 1, 2. Let ν<sup>α</sup> := αν<sup>1</sup> + (1 − α)ν<sup>2</sup> and µ<sup>α</sup> := αµ<sup>1</sup> + (1 − α)µ2, α ∈ (0, 1). We have, by the dual representation [\(10\)](#page-3-2) of W1,

$$
W_1(\nu_{\alpha}, \mu_{\alpha}) \leq \alpha W_1(\nu_1, \mu_1) + (1 - \alpha)W_1(\nu_2, \mu_2) < \epsilon_1,
$$

which implies that A<sup>ǫ</sup><sup>1</sup> is convex. Similarly, we can find a ν<sup>0</sup> ∈ D(X) such that W1(µ0, ν0) < ǫ1. Note that W1(ν, µ) ≥ W1(µ0, µ) − W1(µ0, ν0) − W1(ν0, ν) ≥ ǫ<sup>0</sup> − ǫ<sup>1</sup> − W1(ν0, ν), ∀ν ∈ A<sup>ǫ</sup><sup>1</sup> , µ ∈ A, yields infµ∈<sup>A</sup> W1(ν, µ) ≥ ǫ<sup>0</sup> − ǫ<sup>1</sup> − W1(ν0, ν), ∀ν ∈ A<sup>ǫ</sup><sup>1</sup> . Because ǫ<sup>1</sup> ≥ infµ∈<sup>A</sup> W1(ν, µ), we have W1(ν0, ν) ≥ ǫ<sup>0</sup> − 2ǫ<sup>1</sup> > 0, ∀ν ∈ A<sup>ǫ</sup><sup>1</sup> . Hence, by Theorem [2.7,](#page-5-1) there exists a function f<sup>0</sup> ∈ L (X) with kf0kLip ≤ 1, such that

$$
\int f_0 d\nu \ge \int f_0 d\nu_0 + \epsilon_0 - 2\epsilon_1, \forall \nu \in A_{\epsilon_1}.
$$
 (16)

Step 3. Finally, we show that f<sup>0</sup> is the required Lipschitz function. For each µ ∈ A, there exists an ν<sup>µ</sup> ∈ A<sup>ǫ</sup><sup>1</sup> such that W1(µ, νµ) < ǫ<sup>1</sup> and hence R fdµ ≥ R fdν<sup>µ</sup> − ǫ1, ∀f ∈ [L (X)]1. In particular,

<span id="page-6-0"></span>
$$
\int f_0 d\mu \ge \int f_0 d\nu_\mu - \epsilon_1. \tag{17}
$$

Similarly, W1(µ0, ν0) < ǫ<sup>1</sup> implies

<span id="page-7-0"></span>
$$
\int f_0 d\nu_0 \ge \int f_0 d\mu_0 - \epsilon_1. \tag{18}
$$

Combining [\(16\)](#page-6-0) – [\(18\)](#page-7-0), we obtain R f0dµ ≥ R f0dµ<sup>0</sup> + ǫ<sup>0</sup> − 4ǫ<sup>1</sup> = R f0dµ<sup>0</sup> + ǫ0 5 , ∀µ ∈ A, which yields the required separability.

Analogously, we can obtain the same separation result in the space P1(X) × R which will be used in the following subsection.

<span id="page-7-2"></span>Theorem 2.10. *Let* A˜ *be a convex and closed subset of* P1(X)×R *equipped with the metric*

$$
\tilde{d}((\mu,r_1),(\nu,r_2)) := W_1(\mu,\nu) \vee |r_1 - r_2|.
$$

*Let* (µ0, r0) ∈ P1(X) × R *be a point not contained in* A*. Then, there exists a tuple* (f, α) ∈ L (X) × R, *and* ǫ<sup>0</sup> > 0, *such that*

$$
\int f d\mu + \alpha r \ge \int f d\mu_0 + \alpha r_0 + \epsilon_0, \forall (\mu, r) \in \tilde{A}.
$$

The proof is similar to the proof of Theorem [2.9.](#page-6-1)

### 2.6 Proof of the duality theorem

We shall prove Theorem [1.1](#page-1-0) in this subsection. We want to stress that the proofs of Lemma [2.13](#page-7-1) and the Theorem [1.1](#page-1-0) mostly follow the line of proof found in [Ioan-Bot et al.](#page-18-1) [\(2009](#page-18-1), Theorem 2.2.15).

Definition 2.11. *For a function* φ : P1(X) → R¯*, its* domain *is defined by dom*(φ) := {µ ∈ P1(X) : φ(µ) < +∞}*.* φ *is said to be* proper *if* φ(µ) > −∞ *for all* µ ∈ P1(X) *and dom*(φ) 6= ∅*. The* epigraph *of* φ *is defined as epi*(φ) := {(µ, r) ∈ P1(X) × R | φ(µ) ≤ r}.

<span id="page-7-3"></span>Now we provide the following proposition whose proof is standard and will be omitted. Proposition 2.12. *If* φ : P1(X) → R¯ *is convex and lower semicontinuous (equipped with the metric* W1*), then epi*(φ) *is convex and closed w.r.t.*

<span id="page-7-4"></span>
$$
\tilde{d}((\mu, a), (\nu, b)) := W_1(\mu, \nu) \vee |a - b|.
$$

For any φ : P1(X) → R¯, we define the following set

$$
M_{\phi} := \left\{ (f, \eta) \in \mathscr{L}(\mathsf{X}) \times \mathbb{R} \middle| \int f d\mu + \eta \leq \phi(\mu), \forall \mu \in \mathscr{P}_1(\mathsf{X}) \right\}.
$$
 (19)

<span id="page-7-1"></span>Lemma 2.13. *Let* φ : P1(X) → R¯ *be proper, convex and lower semicontinuous with respect to* W1*. Then,* M<sup>φ</sup> *is not empty.*

Proof. Since φ is proper, there exists an element ν ∈ P1(X) such that φ(ν) ∈ R. Then epi(φ) 6= ∅ and (ν, φ(ν) − 1) ∈/ epi(φ). By Theorem [2.10,](#page-7-2) there exists (f0, η0) ∈ L (X) × R such that

$$
\int f_0 d\nu + \eta_0(\phi(\nu) - 1) < \int f_0 d\mu + \eta_0 r, \forall (\mu, r) \in \text{epi}(\phi).
$$

Since (ν, φ(ν)) ∈ epi(φ), we have η<sup>0</sup> > 0 and (1/η0) R f0dν − R f0dµ + φ(ν) − 1 < r, ∀(µ, r) ∈ epi(φ). For any µ ∈ dom(φ), we have (µ, φ(µ)) ∈ epi(φ), and hence

$$
(1/\eta_0)\left(\int f_0 d\nu - \int f_0 d\mu\right) + \phi(\nu) - 1 < \phi(\mu).
$$

If µ /∈ dom(φ), this inequality holds trivially. Thus,

$$
\left(-f_0/\eta_0,\phi(\nu)-1+\int f_0 d\nu/\eta_0\right)\in M_\phi.
$$

It is easy to verify that under the same conditions as in the above lemma, we have the following equation for the second conjugate dual φ c of φ:

$$
\phi^c(\mu_0) = \sup_{(f,\eta) \in M_{\phi}} \left\{ \int f d\mu_0 + \eta \right\}.
$$

We now proceed with the proof of Theorem [1.1.](#page-1-0)

*Proof of Theorem [1.1.](#page-1-0)* By definition, we have ρ(f) ≥ R fdµ − φ(µ), ∀(µ, f) ∈ P1(X) × L (X), which implies R fdµ − ρ(f) ≤ φ(µ), ∀(µ, f) ∈ P1(X) × L (X), and hence φ c (µ) ≤ φ(µ), ∀µ ∈ P1(X).

Next we show that φ(µ) ≤ φ c (µ), ∀µ ∈ P1(X). Assume towards a contradiction that there exists a µ<sup>0</sup> ∈ P1(X) and r<sup>0</sup> ∈ R such that

<span id="page-8-1"></span><span id="page-8-0"></span>
$$
\phi(\mu_0) > r_0 > \phi^c(\mu_0) = \sup_{(f,\eta) \in M_{\phi}} \left\{ \int f d\mu_0 + \eta \right\}.
$$
 (20)

It is clear that (µ0, r0) ∈/ epi(φ). Note that by Proposition [2.12,](#page-7-3) epi(φ) is closed. Furthermore it is convex and non-empty. Hence, by Theorem [2.10,](#page-7-2) there exists a (f0, η0) ∈ L (X) × R such that

$$
\int f_0 d\mu + \eta_0 r > \int f_0 d\mu_0 + \eta_0 r_0 + \epsilon, \forall (\mu, r) \in \text{epi}(\phi),
$$
\n(21)

Note that if (µ, r) ∈ epi(φ), then (µ, r + s) ∈ epi(φ) for any s ≥ 0. Thus η<sup>0</sup> ≥ 0.

Suppose φ(µ0) ∈ R. Using the fact that (µ0, φ(µ0)) ∈ epi(φ), we obtain η0(φ(µ0) − r0) > 0. Hence η<sup>0</sup> > 0. For µ ∈ dom(φ), we obtain φ(µ) > 1 η0 R f0dµ<sup>0</sup> − 1 η0 R f0dµ + r0. Now setting η = r<sup>0</sup> + 1 η0 R f0dµ<sup>0</sup> and f = − f0 η0 in [\(20\)](#page-8-0), we have R fdµ<sup>0</sup> + η = r0, which contradicts [\(20\)](#page-8-0).

Suppose now that φ(µ0) = +∞. If η<sup>0</sup> > 0, the contradiction remains. Thus η<sup>0</sup> = 0 and [\(21\)](#page-8-1) becomes R f0dµ > R f0dµ<sup>0</sup> + ǫ, ∀(µ, r) ∈ epi(φ). By Lemma [2.13,](#page-7-1) the set M<sup>φ</sup> defined in [\(19\)](#page-7-4) is not empty. Hence, there exists (f1, a1) ∈ M<sup>φ</sup> such that R f1dµ + a<sup>1</sup> ≤ φ(µ), ∀µ ∈ P1(X). By the assumption made in [\(20\)](#page-8-0), b := (r<sup>0</sup> − R f1dµ<sup>0</sup> − a1)/ǫ > 0. For all µ ∈ dom(φ),

$$
\int (f_1 - bf_0)d\mu + \int bf_0 d\mu_0 + a_1 + b\epsilon
$$
\n
$$
= \int f_1 d\mu + a_1 + b\left(-\int f_0 d\mu + \int f_0 d\mu_0 + \epsilon\right) \le \int f_1 d\mu + a_1 \le \phi(\mu).
$$
\n(22)

This can be extended to all µ ∈ P1(X). Hence, (f1−bf0, R bf0dµ0+a1+bǫ) ∈ Mφ. Taking µ = µ<sup>0</sup> in [\(22\)](#page-8-2), we have R (f<sup>1</sup> − bf0)dµ<sup>0</sup> + R bf0dµ<sup>0</sup> + a<sup>1</sup> + bǫ = r0, which again contradicts [\(20\)](#page-8-0).

We will end this section with the proof Corollary [1.4](#page-2-0)

*Proof of Corollary [1.4.](#page-2-0)* (a) We show first φ(µ) = supf∈N<sup>φ</sup> R fdµ. Indeed, Theorem [1.1](#page-1-0) yields

$$
\phi(\mu) = \sup_{f \in \mathscr{L}(\mathsf{X})} \left( \int f d\mu - \rho(f) \right) \ge \sup_{f \in \mathcal{N}_{\phi}} \left( \int f d\mu - \rho(f) \right) = \sup_{f \in \mathcal{N}_{\phi}} \int f d\mu.
$$

Since there exists at least one µ such that φ(µ) ∈ R, we have ρ(f) > −∞, ∀f ∈ L (X). Thus,

$$
\sup_{f \in \mathscr{L}(\mathsf{X})} \left( \int f d\mu - \rho(f) \right) = \sup_{f \in \mathscr{L}(\mathsf{X}): \rho(f) < \infty} \left( \int f d\mu - \rho(f) \right) = \sup_{f \in \mathscr{L}(\mathsf{X}): \rho(f) \in \mathbb{R}} \left( \int f d\mu - \rho(f) \right)
$$

<span id="page-8-3"></span><span id="page-8-2"></span>.

Due to the translation invariance, f ′ := f − ρ(f) satisfies that ρ(f ′ ) = 0 if ρ(f) ∈ R. Hence,

$$
\phi(\mu) = \sup_{f \in \mathscr{L}(\mathsf{X}): \rho(f) \in \mathbb{R}} \left( \int f d\mu - \rho(f) \right) = \sup_{f': f' = f - \rho(f), f \in \mathscr{L}(\mathsf{X}), \rho(f) \in \mathbb{R}} \int f' d\mu \le \sup_{f' \in \mathcal{N}_{\phi}} \int f' d\mu. \tag{23}
$$

Combining the above two inequalities yields φ(µ) = supf∈N<sup>φ</sup> R fdµ.

(b) We show now φ(µ) = supf∈N¯<sup>φ</sup> R fdµ. Theorem [1.1](#page-1-0) yields

$$
\phi(\mu) = \sup_{f \in \mathscr{L}(\mathsf{X})} \left( \int f d\mu - \rho(f) \right) \ge \sup_{f \in \bar{\mathcal{N}}_{\phi}} \left( \int f d\mu - \rho(f) \right) \ge \sup_{f \in \bar{\mathcal{N}}_{\phi}} \int f d\mu.
$$

On the other hand, [\(23\)](#page-8-3) yields φ(µ) ≤ supf′∈N<sup>φ</sup> R f ′ dµ ≤ supf′∈N¯<sup>φ</sup> R f ′ dµ.

### 3 POMDPs

### 3.1 Outline and related literature.

Most early literature on POMDPs (see e.g. [Sondik \(1978\)](#page-19-6); [Hern´andez-Lerma \(1989](#page-18-7))) considers finite state spaces or bounded reward function. In their recent work, [Feinberg et al.](#page-18-8) [\(2016](#page-18-8)) consider a more general setting with Borel spaces and reward/cost functions that are bounded on one side. We adopt the setting of MDPs from [Hern´andez-Lerma and Lasserre](#page-18-10) [\(1999](#page-18-10)) with Borel spaces and real-valued reward functions, but we apply the weighted norm technique that connects them naturally to the Wasserstein-1 space.

In what follows, we are going to present the concept of POMDPs, and how they can be reduced to classical MDPs with a state space that contains all probability measures over the POMDPs' initial state space. We describe the weighted norm technique for solving MDPs, and demonstrate how our general assumptions imply the sufficient conditions for the convergence of the value iteration method in [Hern´andez-Lerma and Lasserre \(1999\)](#page-18-10).

Although our approach covers cases with two-sided unbounded reward functions, these cases can be reduced to MDPs with bounded reward functions by applying an algebraic transformation [\(Van Der Wal, 1981\)](#page-19-14). The contribution of our paper on POMDPs, is the conjugate approach for the computation of the value function described in Section 5 that extends the ideas from [Sondik \(1978\)](#page-19-6); [F¨ollmer and Schied \(2004](#page-18-6)), and which we expect to inspire a computable set iteration algorithm for approximations of the value function.

### <span id="page-9-0"></span>3.2 Setup

A partially observable Markov decision process (POMDP, see e.g., [Hern´andez-Lerma](#page-18-7) [\(1989](#page-18-7), Chapter 4)) is described by a tuple (X,Y,A, P, Q, µ, r), where:

- (a) X is the (hidden or latent) state space, a Polish space with metric d.
- (b) Y is the space of observations, a Borel space.
- (c) A is the action space, a Borel space.
- (d) P(dx′ |x, a) is the state transition law, a stochastic kernel on X given K := X × A. K is also a Borel space.
- (e) Q(dy|a, x) is the observation kernel a stochastic kernel on Y given K. Q<sup>0</sup> is the initial observation kernel, a stochastic kernel on Y given X.
- (f) µ ∈ P(X) is the initial distribution.
- (g) r : K → R is the one-step reward function, which is B(K)-measurable.

The POMDP evolves as follows; At time t = 0, the initial (hidden or latent) state x<sup>0</sup> follows a given prior distribution µ, while the initial observation y<sup>0</sup> is generated according to the initial observation kernel Q0(·|x0). If, at time t, the state of the system is x<sup>t</sup> and the control a<sup>t</sup> ∈ A is applied, then the agent receives a reward r(xt, at) and the system transits to state xt+1 according to the transition law P(dxt+1|xt, at). The observation yt+1 is generated by the observation kernel Q(dyt+1|at, xt+1). The *observed* history is defined as

<span id="page-9-1"></span>
$$
h_0 := \{\mu, y_0\} \in \mathsf{H}_0 \text{ and } h_t := \{\mu, y_0, a_0, \dots, y_{t-1}, a_{t-1}, y_t\} \in \mathsf{H}_t, t = 1, 2, \dots,
$$
 (24)

where H<sup>0</sup> := P(X) × Y and Ht+1 = H<sup>t</sup> × Y × A, t = 1, 2, . . . . Notably, comparing with the canonical Markov decision processes (MDPs, see e.g., [Hern´andez-Lerma \(1989\)](#page-18-7)), the states {xt} are not observable and hence, a *policy* depends only on the observed history.

A deterministic policy π := [π0, π1, . . .] is composed of a sequence of one-step policies π<sup>t</sup> : H<sup>t</sup> → A, given the observed history up to time t. Let Π be the set of all deterministic policies. Note that even with extension to nondeterministic policies, it is known [\(Hern´andez-Lerma, 1989](#page-18-7), Chapter 4) that an optimal policy to a POMDP is always deterministic. Hence, we consider in this paper only deterministic policies. The Ionescu-Tulcea theorem [\(Bertsekas and Shreve](#page-18-11), [1978,](#page-18-11) pp. 140–141) implies that for each π ∈ Π and an initial µ ∈ P(X), along with P, Q and Q0, a probability measure P π <sup>µ</sup> and a stochastic process {Xt, Yt, At} can be defined in a canonical way. We denote by E π <sup>µ</sup> the expectation with respect to this probability measure P π µ .

We consider the following *discounted cumulative rewards*

$$
J_T(\boldsymbol{\pi}, \mu) := \mathbb{E}_{\mu}^{\boldsymbol{\pi}} \left[ \sum_{t=0}^{T} \alpha^t r(X_t, A_t) \right], \qquad (25)
$$

where α ∈ (0, 1) stands for a discount factor, and T ∈ N ∪ {∞}. The objective is now to maximize the expected reward over the set of deterministic policies Π,

$$
\phi_T^*(\mu) := \sup_{\pi \in \Pi} J_T(\pi, \mu), \quad \mu \in \mathscr{P}(\mathsf{X}).
$$

We will finally use the notation

$$
\phi^* := \phi^*_{\infty}.\tag{26}
$$

### 3.3 Reduction to Markov decision process

We show briefly in this subsection that the POMDP can be reduced to a Markov decision process (MDP, see e.g. [Hern´andez-Lerma and Lasserre \(1999](#page-18-10))). We follow mostly the derivation by [Hern´andez-Lerma \(1989,](#page-18-7) Chapter 4). We first introduce the following notation:

$$
\tilde{r}(\mu, a) := \int r(x, a)\mu(dx), \text{ and } \tilde{P}(\mathsf{B}|\mu, a) := \int \mu(dx)P(\mathsf{B}|x, a), \mathsf{B} \in \mathcal{B}(\mathsf{X}), \tag{27}
$$

where µ ∈ P(X), and a ∈ A. For any C ∈ B(Y) and B ∈ B(X), we define

$$
R(\mathsf{B},\mathsf{C}|\mu,a) := \int_{\mathsf{B}} Q(\mathsf{C}|a,x') \tilde{P}(dx'|\mu,a), \text{ and } \tilde{R}(\mathsf{C}|\mu,a) := R(\mathsf{X},\mathsf{C}|\mu,a). \tag{28}
$$

Proposition 3.1. *There exists a stochastic kernel* M *from* P(X) × A × Y *to* X *such that for each* µ ∈ P(X)*,* a ∈ A,B ∈ B(X) *and* C ∈ B(Y)*,*

<span id="page-10-1"></span>
$$
R(\mathsf{B},\mathsf{C}|\mu,a) = \int_{\mathsf{C}} M(\mathsf{B}|\mu,a,y) \tilde{R}(dy|\mu,a). \tag{29}
$$

Proof. Direct application of [Bertsekas and Shreve \(1978](#page-18-11), Corollary 7.27.1).

M can also be viewed as a mapping P(X) × A × Y → P(X). With a slight abuse of notation, let M(µ, a, y) := M(·|µ, a, y) ∈ P(X). Then we define the following stochastic kernel

$$
\tilde{Q}(\mathsf{D}|\mu, a) := \int 1_{\mathsf{D}}(M(\mu, a, y)) \tilde{R}(dy|\mu, a), \quad D \in \mathcal{B}(\mathcal{P}(\mathsf{X})). \tag{30}
$$

Let µ<sup>t</sup> ∈ P(X) be the distribution at time t. Then, given an action a<sup>t</sup> ∈ A and an observation yt+1 ∈ Y, the *successive* distribution µt+1 ∈ P(X) is given by

<span id="page-10-0"></span>
$$
\mu_{t+1} = M(\mu_t, a_t, y_{t+1}). \tag{31}
$$

Note that µt+1 is a random measure since yt+1 is a random variable with the distribution R˜(·|µt, at). Hence, the POMDP can be reduced to a Markov decision process (MDP) with the *belief* state space P(X), the action space A, the reward function ˜r on P(X) × A and the transition kernel on belief states Q˜ defined above.

Let h˜<sup>t</sup> be a t-stage history for the MDP described above:

$$
\tilde{h}_t := \{\tilde{\mu}_0, \tilde{a}_0, \ldots, \tilde{\mu}_{t-1}, \tilde{a}_{t-1}, \tilde{\mu}_t\} \in \tilde{H}_t := \mathscr{P}(\mathsf{X}) \times (\mathsf{A} \times \mathsf{P})^t, t = 0, 1, \ldots,
$$

where ˜µ<sup>0</sup> is the initial distribution and the ˜µ<sup>t</sup> ∈ P(X) are recursively defined by [\(31\)](#page-10-0). Given the original t-stage history h<sup>t</sup> defined in [\(24\)](#page-9-1), let m<sup>t</sup> : H<sup>t</sup> → H˜<sup>t</sup> be the mapping such that mt(ht) = h˜t, ∀h<sup>t</sup> ∈ Ht, t = 0, 1, . . . . For a history-dependent MDPpolicy δ := [δ0, δ1, . . .], where δ<sup>t</sup> : H˜<sup>t</sup> → A, we define its counterpart POMDP-policy as π <sup>δ</sup> = [π δ 0, π<sup>δ</sup> <sup>1</sup>, . . .], with π δ <sup>t</sup> (ht) = δt(mt(ht)). If a policy δ is optimal for the MDP, then its counterpart policy π δ is also optimal for the POMDP. For more details, we refer to [Hern´andez-Lerma \(1989](#page-18-7), Chapter 4) and references therein.

After the reduction to a MDP, it is well known that under proper assumptions (see, e.g., [\(Hern´andez-Lerma](#page-18-7), [1989](#page-18-7), Chapter 4) and [Feinberg et al. \(2016](#page-18-8))), the optimal φ ∗ for the infinite-stage case satisfy the following *optimality equation*:

$$
\phi(\mu) = \mathcal{T}(\phi)(\mu) := \sup_{a \in \mathcal{A}} \left( r(\mu, a) + \alpha \int \phi \left( M(\mu, a, y) \right) \tilde{R}(dy | \mu, a) \right), \forall \mu \in \mathscr{P}(\mathsf{X}), \tag{32}
$$

where T is an operator on the space of Borel measurable functions on P(X). We will show in Section [4,](#page-11-0) that under general assumptions, the existence of a solution of the above equation is guaranteed, as well as the existence of an optimal deterministic policy. The value iteration algorithm gives a sequence that converges to the value function.

### <span id="page-11-0"></span>4 Optimal solution on weighted space

### 4.1 Weighted norm

The *weighted norm* has proven to be very useful when dealing with MDPs (see e.g. [Hern´andez-Lerma and Lasserre \(1999](#page-18-10))). The weighted norm induced by the Wasserstein-1 metric is defined as follows: First, we specify a weight function w : X → [1,∞) by

$$
w(x) := 1 + k \cdot d(x_0, x), \quad x \in \mathsf{X} \tag{33}
$$

with some fixed x<sup>0</sup> ∈ X and a positive constant k > 0. This definition implies w(x0) = 1. One can easily verify that w is Lipschitz, and therefore continuous and measurable. Denote by Lw(X) the space of all continuous functions on X such that

<span id="page-11-1"></span>
$$
||f||_w := \sup_{x \in \mathsf{X}} \frac{|f(x)|}{w(x)} < \infty.
$$

Let Pw(X) ⊂ P(X) be the set of probability measures µ on X satisfying R wdµ < ∞. We equip Pw(X) with the following concept of weak convergence:

<span id="page-11-2"></span>Definition 4.1. *(a)* µ<sup>n</sup> *is said to converge weakly to* µ *in* Pw(X)*, if (i) for any bounded continuous function* f *on* X*, it follows that* R X f(x)µn(dx) → R X f(x)µ(dx) *as* n → ∞; *and (ii)* R <sup>X</sup> w(x)µn(dx) → R <sup>X</sup> w(x)µ(dx) *as* n → ∞*. (b) A function* φ : Pw(X) → R *is said to be lower (resp. upper) semicontinuous if*

$$
\liminf_{n \to \infty} \phi(\mu_n) \ge \phi(\mu) \ (resp. \ \limsup_{n \to \infty} \phi(\mu_n) \le \phi(\mu)),
$$

*whenever* µ<sup>n</sup> *converges weakly to* µ*.* φ *is said to be continuous, if* φ *is both lower and upper continuous.*

*Remark* 4.2*.* It is worth to be mentioned that the weak convergence defined above is stronger than the usual weak convergence, which requires only (i). Hence, to emphasize this difference, we call the latter *canonical weak convergence* throughout the rest of this paper.

<span id="page-11-3"></span>Proposition 4.3. *The following two statements are equivalent: (i)* µ<sup>n</sup> *converges weakly to* µ *in* Pw(X) *and (ii)* R fdµ<sup>n</sup> → R fdµ, ∀f ∈ Lw(X)*.*

For a proof, see [Villani \(2009](#page-19-2), Definition 6.8).

Proposition 4.4. *Let* w *be defined as in* [\(33\)](#page-11-1) *with some* k > 0 *and* x<sup>0</sup> ∈ X*. Then (i)* P1(X) = Pw(X) *and (ii) the weak convergence defined in Definition [4.1](#page-11-2) is equivalent to the convergence in* (P1(X), W1)*, in other words,* W<sup>1</sup> *metrizes the weak convergence.*

Proof. (i) This is obvious by definition. (ii) This is a direct result of [Villani \(2009](#page-19-2), Theorem 6.9).

In the rest of this paper, we always assume that the weight function satisfies [\(33\)](#page-11-1) and hence Pw(X) is used interchangeably with P1(X). Then, the belief state space is Polish, and therefore, a Borel space.

We next specify the weight function and its weighted norm on Pw(X). Define ˜w : Pw(X) → [1, ∞) as

<span id="page-11-4"></span>
$$
\tilde{w}(\mu) := \int w d\mu. \tag{34}
$$

It is easy to check that ˜w is a continuous function and hence measurable on (Pw(X), W1). Define the following space of functions on Pw(X) with bounded ˜w-norm:

$$
\mathscr{B}_{\tilde{w}}(\mathsf{X}) := \left\{\phi:\mathscr{P}_{w}(\mathsf{X})\to\mathbb{R}\;\middle|\;\phi\text{ is }\mathcal{B}(\mathscr{P}_{w}(\mathsf{X}))\text{-measurable}, \|\phi\|_{\tilde{w}} := \sup_{\mu\in\mathscr{P}_{w}(\mathsf{X})}\frac{|\phi(\mu)|}{\tilde{w}(\mu)} < \infty\right\}.
$$

In the next subsection, we shall specify some assumptions on the original POMDP in order to ensure the assumptions needed for MDPs as in Theorem 8.3.6 in [Hern´andez-Lerma and Lasserre](#page-18-10) [\(1999](#page-18-10)).

### 4.2 Assumptions

We introduce the following assumption for the reward function.

<span id="page-12-0"></span>*Assumption* 4.5*.* (i) There exists a positive constant ¯r > 0 such that |r(x, a)| ≤ rw¯ (x), for each (x, a) ∈ K. (ii) For each x ∈ X, a 7→ r(x, a) is upper semicontinuous.

<span id="page-12-1"></span>Proposition 4.6. *Under Assumption [4.5,](#page-12-0) (i)* |r˜(µ, a)| ≤ r¯w˜(µ), ∀(µ, a) ∈ Pw(X) × A*; (ii) for each* µ ∈ Pw(X)*,* a 7→ r˜(µ, a) *is upper semicontinuous; (iii) for each* a ∈ A*,* µ 7→ r˜(µ, a) *is continuous in* Pw(X)*.*

Proof. (i) For each (µ, a) ∈ Pw(X) × A, we have |r˜(µ, a)| ≤ R |r(x, a)|µ(dx) ≤ r¯ R wdµ = r¯w˜(µ). (ii) Let {an, n = 1, 2, . . .} be a sequence of actions converging to a<sup>0</sup> and set rn(x) := r(x, an), n ∈ N. By Assumption [4.5\(](#page-12-0)i), r<sup>n</sup> ≤ rw¯ . Applying the reversed Fatou's lemma, we obtain

$$
\limsup_{n \to \infty} \int r_n d\mu \le \int \limsup_{n \to \infty} r_n d\mu \le \int r_0 d\mu,
$$

where the last inequality is due to Assumption [4.5\(](#page-12-0)ii). Finally, (iii) is a direct result of Proposition [4.3\(](#page-11-3)ii).

Similar to the assumptions made in the literature of MDPs [\(Hern´andez-Lerma and Lasserre](#page-18-10), [1999,](#page-18-10) Assumptions 8.3.2 and 8.3.3), we introduce the following assumption on the transition kernel P:

*Assumption* 4.7*.* (i) There exists a constant β ∈ (0, α<sup>−</sup><sup>1</sup> ) such that

$$
\int w(x')P(dx'|x,a) \leq \beta w(x), \forall (x,a) \in \mathsf{X} \times \mathsf{A}.
$$

(ii) For each x ∈ X, a 7→ R w(x ′ )P(dx′ |x, a) is continuous.

Under the above assumption, we show that the new probability measure M(µ, a, y) belongs to Pw(X) almost surely, and a 7→ R w˜(µ ′ )Q˜(dµ′ |µ, a) is continuous.

Proposition 4.8. *Suppose Assumption 4.7 holds. Then for each* µ ∈ Pw(X) *and* a ∈ A*, (i)* M(µ, a, y) ∈ Pw(X)*,* R˜(·|µ, a)*-almost surely; (ii)* R w˜(µ ′ )Q˜(dµ′ |µ, a) ≤ βw˜(µ); *and (iii) for each* µ ∈ Pw(X)*, the map* a 7→ R w˜(µ ′ )Q˜(dµ′ |µ, a) *is continuous.*

Proof. Fix an arbitrary (µ, a) ∈ Pw(X) × A. (i) Let C ∈ B(Y) be a subset such that R˜(C|µ, a) > 0. Then, we have

$$
\int_{\mathsf{C}} \int_{\mathsf{X}} w(x') M(dx'|\mu, a, y) \tilde{R}(dy|\mu, a) = \int_{\mathsf{X}} Q(\mathsf{C}|a, x') w(x') \tilde{P}(dx'|\mu, a) \le
$$
  
$$
\int_{\mathsf{X}} Q(\mathsf{Y}|a, x') w(x') \tilde{P}(dx'|\mu, a) \le \int_{\mathsf{X}} w(x') \tilde{P}(dx'|\mu, a) \le \beta \int w d\mu < \infty.
$$

This implies that R <sup>X</sup> w(x ′ )M(dx′ |µ, a, y) < ∞, R˜(·|µ, a)-almost surely, and hence (i) holds. (ii) By definition, we have

$$
\int \tilde{w}(\mu')\tilde{Q}(d\mu'|\mu, a) = \int_{\mathsf{Y}} \tilde{w}(M(\mu, a, y))\tilde{R}(dy|\mu, a)
$$
  
(by (34)) 
$$
= \int_{\mathsf{Y}} \int_{\mathsf{X}} w(x')M(dx'|\mu, a, y)\tilde{R}(dy|\mu, a)
$$
  
(by (29) and Fubini's theorem) 
$$
= \int_{\mathsf{X}} Q(\mathsf{Y}|a, x')w(x')\tilde{P}(dx'|\mu, a)
$$
$$
\leq \beta \int w d\mu = \beta \tilde{w}(\mu).
$$

(iii) Note that the above calculation yields

$$
\int_{\mathsf X} \tilde{w}(\mu') \tilde{Q}(d\mu'|\mu, a) = \int_{\mathsf X} w(x') \tilde{P}(dx'|\mu, a) = \int_{\mathsf X} \int_{\mathsf X} w(x') P(dx'|x, a) \mu(dx).
$$

Let (an)n∈<sup>N</sup> be a sequence in A converging to a<sup>0</sup> and define

$$
f_n(x) := \int w(x')P(dx'|x, a_n), n \in \mathbb{N}.
$$

Hence, the required continuity is equivalent to showing that limn→∞ R fndµ = R f0dµ. Indeed, by Assumption 4.7(i), we have f<sup>n</sup> ≤ βw, ∀n ∈ N. The reversed Fatou's lemma implies lim supn→∞ R fndµ ≤ R lim supn→∞ fndµ = R f0dµ. On the other hand, we have f<sup>n</sup> ≥ −βw, ∀n ∈ N. Then, the extended Fatou's lemma implies lim infn→∞ R fndµ ≥ R lim infn→∞ fndµ = R f0dµ. Combining the above two inequalities yields the convergence. 

<span id="page-13-0"></span>*Assumption* 4.9*.* For each µ ∈ Pw(X), there exist stochastic kernels M on P(X) given Pw(X) × A × Y and R˜ on Y given Pw(X) × A satisfying [\(29\)](#page-10-1) such that, if {a<sup>n</sup> ∈ A, n = 1, 2, . . .} converges to a<sup>0</sup> ∈ A as n → ∞,

- (i) there exists a subsequence {a<sup>n</sup><sup>k</sup> } ⊂ {an} and a measurable set C¯ ∈ B(Y) such that R˜(C¯|µ, a0) = 1 and for all y ∈ C¯, M(µ, a<sup>n</sup><sup>k</sup> , y) converges canonically weakly to M(µ, a0, y);
- (ii) for each C ∈ B(Y), R˜(C|µ, an) → R˜(C|µ, a0) as n → ∞.

This assumption is inspired by Condition (c) in [\(Feinberg et](#page-18-8) al., [2016,](#page-18-8) Theorem 3.2). A sufficient condition for it will be discussed in the next section (see Remark [4.17\)](#page-15-0).

<span id="page-13-2"></span>Proposition 4.10. *Under Assumptions [4.9](#page-13-0) and 4.7, for each* µ ∈ Pw(X)*,* a 7→ Q˜(·|µ, a) *is canonically weakly continuous.*

Proof. This canonical weak continuity is guaranteed by [Feinberg et](#page-18-8) al. [\(2016,](#page-18-8) Theorem 3.4).

<span id="page-13-1"></span>Finally, to guarantee the existence of one "selector", we assume *Assumption* 4.11*.* A is compact.

Note that the operator T : Bw˜(X) → Bw˜(X) is defined as follows

<span id="page-13-4"></span><span id="page-13-3"></span>
$$
\mathcal{T}_a(\phi)(\mu) := \tilde{r}(\mu, a) + \alpha \int \phi \left( M(\mu, a, y) \right) \tilde{R}(dy | \mu, a) \tag{35}
$$

and 
$$
\mathcal{T}(\phi)(\mu) := \sup_{a \in A} \mathcal{T}_a(\phi)(\mu).
$$
 (36)

Under Assumptions [4.5](#page-12-0) – [4.9,](#page-13-0) it is guaranteed that for each µ ∈ Pw(X), a 7→ Ta(φ)(µ) is upper-semicontinuous (for a proof, see [\(Hern´andez-Lerma and Lasserre](#page-18-10), [1999,](#page-18-10) Lemma 8.3.7(a))). Hence, under the additional Assumption [4.11,](#page-13-1) the optimal a in the above optimization problem is always attainable in A (see, e.g., [\(Hern´andez-Lerma and Lasserre](#page-18-10), [1999,](#page-18-10) Lemma 8.3.8(a))). Hence, from now on, we replace "sup" with "max".

### 4.3 Value iteration

The following *value iteration* is a widely used method to compute the optimal solution for POMDPs, and MDPs as well. Starting from arbitrary *value function* in Bw˜(X), φ0, at time t, we update value function as follows

$$
\phi_{t+1}(\mu) = \mathcal{T}(\phi_t)(\mu) = \max_{a \in A} \left( \tilde{r}(\mu, a) + \alpha \int \phi \left( M(\mu, a, y) \right) \tilde{R}(dy | \mu, a) \right)
$$

Finally, by a suitable application of Theorem 8.3.6 in [Hern´andez-Lerma and Lasserre](#page-18-10) [\(1999](#page-18-10)), we obtain the following convergence.

<span id="page-13-5"></span>Theorem 4.12. *Suppose that Assumptions [4.5](#page-12-0) – [4.11](#page-13-1) hold. Let* β *be the constant in Assumption 4.7(i) and* r¯ *be the constant in [4.5\(](#page-12-0)i) and define* γ := αβ ∈ (0, 1)*. Then*

*(a) the optimal value function* φ ∗ *is the unique fixed point of the operator* T *satisfying* φ <sup>∗</sup> = T (φ ∗ ) *in* Bw˜(X) *and* kφ<sup>t</sup> − φ ∗ kw˜ ≤ rγ¯ t /(1 − γ), t = 1, 2, . . . .

*(b) there exists a selector* f ∗ : Pw(X) → A *such that*

$$
\phi^*(\mu) = \tilde{r}(\mu, f^*(\mu)) + \alpha \int \phi(M(\mu, f^*(\mu), y)) \tilde{R}(dy|\mu, f^*(\mu)), \forall \mu \in \mathscr{P}_w(\mathsf{X}).
$$

*and* π <sup>∗</sup> = (f ∗ ) <sup>∞</sup> *is one optimal policy satisfying* φ ∗ (µ) = J(µ, π ∗ ), ∀µ ∈ Pw(X)*.*

Proof. The original POMDP specified in Subsection [3.2](#page-9-0) can be reduced to an MDP with (Pw(X),A, r, ˜ Q˜). Under Assumptions [4.5](#page-12-0) – [4.11,](#page-13-1) Propositions [4.6](#page-12-1) – [4.10](#page-13-2) hold, and therefore, the conditions required by Theorem 8.3.6 in [Hern´andez-Lerma and Lasserre](#page-18-10) [\(1999](#page-18-10)) are satisfied. The assertion is then a direct application of that Theorem.

### 4.4 Application to POMDPs

Now we apply the conjugate duality obtained in Corollary [1.4](#page-2-0) to POMDPs. Recall that the operators T<sup>a</sup> and T are defined in equations [\(35\)](#page-13-3) and [\(36\)](#page-13-4).

<span id="page-14-3"></span>Lemma 4.13. *If* φ : Pw(X) → R *is convex, then* Ta(φ) *is convex,* ∀a ∈ A*, and therefore,* T (φ) *is convex as well.*

Proof. It is sufficient to show that µ 7→ r˜(µ, a) + α R φ(M(µ, a, y))R˜(dy|µ, a) is convex for each a ∈ A. Indeed, take any action a ∈ A and let µ<sup>1</sup> and µ<sup>2</sup> be two arbitrary elements in Pw(X). Take any κ ∈ (0, 1) and define µ<sup>κ</sup> := κµ<sup>1</sup> + (1 − κ)µ2. By the definition, for any B ∈ B(X) and C ∈ B(Y), we have

$$
R(\mathsf{B},\mathsf{C}|\mu_{\kappa},a) = \kappa R(\mathsf{B},\mathsf{C}|\mu_1,a) + (1-\kappa)R(\mathsf{B},\mathsf{C}|\mu_2,a) \tag{37}
$$

$$
=\kappa \int_{\mathsf{C}} M(\mathsf{B}|\mu_1, a, y) \tilde{R}(dy|\mu_1, a) + (1 - \kappa) \int_{\mathsf{C}} M(\mathsf{B}|\mu_2, a, y) \tilde{R}(dy|\mu_2, a). \tag{38}
$$

On the other hand, a simple calculation yields

$$
\tilde{R}(\mathsf{C}|\mu_{\kappa},a) = \kappa \tilde{R}(\mathsf{C}|\mu_1,a) + (1-\kappa)\tilde{R}(\mathsf{C}|\mu_2,a), \forall \mathsf{C} \in \mathcal{B}(\mathsf{Y}).\tag{39}
$$

Hence, R˜(C|µκ, a) = 0 implies R˜(C|µ1, a) = 0 and R˜(C|µ2, a) = 0, ∀C ∈ B(Y). By Radon-Nikodym theorem, there exist functions f<sup>i</sup> : Y × A → [0, ∞), i = 1, 2, which are both B(Y)-measurable for the fixed a, such that

<span id="page-14-2"></span><span id="page-14-1"></span><span id="page-14-0"></span>
$$
\tilde{R}(\mathsf{C}|\mu_i, a) = \int_{\mathsf{C}} f_i(y, a) \tilde{R}(dy | \mu_{\kappa}, a), i = 1, 2.
$$
\n(40)

Applying these two equations in [\(39\)](#page-14-0) accordingly, we obtain

$$
\tilde{R}(\mathsf{C}|\mu_{\kappa},a) = \int_{\mathsf{C}} \left( \kappa f_1(y,a) + (1-\kappa)f_2(y,a) \right) \tilde{R}(dy|\mu_{\kappa},a), \forall \mathsf{C} \in \mathcal{B}(\mathsf{Y}),
$$

which implies that κf1(y, a)+(1−κ)f2(y, a) = 1, R˜(·|µκ, a)-almost surely. In other words, there exists a Borel set C¯ ∈ B(Y) such that R˜(C¯|µκ, a) = 1 and κf1(y, a)+(1−κ)f2(y, a) = 1, ∀y ∈ C¯.

Applying [\(40\)](#page-14-1) to [\(38\)](#page-14-2), we obtain

$$
R(\mathsf{B},\mathsf{C}|\mu_{\kappa},a) = \int_{\mathsf{C}} \left[ \kappa M(\mathsf{B}|\mu_1,a,y) f_1(y,a) + (1-\kappa) M(\mathsf{B}|\mu_2,a,y) f_2(y,a) \right] \tilde{R}(dy|\mu_{\kappa},a),
$$

and for each κ ∈ (0, 1), M(·|a, y, κ) := κM(·|µ1, a, y)f1(y, a) + (1 − κ)M(·|µ2, a, y)f2(y, a) is a valid stochastic kernel satisfying R(B, C|µκ, a) = R <sup>C</sup> M(B|a, y, κ)R˜(dy|µκ, a), ∀B ∈ B(X), C ∈ B(Y). Finally, the convexity of φ implies

$$
\int \phi(M(\cdot|a,y,\kappa))\tilde{R}(dy|\mu_{\kappa},a) = \int_{\bar{C}} \phi(M(\cdot|a,y,\kappa))\tilde{R}(dy|\mu_{\kappa},a)
$$
  
\n
$$
\leq \int_{\bar{C}} [\kappa f_1(y,a)\phi(M(\mu_1,a,y)) + (1-\kappa)f_2(y,a)\phi(M(\mu_2,a,y))] \tilde{R}(dy|\mu_{\kappa},a)
$$
  
\n
$$
\leq \kappa \int \phi(M(\mu_1,a,y))\tilde{R}(dy|\mu_1,a) + (1-\kappa)\int \phi(M(\mu_2,a,y))\tilde{R}(dy|\mu_2,a),
$$

which yields the required convexity.

We introduce the following assumption accompanying Assumption [4.9.](#page-13-0)

<span id="page-15-1"></span>*Assumption* 4.14*.* For each a ∈ A, there exist stochastic kernels M on P(X) given Pw(X)× A×Y and R˜ on Y given Pw(X)×A satisfying [\(29\)](#page-10-1) such that, if {µ<sup>n</sup> ∈ Pw(X), n = 1, 2, . . .} converges to µ<sup>0</sup> ∈ Pw(X) as n → ∞,

(i) there exists a subsequence {µ<sup>n</sup><sup>k</sup> } ⊂ {µn} and a measurable set C¯ ∈ B(Y) such that R˜(C¯|µ0, a) = 1 and for all y ∈ C¯, M(µ<sup>n</sup><sup>k</sup> , a, y) converges canonically weakly to M(µ0, a, y);

(ii) for each C ∈ B(Y), R˜(C|µn, a) → R˜(C|µ0, a) as n → ∞.

<span id="page-15-3"></span>Lemma 4.15. *Suppose Assumptions [4.14,](#page-15-1) [4.5\(](#page-12-0)i) and 4.7(i) hold. Then, for any* φ ∈ Bw˜(X)*,* Ta(φ) *is continuous for any* a ∈ A *and therefore* T (φ) *is lower semicontinuous.* Proof. Fix one a ∈ A. Note that Proposition [4.6\(](#page-12-1)iii) ensures the continuity of the function µ 7→ r(µ, a). It remains to show that µ 7→ R φ(µ ′ )Q˜(dµ′ |µ, a) is continuous.

By Assumption [4.14](#page-15-1) and [\(Feinberg et al.](#page-18-8), [2016](#page-18-8), Theorem 3.4), µ 7→ Q˜(dµ′ |µ, a) is canonically weakly continuous. By Assumption, there exists a constant φ >¯ 0 such that |φ(µ)| ≤ φ¯w˜(µ) = φ¯ R wdµ. Let φ ′ (µ) := φ(µ) + φ¯ R wdµ, which is nonnegative. Hence, it is a limit of a nondecreasing sequence of measurable bounded function {φ ′ <sup>m</sup>} such that φ ′ <sup>m</sup> ↑ φ ′ . Let {µ<sup>n</sup> ∈ Pw(X)} be a converging sequence under W<sup>1</sup> to a limit µ<sup>0</sup> ∈ Pw(X). We have then

$$
\liminf_{n\to\infty}\int\phi'(\mu')\tilde{Q}(d\mu'|\mu_n,a)\geq \liminf_{n\to\infty}\int\phi_m'(\mu')\tilde{Q}(d\mu'|\mu_n,a)=\int\phi_m'(\mu')\tilde{Q}(d\mu'|\mu_0,a).
$$

Hence, letting m → ∞, monotone convergence yields that

<span id="page-15-2"></span>
$$
\liminf_{n \to \infty} \int \phi'(\mu') \tilde{Q}(d\mu'|\mu_n, a) \ge \int \phi'(\mu') \tilde{Q}(d\mu'|\mu_0, a). \tag{41}
$$

On the other hand, we have for each n ∈ N,

$$
\int \tilde{w}(\mu')\tilde{Q}(d\mu'|\mu_n, a) = \int_{\mathsf{Y}} \int_{\mathsf{X}} w(x')\tilde{P}(dx'|\mu_n, a)Q(dy|x', a) = \int_{\mathsf{X}} \int_{\mathsf{X}} w(x')P(dx'|x, a)\mu_n(dx).
$$

Note that by Assumption 4.7(i), we have for each a ∈ A, w ′ (x, a) := R <sup>X</sup> w(x ′ )P(dx′ |x, a) ∈ Lw. Proposition [4.3\(](#page-11-3)ii) yields that limn→∞ R w˜(µ ′ )Q˜(dµ′ |µn, a) = R w˜(µ ′ )Q˜(dµ′ |µ0, a). Hence, [\(41\)](#page-15-2) implies that lim infn→∞ R φ(µ ′ )Q˜(dµ′ |µn, a) ≥ R φ(µ ′ )Q˜(dµ′ |µ0, a). In other words, µ 7→ R φ(µ ′ )Q˜(dµ′ |µ, a) is lower semicontinuous. We apply this fact to −φ in lieu of φ and obtain that µ 7→ R φ(µ ′ )Q˜(dµ′ |µ, a) is also upper semicontinuous. Thus the required continuity holds.

We immediately obtain the following result.

Theorem 4.16. *Suppose Assumptions [4.14,](#page-15-1) [4.5\(](#page-12-0)i) and 4.7(i) hold. If* φ ∈ Bw˜(X) *is convex, then* T (φ) *is convex and lower semicontinuous.*

<span id="page-15-0"></span>*Remark* 4.17*.* [Feinberg et al. \(2016](#page-18-8), Theorem 3.6) show that one sufficient condition to guarantee both Assumption [4.9](#page-13-0) and [4.14](#page-15-1) is that (i) The stochastic kernel P(dx′ |x, a) is canonically weakly continuous and (ii) the stochastic kernel Q(dy|x, a) is continuous in total variation. In addition, it is demonstrated in [\(Feinberg et al., 2016](#page-18-8), Example 4.1) that the latter continuity in total variation cannot be weakened to the canonical weak continuity. This confirms the necessity of Assumption [4.14\(](#page-15-1)ii).

### 4.5 Set iteration

Recall that Corollary [1.4](#page-2-0) imply that a convex and lower semicontinuous function φ admits a representation of φ(µ) = supf∈N R fdµ with some set N ⊂ L (X). Hence, instead of iterating the value function, we can iterate the acceptance set, which is described as follows.

*Algorithm* 4.18*.* Start with any set N¯<sup>0</sup> ⊂ L (X). At time t, update the acceptance set using the following two steps:

$$
\phi_{t+1}(\mu) = \max_{a \in A} \left( \tilde{r}(\mu, a) + \alpha \int \left( \sup_{f \in \tilde{\mathcal{N}}_t} \int f(x') M(dx' | \mu, a, y) \right) \tilde{R}(dy | \mu, a) \right)
$$
$$
\tilde{\mathcal{N}}_{t+1} = \left\{ f \in \mathscr{L}(\mathsf{X}) \mid \phi_{t+1}(\mu) \ge \int f d\mu, \forall \mu \in \mathscr{P}_w(\mathsf{X}) \right\}.
$$

These steps will be repeated until some stopping criterion is satisfied.

An iteration of null level-sets can be analogously designed as above and is therefore omitted. Note that in course of iteration, Lemma [4.13](#page-14-3) and [4.15](#page-15-3) guarantee that φ<sup>t</sup> is convex and lower semicontinuous for each t = 1, 2, . . . . Hence, Corollary [1.4](#page-2-0) ensures that φt(µ) = supf∈N¯<sup>t</sup> R fdµ, ∀µ ∈ Pw(X), and for each t = 1, 2, . . . . By Theorem [4.12\(](#page-13-5)a), we immediately obtain the following result.

<span id="page-16-1"></span>Theorem 4.19. *Suppose Assumptions [4.5,](#page-12-0) 4.7, [4.9,](#page-13-0) [4.11](#page-13-1) and [4.14](#page-15-1) hold. Let* φ ∗ *be the optimal value function for the POMDP,* r > ¯ 0 *and* γ ∈ (0, 1) *be the constants as in Theorem [4.12\(](#page-13-5)a). Then,*

$$
\|\phi^* - \phi_t\|_{\tilde{w}} \leq \bar{r}\gamma^t/(1-\gamma), \text{ where } \phi_t(\mu) = \sup_{f \in \bar{\mathcal{N}}_t} \int f d\mu, \forall \mu \in \mathscr{P}_w(\mathsf{X}).
$$

This implies that the optimal value function φ ∗ can be arbitrarily well approximated by a convex and lower semicontinuous function φ of the dual form.

Corollary 4.20. *Suppose Assumptions [4.5,](#page-12-0) 4.7, [4.9,](#page-13-0) [4.11](#page-13-1) and [4.14](#page-15-1) hold. For any* ǫ > 0*, there exists a set* N <sup>ǫ</sup> ⊂ L (X) *satisfying* kφ <sup>∗</sup>−φ ǫ kw˜ ≤ ǫ, *where* φ ǫ (µ) := supf∈N<sup>ǫ</sup> R fdµ, ∀µ ∈ Pw(X).

A special case: Q is supported by a reference measure Let us assume that there exists a reference (probability) measure ϕ on Y such that Q(·|x ′ , a) ≪ ϕ(·) for all (x ′ , a) ∈ X × A. Note that POMDPs in many applications satisfy this assumption. For example, the assumption holds automatically if the observation space is finite. Hence, the density of Q w.r.t. ϕ exists and is denoted by q(y|x ′ , a). In this case, the iteration can be further simplified. Indeed, it is easy to verify that

$$
M(dx'|\mu, a, y) = \frac{\tilde{P}(dx'|\mu, a)q(y|x', a)}{\int_{X} \tilde{P}(dx'|\mu, a)q(y|x', a)} \quad \text{and} \quad \tilde{R}(dy|\mu, a) = \int_{X} \tilde{P}(dx'|\mu, a)q(y|x', a)\varphi(dy)
$$

satisfy [\(29\)](#page-10-1). Under this setup, the calculation of iteration becomes much simpler. Suppose φ ∈ Bw˜ is convex and lower semicontinuous, then we have by Corollary [1.4,](#page-2-0)

$$
\mathcal{T}_a(\phi)(\mu) = \tilde{r}(\mu, a) + \alpha \int \left( \sup_{f \in \tilde{\mathcal{N}}_{\phi}} \int f(x') \tilde{P}(dx' | \mu, a) q(y | x', a) \right) \varphi(dy). \tag{42}
$$

In particular, the continuity of Q in total variation mentioned in Remark [4.17](#page-15-0) is

$$
\int |q(y|x_n, a_n) - q(y|x_0, a_0)| \varphi(dy) \to 0, \text{ as } (x_n, a_n) \to (x_0, a_0).
$$

### 5 Appendix

<span id="page-16-0"></span>Lemma 5.1. *For* µ ∈ P1(X)*, it holds that*

$$
\log \int_{X} e^{g} d\mu = \sup_{\nu \in \mathcal{P}_1(X)} \left\{ \int_{X} g d\nu - R(\nu|\mu) \right\}, \quad \forall g \in \mathcal{L}(X)
$$
 (43)

*Proof.* Let µ<sup>n</sup> with dµ<sup>n</sup> dµ = e min(g,n) · 1 R X <sup>e</sup>min(g,n)dµ . For an arbitrary <sup>ν</sup> ∈ P1(X) with R(ν|µ) < ∞, we have that ν is absolutely continuous with respect to µ<sup>n</sup> and therefore

<span id="page-16-2"></span>
$$
\int_{X} g d\nu - \mathcal{R}(\nu|\mu) = \int_{X} g d\nu - \int_{X} \log\left(\frac{d\nu}{d\mu}\right) d\nu
$$
\n
$$
= \int_{X} g d\nu - \int_{X} \log\left(\frac{d\nu}{d\mu_{n}}\right) d\nu - \int_{X} \log\left(\frac{d\mu_{n}}{d\mu}\right) d\nu
$$
\n
$$
= \int_{X} g d\nu - \mathcal{R}(\nu|\mu_{n}) + \log\left(\int_{X} e^{\min(g,n)} d\mu\right) - \int_{X} \min(g,n) d\nu.
$$
\n(44)

Now by using the positivity of R and applying the monotone convergence theorem we get

$$
\int_{\mathsf{X}} g d\nu - \mathcal{R}(\nu|\mu) \le \log \int_{\mathsf{X}} e^g d\mu.
$$

If R(ν|µ) = ∞, the above inequality holds trivially.

Now, on the other hand, by setting ν = µ<sup>n</sup> in [\(44\)](#page-16-2), observing that R X gdµn− R <sup>X</sup> min(g, n)dµ<sup>n</sup> ≥ 0, and applying the monotone convergence theorem one more time, we get

$$
\lim_{n\to\infty}\left(\int_X g d\mu_n - \mathcal{R}(\mu_n|\mu)\right) \geq \log \int_X e^g d\mu,
$$

which yields our result.

<span id="page-17-0"></span>Lemma 5.2. *For* µ, ν ∈ P1(X)*, it holds that*

$$
\sup_{g \in C_b(\mathsf{X})} \left\{ \int_{\mathsf{X}} g d\nu - \log \int_{\mathsf{X}} e^g d\mu \right\} = \sup_{g \in \mathscr{L}(\mathsf{X})} \left\{ \int_{\mathsf{X}} g d\nu - \log \int_{\mathsf{X}} e^g d\mu \right\} \tag{45}
$$

*Proof.* For simplicity we will set F(g) = R X gdν − log R X e g dµ. By properties of the supermum, we have

sup g∈Cb(X)∩L(X) F(g) ≤ sup g∈Cb(X) F(g) ≤ sup g∈Cb(X)∪L(X) F(g), sup g∈Cb(X)∩L(X) F(g) ≤ sup g∈L(X) F(g) ≤ sup g∈Cb(X)∪L(X) F(g).

So it will be enough to prove that

$$
\sup_{g \in C_b(\mathsf{X}) \cup \mathscr{L}(\mathsf{X})} F(g) \leq \sup_{g \in C_b(\mathsf{X}) \cap \mathscr{L}(\mathsf{X})} F(g).
$$

Let g ∈ Cb(X) ∪ L (X), with F(g) 6= −∞. It is now enough to prove that for every ǫ > 0, it exists ˜g ∈ Cb(X) ∩ L (X) such that F(g) − F(˜g) ≤ ǫ.

First we are going to approximate g by a bounded function ˆg. We set g<sup>m</sup> = min(g, m), and by a suitable application of the monotone convergence theorem we have that for sufficiently big m holds |F(g) − F(gm)| ≤ <sup>ǫ</sup> 4 . Now if we further set g n <sup>m</sup> = max(gm, −n), and we apply the dominated convergence theorem, we can find ˆg = g n <sup>m</sup> such that

<span id="page-17-1"></span>
$$
|F(g) - F(\hat{g})| \le \frac{\epsilon}{2}.\tag{46}
$$

To get the Lipschiz property, we will first apply Prohorov's theorem, and we will find a compact set K such that µ(X\ K), ν(X\ K) ≤ ǫ ′ . Now, we can approximate any function gˆ in Cb(K), ǫ′ -uniformly by a function in L (K) through the formula

$$
\hat{g}_n(x) = \inf_{y \in \mathsf{K}} \left\{ \hat{g}(y) + nd(x, y) \right\},\tag{47}
$$

for sufficiently large n. By taking n big enough we can also have that e <sup>g</sup>ˆ<sup>n</sup> , e<sup>g</sup><sup>ˆ</sup> , are at most ǫ ′ -uniformly apart in K. This formula actually defines ˆg<sup>n</sup> to be Lipschitz on the whole space X. We can further bound by using ˜g(x) = max (min (ˆgn(x), kgˆk∞), −kgˆk∞). Now we have

$$
\left| \int_{\mathsf{K}} \hat{g} d\nu - \int_{\mathsf{K}} \tilde{g} d\nu \right| \leq \epsilon', \quad \left| \int_{\mathsf{X} \backslash \mathsf{K}} \hat{g} d\nu - \int_{\mathsf{X} \backslash \mathsf{K}} \tilde{g} d\nu \right| \leq 2\epsilon' ||\hat{g}||_{\infty}
$$
\n
$$
\left| \int_{\mathsf{K}} e^{\hat{g}} d\nu - \int_{\mathsf{K}} e^{\tilde{g}} d\nu \right| \leq \epsilon', \quad \left| \int_{\mathsf{X} \backslash \mathsf{K}} e^{\hat{g}} d\nu - \int_{\mathsf{X} \backslash \mathsf{K}} e^{\tilde{g}} d\nu \right| \leq 2\epsilon' e^{||\hat{g}||_{\infty}}
$$
\n(48)

Now by using the modulus of uniform continuity ω for the logarithm on [e −kgˆk<sup>∞</sup>, e<sup>k</sup>gˆk<sup>∞</sup>]. (or a simple mean value theorem), we get the following estimate |F(ˆg) − F(˜g)| ≤ 2ǫ ′ + 2ǫ ′ kgˆk∞+ω(2ǫ ′ (1+e <sup>k</sup>gˆk<sup>∞</sup>)). Now if ǫ ′ becomes sufficiently small we have |F(ˆg)−F(˜g)| ≤ <sup>ǫ</sup> 2 , and by combining with [\(46\)](#page-17-1) we get our claim.

We conclude by providing a proof for Corollary [1.2.](#page-1-3)

*Proof of Corollary [1.2.](#page-1-3)* First assume that Φ(W1(µ, ν)) ≤ φ(µ). For f ∈ [L(X)]1, we have

$$
\rho\left(t\int_X f d\nu - tf - \Phi^*(t)\right) = \sup_{\mu \in \mathcal{P}_1(X)} \left[\int_X \left(t\int_X f d\nu - tf - \Phi^*(t)\right) d\mu - \phi(\mu)\right]
$$
$$
= \sup_{\mu \in \mathcal{P}_1(X)} \left[t\left(\int_X f d\nu - \int_X f d\mu\right) - \Phi^*(t) - \phi(\mu)\right]
$$
$$
= \sup_{\mu \in \mathcal{P}_1(X)} \left[t\mathcal{W}_1(\mu, \nu) - \Phi^*(t) - \phi(\mu)\right]
$$
$$
= \sup_{\mu \in \mathcal{P}_1(X)} \left[\Phi(W_1(\mu, \nu)) - \phi(\mu)\right] \le 0.
$$

Conversely if ρ t R X fdν − tf − Φ ∗ (t) ≤ 0, we have

$$
t\left(\int_{X} f d\nu - \int_{X} f d\mu\right) - \Phi^*(t) = \int_{X} \left(t \int_{X} f d\nu - tf - \Phi^*(t)\right) d\mu
$$
  
$$
\leq \rho \left(t \int_{X} f d\nu - tf - \Phi^*(t)\right) + \phi(\mu) \leq \phi(\mu).
$$
 (49)

Taking the supremum over f ∈ [L (X)]1, we get

$$
tW_1(\mu,\nu) - \Phi^*(t) \le \phi(\mu) \tag{50}
$$

By taking the supremum over t ≥ 0, we have Φ(W1(µ, ν)) ≤ φ(µ).

### References

- <span id="page-18-9"></span>M. Arjovsky, S. Chintala and L. Bottou. *Wasserstein GAN.* ArXiv: 1701.07875
- <span id="page-18-11"></span>D.P. Bertsekas and S.E. Shreve. *Stochastic Optimal Control: The Discrete Time Case*. Academic Press, 1978.
- <span id="page-18-5"></span>SG. Bobkov and F. Gtze. *Exponential integrability and transportation cost related to logarithmic Sobolev inequalities*. Journal of Functional Analysis, 2019.
- <span id="page-18-2"></span>J.M. Borwein and A.S. Lewis. *Convex Analysis and Nonlinear Optimization: Theory and Examples*. Springer, 2nd edition, 2006.
- <span id="page-18-0"></span>R. Bot *Conjugate Duality in Convex Optimization*. Springer, Lecture Notes in Economics and Mathematical Systems, 2010.
- <span id="page-18-3"></span>S. Boyd and L. Vandenberghe. *Convex Optimization*. Cambridge University Press, 2004.
- <span id="page-18-4"></span>Dupuis, P and Ellis, RS S *A Weak Convergence Approach to the Theory of Large Deviations*. John Wiley & Sons, 1997.
- <span id="page-18-8"></span>E.A. Feinberg, P.O. Kasyanov, and M.Z. Zgurovsky. *Partially observable total-cost Markov decision processes with weakly continuous transition probabilities.* Mathematics of Operations Research, 2016.
- <span id="page-18-6"></span>H. F¨ollmer and A. Schied. *Stochastic Finance*. Walter de Gruyter & Co., Berlin, 2004. Extended edition.
- <span id="page-18-7"></span>O. Hern´andez-Lerma. *Adaptive Markov Control Processes*. Springer, 1989.
- O. Hern´andez-Lerma and J.B. Lasserre. *Discrete-time Markov Control Processes: Basic Optimality Criteria*. Springer, 1996.
- <span id="page-18-10"></span>O. Hern´andez-Lerma and J.B. Lasserre. *Further Topics on Discrete-Time Markov Control Processes*. Springer Verlag, 1999.
- <span id="page-18-1"></span>R. Ioan-Bot, S.-M. Grad, and G. Wanka. *Duality in Vector Optimization*. Springer Science & Business Media, 2009.

- <span id="page-19-5"></span>L.P. Kaelbling, M.L. Littman, and A.R. Cassandra. *Planning and acting in partially observable stochastic domains.* Artificial intelligence, 101(1):99–134, 1998.
- <span id="page-19-12"></span>L.V. Kantorovich and G.P. Akilov. *Functional Analysis* (Second edition). Pergamon Press, 1982.
- <span id="page-19-3"></span>W.S. Lovejoy. *A survey of algorithmic methods for partially observed Markov decision processes.* Annals of Operations Research, 28(1):47–65, 1991.
- <span id="page-19-13"></span>D.G. Luenberger. *Optimization by Vector Space Methods*. JohnWiley & Sons Inc., New York, 1969.
- <span id="page-19-4"></span>J. Pineau, G. Gordon, and S. Thrun. *Anytime point-based approximations for large POMDPs*. Journal of Artificial Intelligence Research, pages 335–380, 2006.
- <span id="page-19-7"></span>Y. Sawaragi and T. Yoshikawa. *Discrete-time Markovian decision processes with incomplete state observation.* The Annals of Mathematical Statistics, 41(1):78–86, 1970.
- <span id="page-19-11"></span>H. Schaefer *Topological vector spaces* Springer-Verlag, 1971.
- <span id="page-19-8"></span>G. Shani, J. Pineau, and R. Kaplow. *A survey of point-based POMDP solvers.* Autonomous Agents and Multi-Agent Systems, 27(1):1–51, 2013.
- <span id="page-19-0"></span>R.D. Smallwood and E.J. Sondik. *The optimal control of partially observable Markov processes over a finite horizon.* Operations Research, 21(5):1071–1088, 1973.
- <span id="page-19-6"></span>E.J. Sondik. *The optimal control of partially observable Markov processes over the infinite horizon: Discounted costs.* Operations Research, 26(2):282–304, 1978.
- <span id="page-19-2"></span>C. Villani. *Optimal Transport*. Springer, 2009.
- <span id="page-19-14"></span>J. Van Der Wal. *Stochastic Dynamic Programming successive approximations and nearly optimal strategies for Markov decision processes*. Methematisch Centrum, 1981
- <span id="page-19-9"></span>N. Weaver. *Lipschitz Algebras*. World Scientific, 1999.
- <span id="page-19-10"></span>N. Weaver. *On the unique predual problem for Lipschitz spaces* [arXiv:1611.01812,](http://arxiv.org/abs/1611.01812) 2016
- <span id="page-19-1"></span>C. Z˘alinescu. *Convex Analysis in General Vector Spaces*. World Scientific, 2002.